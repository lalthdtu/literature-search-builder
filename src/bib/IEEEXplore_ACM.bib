@inproceedings{9974398,
    author        = {Zhu, Tingting},
    booktitle     = {2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
    title         = {The Impact of Non-immersive Virtual Reality Technologies on Consumers' Behaviors in real estate: A Website's Perspective},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {13--20},
    abstract      = {With the development of virtual reality (VR) technologies, an increasing number of studies have recognized that virtual reality (VR) technologies increased consumer experience and made life convenient. In real estate platform, the effectiveness of VR technologies on consumer behaviors from the website perspectives remains ambiguous. Consequently, this study investigates the impact of the non-immersive VR technologies experience provided by real estate website on the consumers' behaviors. By crawling data from the website, we capture consumers' viewing behaviors when presented the property through static photographs and 3D Tour. This study highlights the advantages of non-immersive VR technologies in increasing the number of consumers' behaviors significantly from the website perspective.},
    keywords      = {Consumer behavior;Three-dimensional displays;Augmented reality;impact;non-immersive virtual reality;consumer behavior;real estate},
    doi           = {10.1109/ISMAR-Adjunct57072.2022.00013},
    issn          = {2771-1110},
    month         = {Oct}
}
@inproceedings{9658673,
    author        = {Perera, Madhawa and Gedeon, Tom and Adcock, Matt and Haller, Armin},
    booktitle     = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
    title         = {Towards Self-Guided Remote User Studies - Feasibility of Gesture Elicitation using Immersive Virtual Reality},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {2576--2583},
    abstract      = {Gesture Elicitation Studies (GES) are a widely used empirical method to develop gesture vocabularies, interaction models and methods for gesture-based systems in different contexts. While GES show great promise to identify user-defined gestures, there are inherent problems with current methods used for GES. Especially during the ongoing pandemic, it has been nearly impossible to conduct in-person, in-lab GES, while ensuring the safety and well-being of the participants, and complying with social distancing regulations. Further, with prevailing experiment designs, increasing the number of participants is time consuming, while in-lab environments also limit ecological validity. This study explores an intuitive way of conducting self-guided GES using immersive Virtual Reality (VR), utilizing its capability to simulate various contexts to enhance ecological validity. We present a methodology and a tool set that use an immersive VR environment to conduct ecologically valid GES (as a use case) while requiring minimal involvement by the investigator. We evaluate our method using the case of a smart home environment and measure participant acceptance and discuss opportunities and challenges involved in this method. We believe that this study will help HCI research to move forward with participatory design research, even when lab experiments are difficult to conduct.},
    keywords      = {Human computer interaction;Vocabulary;Visualization;Solid modeling;Pandemics;Virtual reality;Smart homes},
    doi           = {10.1109/SMC52423.2021.9658673},
    issn          = {2577-1655},
    month         = {Oct}
}
@inproceedings{10309380,
    author        = {Kawaguchi, Asaki and Abe, Yutaro and Okamoto, Shogo and Goto, Yuta and Hara, Masayuki and Kanayama, Noriaki},
    booktitle     = {2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
    title         = {Asura hands: Own and control two left hands in immersive virtual reality environment},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {1347--1352},
    abstract      = {Body ownership, which is the feeling that one's body part belongs to oneself, and agency, which is the sense of being able to control one's own body part, can be felt towards fake body parts and those depicted by computer graphics. As part of an attempt to transfer self-body awareness to fake body segments, we investigated whether body ownership and agency are felt towards two visible left hands in an immersive virtual reality environment. One of the two hands shown through virtual reality goggles spatially matched the unseen actual hand. The other hand was fake and displayed at either the 10-cm lateral or medial side of the position of the actual hand. These two left hands moved synchronously with the actual left hand. Participants completed a behavioral test and questionnaire after adapting to the two left hands. In the behavioral test, participants accessed randomly emerging spheres using the seen hands as fast as possible. They used the fake hand to touch a sphere when it appeared near the fake hand 41\% of the time when the fake hand was displayed at the medial position of the actual hand. The results of the questionnaire suggest that agency was experienced for the two visible left hands for this condition. By contrast, body ownership was felt mostly against the displayed hand that was spatially consistent with the actual hand. These findings indicate that although agency can be simultaneously felt for two seen left hands, body ownership is felt only for either of the two visible left hands.},
    keywords      = {Surveys;Virtual reality;Behavioral sciences;Task analysis;Eye protection;Robots},
    doi           = {10.1109/RO-MAN57019.2023.10309380},
    issn          = {1944-9437},
    month         = {Aug}
}
@article{10458353,
    author        = {Xiong, Ningchang and Liu, Qingqin and Zhu, Kening},
    journal       = {IEEE Transactions on Visualization and Computer Graphics},
    title         = {PetPresence: Investigating the Integration of Real-World Pet Activities in Virtual Reality},
    year          = {2024},
    volume        = {30},
    number        = {5},
    pages         = {2559--2569},
    abstract      = {For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets' movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users' performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.},
    keywords      = {Virtual reality;Visualization;Virtual environments;Urban areas;Three-dimensional displays;Portals;Media;Virtual Reality;Haptics;Distractions;Presence;Pet},
    doi           = {10.1109/TVCG.2024.3372095},
    issn          = {1941-0506},
    month         = {May}
}
@inproceedings{8797862,
    author        = {George, Ceenu and Khamis, Mohamed and Buschek, Daniel and Hussmann, Heinrich},
    booktitle     = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
    title         = {Investigating the Third Dimension for Authentication in Immersive Virtual Reality and in the Real World},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {277--285},
    abstract      = {Immersive Virtual Reality (IVR) is a growing 3D environment, where social and commercial applications will require user authentication. Similarly, smart homes in the real world (RW), offer an opportunity to authenticate in the third dimension. For both environments, there is a gap in understanding which elements of the third dimension can be leveraged to improve usability and security of authentication. In particular, investigating transferability of findings between these environments would help towards understanding how rapid prototyping of authentication concepts can be achieved in this context. We identify key elements from prior research that are promising for authentication in the third dimension. Based on these, we propose a concept in which users' authenticate by selecting a series of 3D objects in a room using a pointer. We created a virtual 3D replica of a real world room, which we leverage to evaluate and compare the factors that impact the usability and security of authentication in IVR and RW. In particular, we investigate the influence of randomized user and object positions, in a series of user studies (N=48). We also evaluate shoulder surfing by real world bystanders for IVR (N=75). Our results show that 3D passwords within our concept are resistant against shoulder surfing attacks. Interactions are faster in RW compared to IVR, yet workload is comparable.},
    keywords      = {Authentication;Three-dimensional displays;Password;Virtual reality;Resists;Usability;Human-centered computing--User studies;Human-centered computing--Virtual reality},
    doi           = {10.1109/VR.2019.8797862},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{10536478,
    author        = {Masters, Rachel},
    booktitle     = {2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {[DC] Virtual Reality Nature Environment Designs for Mental Health},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1142--1143},
    abstract      = {Shinrin-yoku, or forest bathing, is a therapeutic nature immersion practice shown to reduce stress and restore mental resources. In a world where the negative effects of sustained stress are an increasingly prevalent issue, connection to nature is important. However, many populations who encounter the most stress are largely isolated from nature, like people working long hours in cities, nursing home residents, or hospital patients. For these populations, virtual reality (VR) nature immersion is a promising supplement for when nature is not accessible. In order to design optimal VR nature environments (VNEs), we must first understand why and how VNEs can be restorative. This is a current area of research, and one critical gap that the proposed research seeks to understand is how the different components of VNEs and their interactions can be optimally designed for short and long term stress reduction and attention restoration. The proposed research does a deeper exploration into the designs of plants and water for optimally restorative VR green and blue spaces.},
    keywords      = {Three-dimensional displays;Hospitals;Cybersickness;Sociology;Urban areas;Green products;Mental health;Human-centered computing--Empirical Studies in HCI--;----Human-centered computing--User studies--;Humancentered computing--Virtual Reality----},
    doi           = {10.1109/VRW62533.2024.00365},
    issn          = {},
    month         = {March}
}
@inproceedings{10029515,
    author        = {Obo, Takenori and Kubota, Noyuki},
    booktitle     = {2022 IEEE 22nd International Symposium on Computational Intelligence and Informatics and 8th IEEE International Conference on Recent Achievements in Mechatronics, Automation, Computer Science and Robotics (CINTI-MACRo)},
    title         = {Topoplogical Structured Learning for Assessment of Unilateral Spatial Neglect},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {000137--000142},
    abstract      = {This paper presents an immersive virtual reality (VR) system for assessment of unilateral spatial neglect (USN). USN is defined by the inability for a person to perceive stimuli on one side of the body or environment that is not due to a lack of sensation. In clinical practice, paper-and-pencil tests are used as the quick assessments. However, the sensitivity of these tests is not sufficient for USN assessment in activities of daily living. Thus, VR systems and multimodal sensing systems have been applied to more sensitive diagnosis for USN. In this study, we aim to propose a method to extract specific features of USN patients in behavioral and cognitive levels.},
    keywords      = {Computer science;Sensitivity;Mechatronics;Multimodal sensors;Virtual reality;Feature extraction;Behavioral sciences;structured learning;topological mapping;immersive virtual reality system;unilateral spatial neglect},
    doi           = {10.1109/CINTI-MACRo57952.2022.10029515},
    issn          = {2471-9269},
    month         = {Nov}
}
@inproceedings{10639581,
    author        = {Ribeiro, Tiago and Henriques, Pedro Rangel and Oliveira, Eva and Rodrigues, Nuno F.},
    booktitle     = {2024 IEEE 12th International Conference on Serious Games and Applications for Health (SeGAH)},
    title         = {Evaluating Constrained Users Ability to Interact with Virtual Reality Applications},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--8},
    abstract      = {This article introduces an immersive Virtual Reality (VR) application designed to assess the interaction capabilities of users with physical and cognitive limitations, including older adults and individuals with disabilities, as well as ICU patients. The VR application encompasses six tasks varying in complexity, each designed to evaluate different aspects of VR interaction skills, such as movements of the head, arms, and fingers, alongside more intricate activities like pick-and-place, pointing, and painting. The paper details the VR application's specifications, including its system architecture, deployment framework, and data structure. The application's efficacy was tested through three pilot studies in a retirement home setting. The analysis focused on examining correlations among various factors, including age, cognitive abilities (evaluated using the Mini-Mental Status Examination), and previous VR experience. The findings reveal significant correlations, illuminating the effects of age, cognitive capacity, and past VR interactions on task performance. The results emphasize the importance of accounting for user-specific attributes, prior experiences, and cognitive abilities in the design of VR-based therapeutic interventions.},
    keywords      = {Correlation;Systems architecture;Medical treatment;Virtual reality;Serious games;Task analysis;Older adults;Virtual Reality;Intensive care;Cognitive resilience;Non-pharmacological therapies},
    doi           = {10.1109/SeGAH61285.2024.10639581},
    issn          = {2573-3060},
    month         = {Aug}
}
@article{9177307,
    author        = {Lei, Zhongcheng and Zhou, Hong and Hu, Wenshan and Liu, Guo-Ping and Deng, Qijun and Zhou, Dongguo and Liu, Zhi-Wei and Gao, Xingran},
    journal       = {IEEE Transactions on Industrial Informatics},
    title         = {Unified 3-D Interactive Human-Centered System for Online Experimentation: Current Deployment and Future Perspectives},
    year          = {2021},
    volume        = {17},
    number        = {7},
    pages         = {4777--4787},
    abstract      = {Online experimentation systems that support remote and/or virtual experiments in an Internet-based environment play an important role in skill-enhanced online learning, especially in the field of engineering. This article explores a human-centered online system with a unified architecture that covers the entire process of control engineering experimentation. The control and security-oriented design are presented and the human-centered design including the HTML5-based web application and the configurable graphical user interface is also introduced. Interactive features such as tuning parameters and 3-D animations and interactions are integrated into the system. Enhanced 3-D effects such as anaglyph 3-D and parallax 3-D are also provided. Thus, users can experience different types of 3-D effects on experiment equipment or in a 3-D virtual world while conducting experiments. Details of an application example with a dual tank system are also explored to verify the performance of the proposed system.},
    keywords      = {Servers;Informatics;Solid modeling;Mathematical model;Graphical user interfaces;Wiring;Monitoring;Human-centered system;online experimentation;3-D rendering;unified architecture},
    doi           = {10.1109/TII.2020.3019238},
    issn          = {1941-0050},
    month         = {July}
}
@article{9122616,
    author        = {Jiang, Weijin and Liu, Xiaoliang and Liu, Xingbao and Wang, Yang and Lv, Sijian and Ye, Fang},
    journal       = {China Communications},
    title         = {A new behavior-assisted semantic recognition method for smart home},
    year          = {2020},
    volume        = {17},
    number        = {6},
    pages         = {26--36},
    abstract      = {In the recent Smart Home (SH) research work, intelligent service recommendation technique based on behavior recognition, it has been extensively preferred by researchers. However, most current research uses the Semantic recognition to construct the user's basic behavior model. This method is usually restricted by environmental factors, the way these models are built makes it impossible for them to dynamically match the services that might be provided in the user environment. To solve this problem, this paper proposes a Semantic behavior assistance (Semantic behavior assistance, SBA). By joining the semantic model on the intelligent gateway, building an SA model, in this way, a logical Internet networks for smart home is established. At the same time, a behavior assistant method based on SBA model is proposed, among them, the user environment-related entities, sensors, devices, and user-related knowledge models exist in the logical interconnection network of the SH system through the semantic model. In this paper, the data simulation experiment is carried out on the method. The experimental results show that the SBA model is better than the knowledge-based pre-defined model.},
    keywords      = {Semantics;Atmospheric modeling;Smart homes;Solid modeling;Intelligent sensors;Data models;smart home (SH);semantic behavior assistance (SBA);user behavior intention;behavior assisted method},
    doi           = {10.23919/JCC.2020.06.003},
    issn          = {1673-5447},
    month         = {June}
}
@inproceedings{9757712,
    author        = {Yao, Powen and Hou, Yu and He, Yuan and Cheng, Da and Hu, Huanpu and Zyda, Michael},
    booktitle     = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Toward Using Multi-Modal Machine Learning for User Behavior Prediction in Simulated Smart Home for Extended Reality},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {688--689},
    abstract      = {In this work, we propose a multi-modal approach to manipulate smart home devices in a smart home environment simulated in virtual reality (VR). We determine the user's target device and the desired action by their utterance, spatial information (gestures, positions, etc.), or a combination of the two. Since the information contained in the user's utterance and the spatial information can be disjoint or complementary to each other, we process the two sources of information in parallel using our array of machine learning models. We use ensemble modeling to aggregate the results of these models and enhance the quality of our final prediction results. We present our preliminary architecture, models, and findings.},
    keywords      = {Solid modeling;Three-dimensional displays;Extended reality;Conferences;Aggregates;Smart homes;Machine learning;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality},
    doi           = {10.1109/VRW55335.2022.00195},
    issn          = {},
    month         = {March}
}
@inproceedings{7905004,
    author        = {Hnoohom, Narit and Nateeraitaiwa, Suppanut},
    booktitle     = {2017 International Conference on Digital Arts, Media and Technology (ICDAMT)},
    title         = {Virtual reality-based smartphone application for animal exposure},
    year          = {2017},
    volume        = {},
    number        = {},
    pages         = {417--422},
    abstract      = {Exposure therapy is one method of behavioral therapy used for treating phobias, by applying virtual reality technology to generate the patient's fear environment that the patient can interact in the virtual environment without any danger. In this paper we propose a virtual reality-based smartphone application for user exposure to face their animal fear phobia. Using this application the user can practice facing the situation they fear. The user is able to use this application at anywhere, even in their own home. With an evaluation on 10 participants, the impact of user participation on realism, dreadfulness of dog, fierceness of dog, and hearing the dog sound was explored. The results have shown that user participation was found to influence the fierceness of dog and the dreadfulness of the dog.},
    keywords      = {Dogs;Solid modeling;Glass;Avatars;Androids;Humanoid robots;Cynophobia;Virtual reality;Smartphone application;Virtual reality glasses;Remote controller},
    doi           = {10.1109/ICDAMT.2017.7905004},
    issn          = {},
    month         = {March}
}
@inproceedings{10536288,
    author        = {Pavanatto, Leonardo and Bowman, Doug A.},
    booktitle     = {2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Virtual Displays for Knowledge Work: Extending or Replacing Physical Monitors for More Flexibility and Screen Space},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {667--669},
    abstract      = {In this paper, we explore the potential of virtual displays in sup-porting knowledge work, focusing on scenarios where conventional physical monitors fall short. Our research investigates the feasibility and productivity costs of extending or replacing physical monitors with augmented and virtual reality displays. We present three com-pelling use cases, illustrating how virtual displays enhance flexibility, adaptability, and customization in remote and diverse work settings. Lessons learned from user studies highlight hardware and interface design challenges, emphasizing the need for larger resolution and field of view in head-worn displays (HWD). We conclude the paper with research opportunities and a call to address the evolving demands of knowledge work interfaces.},
    keywords      = {Productivity;Three-dimensional displays;Head-mounted displays;Focusing;Virtual reality;User interfaces;Hardware;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Mixed / augmented reality;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Empirical studies in interaction design},
    doi           = {10.1109/VRW62533.2024.00131},
    issn          = {},
    month         = {March}
}
@inproceedings{10783069,
    author        = {Shi, Jiaxin and Wu, Qi and Zhang, Di and Ye, Long},
    booktitle     = {2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Enhancing Immersion in Virtual Reality: Cost-Efficient Spatial Audio Generation for Panoramic Videos},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1224--1225},
    abstract      = {This paper describes a novel system for generating spatial audio using panoramic video content for home theater scenarios in 5.1.4 format. In virtual reality, spatial audio technology is an integral part that can greatly enhance the immersive experience. However, current virtual reality videos often lack a systematic approach to spatial audio production, and traditional spatial audio production methods are expensive and complex. To solve this problem, this system provides an efficient and cost-effective solution for audio producers to match audio with panoramic visual effects. Finally, this study provides a visual, intuitive and user-friendly user interface, which further enhances the ease of use of the system. Considering the human auditory properties, this system performs a series of optimizations in generating 5.1.4 spatial surround audio to enhance the listener's immersion.},
    keywords      = {Three-dimensional displays;Systematics;Conferences;Spatial audio;Production;Immersive experience;User interfaces;Visual effects;Optimization;Panoramic video;Spatial audio generation;5.1.4 channel;Auditory properties;Immersion},
    doi           = {10.1109/VRW62533.2024.10783069},
    issn          = {},
    month         = {March}
}
@inproceedings{9724729,
    author        = {Chen, Yin},
    booktitle     = {2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)},
    title         = {Human Behavior Recognition Based on Deep Learning},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {88--91},
    abstract      = {With the continuous advancement of technology, human behavior recognition, as an important scientific research in the field of computer vision, has important research in many fields such as intelligent surveillance, smart home, virtual reality. In the current complex environment, traditional manual methods have been difficult to meet the requirements of high recognition accuracy and applicability. The introduction of deep learning has brought new development directions for behavior recognition. This article mainly summarizes behavior recognition algorithms based on deep learning. Firstly, the research background and significance of behavior recognition are introduced, and then the traditional learning methods and deep learning methods of behavior recognition are discussed and analyzed respectively, and then the structure of algorithmic models and commonly used public data sets are introduced, and finally, the advantages and disadvantages of the various research directions of human behavior recognition methods based on deep learning are analyzed and some suggestions are given in the future research and expansion directions.},
    keywords      = {Deep learning;Seminars;Learning systems;Solid modeling;Surveillance;Virtual reality;Smart homes;Behavior Recognition;Deep Learning;Data Set;Structural Model},
    doi           = {10.1109/AINIT54228.2021.00027},
    issn          = {},
    month         = {Oct}
}
@inproceedings{9583784,
    author        = {Zhao, Jiayan and Simpson, Mark and Sajjadi, Pejman and Wallgr\"{u}n, Jan Oliver and Li, Ping and Bagher, Mahda M. and Oprean, Danielle and Padilla, Lace and Klippel, Alexander},
    booktitle     = {2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
    title         = {CrowdXR - Pitfalls and Potentials of Experiments with Remote Participants},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {450--459},
    abstract      = {Although the COVID-19 pandemic has made the need for remote data collection more apparent than ever, progress has been slow in the virtual reality (VR) research community, and little is known about the quality of the data acquired from crowdsourced participants who own a head-mounted display (HMD), which we call crowdXR. To investigate this problem, we report on a VR spatial cognition experiment that was conducted both in-lab and out-of-lab. The in-lab study was administered as a traditional experiment with undergraduate students and dedicated VR equipment. The out-of-lab study was carried out remotely by recruiting HMD owners from VR-related research mailing lists, VR subreddits in Reddit, and crowdsourcing platforms. Demographic comparisons show that our out-of-lab sample was older, included more males, and had a higher sense of direction than our in-lab sample. The results of the involved spatial memory tasks indicate that the reliability of the data from out-of-lab participants was as good as or better than their in-lab counterparts. Additionally, the data for testing our research hypotheses were comparable between in- and out-of-lab studies. We conclude that crowdsourcing is a feasible and effective alternative to the use of university participant pools for collecting survey and performance data for VR research, despite potential design issues that may affect the generalizability of study results. We discuss the implications and future directions of running VR studies outside the laboratory and provide a set of practical recommendations.},
    keywords      = {Crowdsourcing;Three-dimensional displays;Social networking (online);Resists;Cognition;Spatial databases;Reliability;Virtual reality;crowdsourcing;remote experiments;spatial cognition;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Empirical studies in HCI},
    doi           = {10.1109/ISMAR52148.2021.00062},
    issn          = {1554-7868},
    month         = {Oct}
}
@inproceedings{9419105,
    author        = {Adeniyi, Sam and Rosenberg, Evan Suma and Thomas, Jerald},
    booktitle     = {2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {RED: A Real-Time Datalogging Toolkit for Remote Experiments},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {601--602},
    abstract      = {The ability to conduct experiments on virtual reality systems has become increasingly compelling as the world continues to migrate towards remote research, affecting the feasibility of conducting in-person studies with human participants. The Remote Experiment Datalogger (RED) Toolkit is an open-source library designed to simplify the administration of remote experiments requiring continuous real-time data collection. Our design consists of a REST server, implemented using the Flask framework, and a client API for transparent integration with multiple game engines. We foresee the RED Toolkit serving as a building block for the handling of future remote experiments across a multitude of circumstances.},
    keywords      = {Three-dimensional displays;Conferences;Virtual reality;Games;User interfaces;Real-time systems;Libraries;Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Interaction paradigms;Virtual reality},
    doi           = {10.1109/VRW52623.2021.00183},
    issn          = {},
    month         = {March}
}
@article{8260856,
    author        = {Ghosh, Sarthak and Winston, Lauren and Panchal, Nishant and Kimura-Thollander, Philippe and Hotnog, Jeff and Cheong, Douglas and Reyes, Gabriel and Abowd, Gregory D.},
    journal       = {IEEE Transactions on Visualization and Computer Graphics},
    title         = {NotifiVR: Exploring Interruptions and Notifications in Virtual Reality},
    year          = {2018},
    volume        = {24},
    number        = {4},
    pages         = {1447--1456},
    abstract      = {The proliferation of high resolution and affordable virtual reality (VR) headsets is quickly making room-scale VR experiences available in our homes. Most VR experiences strive to achieve complete immersion by creating a disconnect from the real world. However, due to the lack of a standardized notification management system and minimal context awareness in VR, an immersed user may face certain situations such as missing an important phone call (digital scenario), tripping over wandering pets (physical scenario), or losing track of time (temporal scenario). In this paper, we present the results of 1) a survey across 61 VR users to understand common interruptions and scenarios that would benefit from some form of notifications; 2) a design exercise with VR professionals to explore possible notification methods; and 3) an empirical study on the noticeability and perception of 5 different VR interruption scenarios across 6 modality combinations (e.g., audio, visual, haptic, audio + haptic, visual + haptic, and audio + visual) implemented in Unity and presented using the HTC Vive headset. Finally, we combine key learnings from each of these steps along with participant feedback to present a set of observations and recommendations for notification design in VR.},
    keywords      = {Visualization;Haptic interfaces;Vibrations;Headphones;Virtual environments;Legged locomotion;Virtual Reality;Notifications;Interruptibility;Multi-Modal;Feedback;Context Awareness},
    doi           = {10.1109/TVCG.2018.2793698},
    issn          = {1941-0506},
    month         = {April}
}
@inproceedings{10972965,
    author        = {Rebelo, Ana Rita},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {[DC] Navigating Impossible Spaces in Virtual Reality For Seamless Walking Experiences in Small Physical Spaces},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {1588--1589},
    abstract      = {In Virtual Reality (VR), navigating small physical spaces often relies on handheld controllers, such as teleportation or joystick movement, due to the limited space available for walking. However, walking-based techniques can enhance immersion by enabling more natural movement. This position paper presents research that employs the concept of "impossible spaces" to enable walking in small physical spaces. Three room-connection techniques – portals, corridors, and central hubs – are used to create impossible spaces by overlapping and adapting multiple virtual areas, maximizing the use of limited physical space. Our previous user studies show that all three techniques are viable for connecting rooms in VR within a play area of about 2.5 x 2.5 meters. Portals provide a flexible solution, as they can be placed in the middle of a room; corridors offer a seamless and natural transition between spaces; and central hubs simplify navigation in complex layouts by creating a central room that connects to all other rooms. The primary contribution of this work is to make walking in VR accessible for all users by demonstrating how these room-connection techniques can dynamically adapt virtual environments to fit small physical spaces, such as those commonly available to VR users at home.},
    keywords      = {Legged locomotion;Meters;Three-dimensional displays;Navigation;Layout;Virtual environments;Aerospace electronics;User interfaces;Teleportation;Portals;Virtual reality;navigation;locomotion;impossible spaces},
    doi           = {10.1109/VRW66409.2025.00439},
    issn          = {},
    month         = {March}
}
@inproceedings{9978303,
    author        = {Sun, Winnie and Akhter, Rabia and Uribe-Quevedo, Alvaro and Presas, Daniel and Liscano, Ramiro and Horsburgh, Sheri},
    booktitle     = {2022 IEEE 10th International Conference on Serious Games and Applications for Health(SeGAH)},
    title         = {A Web and Nonimmersive VR Approach for Reminiscence Therapy: A Caregiver Perspective Comparison},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--8},
    abstract      = {Reminiscence therapy (RT) is a multi-sensory treatment that uses a combination of sight, touch, taste, smell, and sound to help persons with dementia (PWD) remember events, people, and places from their past lives. Currently, RT relies on in-person sessions where albums, memorabilia, and media such as pictures and music are brought by the caregivers. However, such sessions have been negatively impacted by physical distancing and restricted access to institutionalized facilities with the goal of reducing exposure and potential outbreaks. Due to such restrictions, digital technologies such as mobile applications and immersive solutions including virtual and augmented reality, have started gaining momentum as supplementary tools for RT. This paper presents a caregiver perspective comparative study between a web RT application and its nonimmersive Virtual Reality counterpart to understand the limitations and opportunities both platforms present for facilitating engaging experiences for people with dementia towards recalling memories while easing the therapy process for the caregivers.},
    keywords      = {Portable computers;Medical treatment;Tutorials;Media;Real-time systems;Physiology;Serious games;caregiver;people with dementia;long-term care facility;reminiscence therapy;virtual reality;web application},
    doi           = {10.1109/SEGAH54908.2022.9978303},
    issn          = {2573-3060},
    month         = {Aug}
}
@inproceedings{10494194,
    author        = {Tseng, Wen-Jie and Kontrazis, Petros Dimitrios and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
    booktitle     = {2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)},
    title         = {Understanding Interaction and Breakouts of Safety Boundaries in Virtual Reality Through Mixed-Method Studies},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {482--492},
    abstract      = {Virtual Reality (VR) technologies become ubiquitous, allowing people to employ immersive experiences in their homes. Since VR participants are visually disconnected from their real-world environment, commercial products propose safety boundaries to prevent colliding with their surroundings. However, there is a lack of empirical knowledge on how people perceive and interact with safety boundaries in everyday VR usage. This paper investigates this research gap with two mixed-method empirical studies. Study 1 reports an online survey (n=48) collecting data about attitudes towards safety boundaries, behavior while interacting with them, and reasons for breakout. Our analysis with open coding reveals that some VR participants ignored safety boundaries intentionally, even breaking out of them and continuing their actions. Study 2 investigates how and why VR participants intentionally break out when interacting close to safety boundaries and obstacles by replicating breakouts in a lab study (n=12). Our interview and breakout data discover three strategies, revealing VR participants sometimes break out of boundaries based on their real-world spatial information. Finally, we discuss improving future VR safety mechanisms by supporting participants' real-world spatial mental models using landmarks.},
    keywords      = {Surveys;Three-dimensional displays;Virtual reality;User interfaces;Aerospace electronics;Encoding;Safety;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Empirical studies in HCI},
    doi           = {10.1109/VR58804.2024.00069},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{10765159,
    author        = {Liu, Qianru and Li, Yue and Chen, Bingqing and Wu, Huiyue and Liang, Hai-Ning},
    booktitle     = {2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
    title         = {User-Defined Gesture Interactions for VR Museums: An Elicitation Study},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {633--642},
    abstract      = {Recognizing the potential of freehand gestures for interacting with virtual objects in virtual environments, our research introduces a user-defined freehand gesture set of typical referents in virtual reality (VR), focusing on a specific scenario: VR museums. We conducted a comprehensive elicitation study with two experiments to define and refine the gesture set. Meanwhile, we demonstrated an enhanced real-time Wizard of Oz approach that facilitated users' understanding of referents in VR and their gesture design. Our findings revealed significant improvements in gesture consistency and user agreement through two experiments, with an average agreement score of firstchoice and second-choice advancing from 0.211 and 0.160 to 0.412 and 0.284, respectively. By offering a consistent user-centered gesture set, this work contributes to guiding museum curators toward creating more immersive user experiences in VR museums. The gestures can also be extended to other VR applications that necessitate travel, selection and manipulation, and system control tasks.},
    keywords      = {Three-dimensional displays;Focusing;Virtual environments;Medical services;Aerospace electronics;User interfaces;Control systems;Museums;Real-time systems;Space exploration;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Humancentered computing-Human computer interaction (HCI)-HCI design and evaluation methods-User studies},
    doi           = {10.1109/ISMAR62088.2024.00078},
    issn          = {2473-0726},
    month         = {Oct}
}
@inproceedings{9515393,
    author        = {Takahashi, Nanami and Inamura, Tetsunari and Mizuchi, Yoshiaki and Choi, YongWoon},
    booktitle     = {2021 30th IEEE International Conference on Robot \& Human Interactive Communication (RO-MAN)},
    title         = {Evaluation of the Difference of Human Behavior between VR and Real Environments in Searching and Manipulating Objects in a Domestic Environment},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {454--460},
    abstract      = {It is important to evaluate and analyze human behaviors and reactions to build robots that can interact with people. While immersive virtual reality (VR) is one of the useful tools for the evaluation, it has been concerned that the human behavior may differ between VR and real environments due to the differences in cognitive characteristics. In this study, we investigated the differences in human behavior by focusing on common situations in the home environment; for example, a change in head position and posture is required when searching for an object (e.g., peeking motion) and when high accuracy is required when manipulating an object (e.g., placing an object on a shelf). We found that object manipulation requires accuracy which in turn, requires more time in the VR environment. In addition, the amount of change in head posture during object search and manipulation behavior was larger in the VR environment. Finally, we discuss the possibility of using the findings of this study to design robot competitions to assess the quality of human-robot interaction (HRI).},
    keywords      = {Focusing;Virtual reality;Tools;Search problems;Time measurement;Trajectory;Motion measurement},
    doi           = {10.1109/RO-MAN50785.2021.9515393},
    issn          = {1944-9437},
    month         = {Aug}
}
@inproceedings{8798191,
    author        = {Voinescu, Alexandra and Fodor, Liviu-Andrei and Fraser, Dana\"{e} Stanton and Mej\'{\i}as, Miguel and David, Daniel},
    booktitle     = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
    title         = {Exploring the Usability of Nesplora Aquarium, a Virtual Reality System for Neuropsychological Assessment of Attention and Executive Functioning},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {1207--1208},
    abstract      = {Virtual reality (VR) has proved to be an efficient alternative to traditional neuropsychological assessment. As VR has become more affordable, it is ready to break out of the laboratory and enter homes and clinical practices. We present preliminary findings from a study designed to evaluate self-reported usability of a VR test for neuropsychological assessment of attention and executive function.},
    keywords      = {Usability;Task analysis;Fish;Virtual reality;Human computer interaction;Visualization;Virtual reality;neuropsychological assessment;usability;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;HCI design and evaluation methods;Usability testing},
    doi           = {10.1109/VR.2019.8798191},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{11114142,
    author        = {Brambilla, Susanna and Ligabue, Marco and Abate, Simone and Boccignone, Giuseppe and Borghese, N. Alberto and Ripamonti, Laura A.},
    booktitle     = {2025 IEEE Conference on Games (CoG)},
    title         = {Virtual Reality Game-Based Classification of Arachnophobia: A Two-Step Clustering Approach},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {1--8},
    abstract      = {Fear is a multifaceted emotion, challenging to define and assess accurately. Biologically, it is an innate response to threats, whereas psychologically, it is shaped by individual experiences and societal influences, sometimes evolving into specific phobias. One such phobia, arachnophobia (the fear of spiders), is particularly widespread and can vary widely in intensity among individuals. This paper presents a prototypal system that classifies the severity of arachnophobia using Machine Learning (ML) algorithms within a Virtual Reality (VR) game-based environment. The proposed system utilizes a two-stage clustering approach to analyze the behavioral data collected during VR exposure. Additionally, participants' self-reported fear levels are measured using the Spider Phobia Questionnaire (SPQ), to provide a comprehensive assessment. Preliminary results suggest that this method could be effectively used to classify arachnophobia intensity level, thus offering potential applications in both clinical settings and video games.},
    keywords      = {Video games;Machine learning algorithms;Psychology;Clustering algorithms;Virtual reality;Machine learning;Games;Particle measurements;Biology;Classification algorithms;Arachnophobia;Virtual Reality;Clustering;Be-havioral Approach Test},
    doi           = {10.1109/CoG64752.2025.11114142},
    issn          = {2325-4289},
    month         = {Aug}
}
@inproceedings{8797971,
    author        = {Gunkel, Simon N.B and Dohmen, Marleen D.W. and Stokking, Hans and Niamut, Omar},
    booktitle     = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
    title         = {360-Degree Photo-realistic VR Conferencing},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {946--947},
    abstract      = {VR experiences are becoming more social, but many social VR systems represent users as artificial avatars. For use cases such as VR conferencing, photo-realistic representations may be preferred. In this paper, we present ongoing research into social VR experiences with photo-realistic representations of participants and present a web-based social VR framework that extends current video conferencing capabilities with new VR functionalities. We explain the underlying design concepts of our framework and discuss user studies to evaluate the framework in three different scenarios. We show that people are able to use VR communication in real meeting situations and outline our future research to better understand the actual benefits and limitations of our approach, to fully understand the technological gaps that need to be bridged and to better understand the user experience.},
    keywords      = {Cameras;Three-dimensional displays;User experience;Resists;Face;Avatars;Virtual Reality;VR;Social VR;VR Conferencing;WebRTC;WebVR;Immersive Virtual Environments;Information systems--World Wide Web--Web conferencing;Information systems--Multimedia information systems--Multimedia streaming},
    doi           = {10.1109/VR.2019.8797971},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{11155462,
    author        = {McIntyre, Lara E. and Gilardi, Marco},
    booktitle     = {2025 International Conference on Software, Knowledge, Information Management \& Applications (SKIMA)},
    title         = {A User Study on Deaf Individuals in VR Social Spaces - The Emergence of the VR Sign Language},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {Deaf individuals often isolate themselves due to living in a predominately hearing world where there is a lack of deaf awareness and knowledge of their native language – sign language. As a result, some communities of deaf individuals have turned to social virtual reality platforms to escape and meet others around the world using sign language communication. However, because sign language encompasses many components, including hand gestures, facial expressions, lip patterns, and body language, current VR technologies make it difficult for individuals to fully express themselves in sign language. This ongoing study adopts a human-centred research approach to understand the experiences of the deaf community in virtual reality. In this work-in-progress paper we present initial results from a user need analysis with deaf VR users, which suggest that current VR technologies lack in providing deaf individuals with the ability to use their native language sign language, and the emergence of a new sign language for use in VR – the virtual reality sign language, which we are the first to report about. Moreover, we present initial low-fidelity prototypes of virtual spaces where deaf people can socialise and an initial evaluation of the design of such spaces.},
    keywords      = {Hands;Sign language;Lips;Prototypes;Virtual reality;Auditory system;deaf people;virtual reality;virtual reality sign language;user need analysis},
    doi           = {10.1109/SKIMA66621.2025.11155462},
    issn          = {},
    month         = {June}
}
@inproceedings{9090528,
    author        = {Dinechin, Gr\'{e}goire Dupont de and Paljic, Alexis},
    booktitle     = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {From Real to Virtual: An Image-Based Rendering Toolkit to Help Bring the World Around Us Into Virtual Reality},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {348--353},
    abstract      = {The release of consumer-grade head-mounted displays has helped bring virtual reality (VR) to our homes, cultural sites, and work-places, increasingly making it a part of our everyday lives. In response, many content creators have expressed renewed interest in bringing the people, objects, and places of our daily lives into VR, helping push the boundaries of our ability to transform photographs of everyday real-world scenes into convincing VR assets. In this paper, we present an open-source solution we developed in the Unity game engine as a way to make this image-based approach to virtual reality simple and accessible to all, to encourage content creators of all kinds to capture and render the world around them in VR. We start by presenting the use cases of image-based virtual reality, from which we discuss the motivations that led us to work on our solution. We then provide details on the development of the toolkit, specifically discussing our implementation of several image-based rendering (IBR) methods. Finally, we present the results of a preliminary user study focused on interface usability and rendering quality, and discuss paths for future work.},
    keywords      = {Rendering (computer graphics);Tools;Cameras;Virtual reality;Games;Three-dimensional displays;Engines;Computing Methodologies;Computer Graphics;Graphics Systems and Interfaces;Virtual Reality;Computing Methodologies;Computer Graphics;Image Manipulation;Image-Based Rendering},
    doi           = {10.1109/VRW50115.2020.00076},
    issn          = {},
    month         = {March}
}
@inproceedings{10467403,
    author        = {Ikhsan, Ridho Bramulya and Prabowo, Hartiwi and Bangapadang, Stephanie and Gui, Anderes and Fernando, Yudi and Prasarry, Yudhita Valen},
    booktitle     = {2023 6th International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)},
    title         = {Implementation of Virtual Reality on Housing Purchase Intentions: An Empirical Study},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {153--157},
    abstract      = {The integration of virtual reality technology in the property industry facilitates the provision of real-time information to prospective buyers. Consequently, the purpose of this investigation is to ascertain the influence of interactivity and virtuality on the augmentation of informativeness. Moreover, it also seeks to establish the impact of interactivity and informativeness on the desire to purchase a property from a housing development corporation. Quantitative methodologies were implemented to address the research hypotheses. A web-based survey was administered to a total of 402 selected participants residing in the Greater Jakarta area. The acquired survey data was subsequently subjected to statistical Structural Equation Modeling analysis based on variance. This study has corroborated the acceptance of all hypotheses posited. Interactivity and virtuality exhibit a positive and significant influence on informativeness. Furthermore, informativeness and interactivity have a positive and significant effect on purchase intention. The findings derived from this analysis offer valuable insights for housing developers, encouraging them to enhance the utilization of virtual reality technology in order to expand the range of available housing options.},
    keywords      = {Surveys;Industries;Seminars;Solid modeling;Virtual reality;Mathematical models;Real-time systems;Interactivity;Virtuality;Informativeness;Purchase Intention;Virtual Reality;Property Industry},
    doi           = {10.1109/ISRITI60336.2023.10467403},
    issn          = {2832-1456},
    month         = {Dec}
}
@inproceedings{9658583,
    author        = {Kannan, Shyam Sundar and Min, Byung-Cheol},
    booktitle     = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
    title         = {Investigation on Accepted Package Delivery Location: A User Study-based Approach},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1829--1835},
    abstract      = {The delivery of packages using robots is emerging and getting common day-to-day. However, currently robots can only deliver packages either far away from the home or at a random location in front of the door. This is because there is no consensus on where to deliver the package around the house that will be liked by the recipient. Therefore, with the ultimate goal of the development of intelligent delivery robots in the future, we conducted a user study where the participants were asked to place packages around a house in a simulated environment through virtual reality at a location of their choice. The participants were asked to deliver packages in six different scenarios that were created based on the common setups seen in the real world. The findings indicated that the participants either prefer the package to be easily visible right in front of the door or at a partially hidden location that is secure and avoids theft. The preferences of the participants were also seen that they depend on other factors like the objects present in the delivery site and the neighborhood. We expect that these findings can open the door to further research on delivery robots in their perception and cognition abilities to deliver packages to desired locations by human recipients.},
    keywords      = {Heating systems;Conferences;Virtual reality;Cognition;Interviews;Robots;Cybernetics},
    doi           = {10.1109/SMC52423.2021.9658583},
    issn          = {2577-1655},
    month         = {Oct}
}
@inproceedings{9757615,
    author        = {Kiarostami, Mohammad Sina and Visuri, Aku and Hosio, Simo},
    booktitle     = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {We Are Oulu: Exploring Situated Empathy through a Communal Virtual Reality Experience},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {966--967},
    abstract      = {In this research, we explore and measure situated empathy. We focus on the hardships of an international community in a foreign country using a virtual reality experiment. Our aim is to facilitate a better understanding of an international community's quality of life and unique difficulties in a society. To this end, we designed a VR experiment with three main stages: data collection, a pre-experiment questionnaire and a post-experiment questionnaire with a concluding interview.},
    keywords      = {Three-dimensional displays;Conferences;Virtual reality;User interfaces;Data collection;Interviews},
    doi           = {10.1109/VRW55335.2022.00334},
    issn          = {},
    month         = {March}
}
@inproceedings{8942250,
    author        = {Nguyen, Vinh T. and Jung, Kwanghee and Dang, Tommy},
    booktitle     = {2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
    title         = {DroneVR: A Web Virtual Reality Simulator for Drone Operator},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {257--2575},
    abstract      = {In recent years, Unmanned Aerial Vehicle (UAV) has been used extensively in various applications from entertainment, virtual tourism to construction, mining, agriculture. Navigation, path planning, and image acquisition are the main tasks in administering these aerial devices in accordance with real-time object tracking for affordable aerial vehicles. Aircraft crash is one of the most critical issues due to the uncontrolled environment and signal loss that cause the aerial vehicle to hit the buildings on its returning mode. Furthermore, real-time image processing, such as object tracking, has not yet been exploited for a low-cost aerial vehicle. This paper proposes a prototype embedded in a Web-based application called DroneVR to mitigate the aforementioned issues. The virtual reality environment was reconstructed based on the real-world fly data (OpenStreetMap) in which path planning and navigation were carried out. Gaussian Mixture Model was used to extract foreground and detect a moving object, Kalman Filter method was then applied to predict and keep track of object's motion. Perceived ease of use was investigated with a small sample size users to improve the simulator.},
    keywords      = {Drones;Three-dimensional displays;Buildings;Path planning;Navigation;Solid modeling;Virtual reality;UAV, Virtual reality, Drone crash, 3D simulator, Openstreetmap, Path planning},
    doi           = {10.1109/AIVR46125.2019.00060},
    issn          = {},
    month         = {Dec}
}
@inproceedings{8673218,
    author        = {Inamura, Tetsunari and Mizuchi, Yoshiaki},
    booktitle     = {2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
    title         = {Robot Competition to Evaluate Guidance Skill for General Users in VR Environment},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {552--553},
    abstract      = {Robot competition such as RoboCup\@Home is one of the most effective ways to evaluate the performance of human-robot interaction; however, it takes a lot of costs for real robot maintenance and the practice of evaluation sessions. We have proposed a simulation software to evaluate human-robot interaction in daily life environment based on immersive virtual reality. In this paper, we design a task named `human navigation' in which the evaluation requires a subjective impression by the users. Through a substantiative experiment, we confirmed that the proposed task and system reduced the cost for the practice of the competition.},
    keywords      = {Robots;Task analysis;Human-robot interaction;Software;Solid modeling;Navigation;Natural languages;Natural Language Generation;Guidance;Robot Competition},
    doi           = {10.1109/HRI.2019.8673218},
    issn          = {2167-2148},
    month         = {March}
}
@inproceedings{10628823,
    author        = {Bazhanov, Alexander and Landhaeusser, Veronika and Kammler-S\"{u}cker, Kornelius and Lenz, Bernd and Meixner, Gerrit},
    booktitle     = {2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)},
    title         = {A Gamified Approach for Alcohol Use Disorder Therapy in Virtual Reality},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {436--445},
    abstract      = {In the therapy of alcohol use disorder, cue-exposure therapy is an established therapeutical approach to generate cravings in patients. A short-coming of traditional cue-exposure is that the environment of the therapy is not similar to the environment of consumption for the patient. The introduction of virtual reality has the potential to fix this short-coming, as virtual reality is an immersive technology where virtual environments can be presented to the user. In this paper, a prototype and a feasibility study are presented where virtual reality is combined with gamification to immerse the patient into environments where urges can be created and, through gamification, increase the motivation and help learning new behaviors for the patient. In the following study, 8 participants who are in therapy for alcohol use disorder tested and evaluated the prototype through a structured questionnaire and unstructured commentary. The results show that (1) the use of gamification increased the motivation and enjoyment of the participants, (2) the virtual environments and the specific tasks were seen as immersive and realistic, and (3) an urge for consumption was generated in some of the participants after using the prototype.},
    keywords      = {Medical treatment;Prototypes;Virtual environments;Task analysis;Informatics;gamification;alcohol use disorder;virtual reality;cue-exposure therapy;approach-avoidance;substance abuse},
    doi           = {10.1109/ICHI61247.2024.00062},
    issn          = {2575-2634},
    month         = {June}
}
@inproceedings{8956463,
    author        = {Petrak, Bjorn and Weitz, Katharina and Aslan, Ilhan and Andre, Elisabeth},
    booktitle     = {2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
    title         = {Let Me Show You Your New Home: Studying the Effect of Proxemic-awareness of Robots on Users' First Impressions},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {1--7},
    abstract      = {First impressions play an important part in social interactions, establishing the foundation of a person's opinion about their counterparts. Since interpersonal communication is essentially multimodal, people are judged during first encounters by both their verbal utterances and nonverbal behavior, such as how they utilize eye contact, body distance, and body orientation. In this paper, we argue that robots would provide better user experiences, including being perceived as more likable if they were able to make a good first impression when introduced to a new home. Moreover, we wanted to test if robots can improve their perceived impression by behaving in a proxemic-aware manner; i.e., by following established social norms, which prescribe, for example how far people should position themselves around other objects to improve the facilitation of social interactions. In order to test this hypothesis, we conducted a user study with 16 participants in a virtual reality setting, comparing the impression of two agents being introduced to their new homes by users. We found that the proxemic-aware agent was indeed perceived as significantly better considering multiple constructs, including perceived anthropomorphism and trustworthiness.},
    keywords      = {Atmospheric measurements;Virtual reality;Particle measurements;Anthropomorphism;Robots},
    doi           = {10.1109/RO-MAN46459.2019.8956463},
    issn          = {1944-9437},
    month         = {Oct}
}
@inproceedings{9316088,
    author        = {Han, Chao},
    booktitle     = {2020 3rd International Conference on Intelligent Sustainable Systems (ICISS)},
    title         = {Three-Dimensional Architectural Modeling and Decoration Design System based on Virtual Reality},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {974--977},
    abstract      = {Three-dimensional architectural modeling and the decoration design system based on virtual reality is presented in this article. With the continuous development of intelligent building, the design of home intelligent integrated wiring system will become the trend of social development in the future, and gradually accepted by people. It is believed that in the next few years, a home intelligent system with stable operation, integrated system, functional use, humanized operation and individualized application will play an extraordinary role in people's life. The key of virtual reality technology is virtual scene modeling, that is, the construction of virtual world, because the quality of virtual world modeling is the key to produce immersion. This paper defines the novel pattern for the decoration design system with the data analysis and computer system. The experiment results have shown that the proposed model has satisfactory results.},
    keywords      = {Solid modeling;Virtual reality;Data models;Information technology;Conferences;Computational modeling;Art;Three-dimensional analysis;architectural modeling;decoration design;virtual reality;data modelling},
    doi           = {10.1109/ICISS49785.2020.9316088},
    issn          = {},
    month         = {Dec}
}
@inproceedings{7776347,
    author        = {Bruun-Pedersen, Jon Ram and Serafin, Stefania and Kofoed, Lise Busk},
    booktitle     = {2016 IEEE International Conference on Healthcare Informatics (ICHI)},
    title         = {Going Outside While Staying Inside -- Exercise Motivation with Immersive vs. Non–immersive Recreational Virtual Environment Augmentation for Older Adult Nursing Home Residents},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {216--226},
    abstract      = {Virtual technology and immersive experiences are not very often associated with older adults. Recent studies suggest that exercise augmentation using flat screen-based virtual environments, which allow nursing home residents to experience virtual places different from the nursing home, can increase the intrinsic motivation of nursing home residents. In this paper, we increase the immersive properties of such augmentation through an Oculus Rift Head Mounted Display, to evaluate the effect on the older adults' sense of presence, if it has any relation to the level of intrinsic motivation to exercise, and an effect of the exercise user experience. A small sample size makes this a feasibility study. Results suggest HMD displays for immersive VR experiences applicable to nursing home users but not the particular exercise purpose.},
    keywords      = {Medical services;Resists;Virtual environments;Visualization;Atmospheric measurements;Particle measurements;Older adults;exercise;motivation;virtual environments;augmentation;presence;immersion},
    doi           = {10.1109/ICHI.2016.31},
    issn          = {},
    month         = {Oct}
}
@article{8821384,
    author        = {Han, Ping-Hsuan and Chen, Yang-Sheng and Liu, Iou-Shiuan and Jang, Yu-Ping and Tsai, Ling and Chang, Alvin and Hung, Yi-Ping},
    journal       = {IEEE Computer Graphics and Applications},
    title         = {A Compelling Virtual Tour of the Dunhuang Cave With an Immersive Head-Mounted Display},
    year          = {2020},
    volume        = {40},
    number        = {1},
    pages         = {40--55},
    abstract      = {The Dunhuang Caves are the home to the largest Buddhist art sites in the world and are listed as a UNESCO World Heritage Site. Over time, the murals have been damaged by both humans and nature. In this article, we present an immersive virtual reality system for exploring spatial cultural heritage, which utilizes the digitized data from the Dunhuang Research Academy to represent the virtual environment of the cave. In this system, the interaction techniques that allow users to flexibly experience any of the artifacts or displays contribute to their understanding of the cultural heritage. Additionally, we evaluated the system by conducting a user study to examine the extent of user acquaintance after the entire experience. Our result has shown what participants learn from the spatial context and augmented information in the VR. This can be used as design considerations for developing other spatial heritages.},
    keywords      = {Cultural differences;Image restoration;Three-dimensional displays;Head-mounted displays;Navigation;Art;Image color analysis},
    doi           = {10.1109/MCG.2019.2936753},
    issn          = {1558-1756},
    month         = {Jan}
}
@inproceedings{8710926,
    author        = {Putra, Hanif Fermanda and Ogata, Kohichi},
    booktitle     = {2018 International Conference on Computer Engineering, Network and Intelligent Multimedia (CENIM)},
    title         = {Development of Eye-Gaze Interface System and Its Application to Virtual Reality Controller},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {208--213},
    abstract      = {Eye-gaze tracking systems are a type of human-machine interface application. These systems have been widely applied in many fields, such as medical, interface systems, and studies on human behavior. In this study, an eye-gaze tracking system is designed to control the view of a virtual reality application. As is generally known, gyroscopes and game controllers are popular devices to control the view of virtual reality applications. To control the view of a virtual reality application, we measure the vertical and horizontal movements of the eye-gaze. Using ring-shaped pattern matching, we find the position of the iris and estimate the direction of the eye-gaze. The vertical and horizontal movement of the eye-gaze are transformed into the rotation of virtual reality camera view in the x and y axes, respectively. The ease of use of the system was evaluated in terms of the distance traveled by the user and the time taken to complete the task.},
    keywords      = {Virtual reality;Cameras;Iris;Image color analysis;Games;Pattern matching;Lenses;eye-gaze;tracking;interface;virtual reality},
    doi           = {10.1109/CENIM.2018.8710926},
    issn          = {},
    month         = {Nov}
}
@inproceedings{10972759,
    author        = {Sato, Yushi and Iwai, Daisuke and Sato, Kosuke},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Shadow Effects for Representing Hovering-and-Contact States of a Projected Hand in Spatial Augmented Reality},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {790--794},
    abstract      = {By projecting a user-controllable computer graphics (CG) hand into real-world space, users can interact with out-of-reach objects by pointing or touching them using the projected CG hand (referred to as the projected hand). However, due to the nature of projection, the projected hand cannot appear to hover in mid-air. This study proposes a method that represents a shadow of the projected hand and dynamically alters its appearance based on user input. This allows users to perceive whether the projected hand is hovering or in contact with an object. A user study suggests that the proposed shadow effect effectively enhances the perception of the projected hand's hovering state.},
    keywords      = {Hands;Three-dimensional displays;Conferences;Spatial augmented reality;Virtual reality;User interfaces;Human augmentation;Spatial augmented reality;human augmentation;projected hand;virtual hand illusion},
    doi           = {10.1109/VRW66409.2025.00160},
    issn          = {},
    month         = {March}
}
@inproceedings{8493444,
    author        = {Eckstein, Benjamin and Krapp, Eva and Lugrin, Birgit},
    booktitle     = {2018 10th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)},
    title         = {Towards Serious Games and Applications in Smart Substitutional Reality},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {1--8},
    abstract      = {Substitutional Reality (SR), the integration of the physical environment into Virtual Reality (VR), is a novel approach to facilitate and intensify the use of home-based VR systems. We propose to extend the passive haptics of SR with the interactive functionality of a smart home environment. This concept of smart SR is meant as a foundation for serious games and applications. In this paper, we describe the concept behind smart SR as well as the prototype in our lab environment. We created multiple virtual environments with a varying degree of mismatch regarding the real world. We present a user study where we examined the influence of these environments on the perceived sense of presence and motivation of users. Our findings showed that presence was high in all conditions while motivation increased with the level of mismatch. This provides us with a promising basis for further research.},
    keywords      = {Games;Smart devices;Haptic interfaces;Smart homes;Virtual environments;Medical treatment},
    doi           = {10.1109/VS-Games.2018.8493444},
    issn          = {2474-0489},
    month         = {Sep.}
}
@inproceedings{9547069,
    author        = {Pathak, Rishabh and Simiscuka, Anderson Augusto and Muntean, Gabriel-Miro},
    booktitle     = {2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)},
    title         = {An Adaptive Resolution Scheme for Performance Enhancement of a Web-based Multi-User VR Application},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {Over the last few years, several frameworks have been introduced to help developers build virtual reality (VR) experiences for the web. One such open-source web framework is the A-Frame framework, which is built on top of WebXR and Three.js. A-Frame can be used to create 3D scenes that can be rendered using compatible browsers such as Chrome and Firefox. The performance of web-based VR applications, however, can be affected due to the limitations of the CPU and GPU, especially in multi-user applications. In this paper, an A-Frame-based multiuser VR application is developed and the performance is analyzed under different scenarios, demonstrating how an increase in the number of users affects metrics related to VR quality of experience (QoE). Then, an Adaptive Resolution Scheme for VR (ARS-VR) is proposed, which improves the VR performance in terms of frame rate and frame latency on remote devices with limited processing and display features.},
    keywords      = {Performance evaluation;Three-dimensional displays;Graphics processing units;Virtual reality;Broadcasting;Browsers;Broadband communication;VR;WebXR;A-Frame;Three.js;frame rate;resolution;adaptation},
    doi           = {10.1109/BMSB53066.2021.9547069},
    issn          = {2155-5052},
    month         = {Aug}
}
@inproceedings{10445539,
    author        = {Zhang, Yunhao and Weiss, Tomer},
    booktitle     = {2024 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)},
    title         = {Crowd-sourced Evaluation of Combat Animations},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {60--65},
    abstract      = {Combat sequences are commonly seen in films, animated media, and video games. Although significant advancements have led to the creation of extensive online collections of these animations, selecting suitable motions for specific uses remains challenging because of their dynamic characteristics. This dynamism and perceptual complexity stem from stylized combat scenes' diverse physical and aesthetic elements. This paper introduces a novel methodology to comprehend user preferences in combat animations with a crowd-sourced learning strategy. We deduce user preferences towards certain motion attributes, which are not easily identifiable through raw geometric data. Our study primarily focuses on sword fighting, which is widely popular in combat scenes.},
    keywords      = {Video games;Films;Dynamics;Virtual reality;Learning (artificial intelligence);Media;Animation;animation;statistical learning},
    doi           = {10.1109/AIxVR59861.2024.00015},
    issn          = {2771-7453},
    month         = {Jan}
}
@article{10753078,
    author        = {Hirobe, Daichi and Shirai, Shizuka and Orlosky, Jason and Alizadeh, Mehrasa and Kobayashi, Masato and Uranishi, Yuki and Ratsamee, Photchara and Takemura, Haruo},
    journal       = {IEEE Transactions on Games},
    title         = {User-Centric Locomotion Techniques for Virtual Reality Games: A Survey of User Needs and Issues},
    year          = {2025},
    volume        = {17},
    number        = {2},
    pages         = {460--473},
    abstract      = {Virtual reality (VR) video games that are played on a VR headset are becoming increasingly common in households, and though many games require players to navigate vast virtual spaces, most homes cannot provide a large enough physical space to encompass the entire virtual space. Thus, VR video games that require locomotion often provide users with alternative locomotion techniques. While teleportation or steering is typically used as a standard, new techniques can overcome remaining problems, such as motion sickness. However, a holistic perspective of user needs and issues regarding these techniques in practical situations has not been studied on a broad basis. To address this gap in the literature and contribute to future VR video game development and research, we conducted 16 semi-structured interviews and surveyed 88 participants to help explore issues regarding existing locomotion techniques. Our results revealed preferences related to teleportation versus steering and the postures that users adopt while playing VR video games, along with user needs for locomotion techniques in each posture.},
    keywords      = {Video games;Teleportation;Games;Legged locomotion;Surveys;Interviews;Motion sickness;User experience;Space exploration;Navigation;Empirical study;games;locomotion;steering;teleportation;virtual reality (VR);needfinding},
    doi           = {10.1109/TG.2024.3498325},
    issn          = {2475-1510},
    month         = {June}
}
@inproceedings{7776409,
    author        = {Li, Xuan and Jolani, Nina and Dao, Thien-Tien and Jimison, Holly},
    booktitle     = {2016 IEEE International Conference on Healthcare Informatics (ICHI)},
    title         = {Serenity: A Low-Cost and Patient-Guided Mobile Virtual Reality Intervention for Cancer Coping},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {504--510},
    abstract      = {Medical procedures often induce physical pain and psychological distress. Cancer patients are particularly vulnerable to fatigue, heightened emotional distress, social isolation, and increased risk of depression, severely reducing quality of life and potential treatment non-adherence and prolonged hospital stays. Leveraging emerging virtual reality (VR) technology, we prototyped Serenity: a mobile smartphone-based VR cancer coping intervention informed by distraction therapy to help alleviate the symptoms of coping and promote patient empowerment. It leverages emerging low-cost VR to improve accessibility and effectiveness of distraction therapy. We describe the results of a preliminary usability study and lessons learned that apply to future design and evaluation of virtual reality interventions for behavioral health.},
    keywords      = {Cancer;Medical treatment;Virtual reality;Resists;Smart phones;Color;Usability;Virtual Reality;Usability;Cancer therapy;Mobile health;Home health;Stress management;User-centered design},
    doi           = {10.1109/ICHI.2016.91},
    issn          = {},
    month         = {Oct}
}
@article{9727109,
    author        = {Zheng, Mengya and Pan, Xingyu and Bermeo, Nestor Velasco and Thomas, Rosemary J. and Coyle, David and O'hare, Gregory M. P. and Campbell, Abraham G.},
    journal       = {IEEE Access},
    title         = {STARE: Augmented Reality Data Visualization for Explainable Decision Support in Smart Environments},
    year          = {2022},
    volume        = {10},
    number        = {},
    pages         = {29543--29557},
    abstract      = {The Internet of Things (IoT) provides unprecedented opportunities for the access to and conflation of a myriad of heterogeneous data to support real-time decision-making within smart environments. Augmented Reality (AR) is on cusp of becoming mainstream and will allow for the ubiquitous visualization of IoT derived data. Such visualization will simultaneously permit the cognitive and visual binding of information to the physical object(s) to which they pertain. Important questions exist as to how one can efficiently filter, prioritize, determine relevance and adjudicate on individual information needs in support of real-time decision making. To this end, this paper proposes a novel AR decision support framework (STARE) to support immediate decisions within a smart environment by augmenting the user's focal objects with assemblies of semantically relevant IoT data and corresponding suggestions. In order to evaluate this technique, a remote user study was undertaken within a simulated smart home environment. The evaluation results demonstrate that the proposed Semantic Augmented Reality decision support framework leads to a reduction in information overloading and enhanced effectiveness, both in terms of IoT data interpretation and decision support.},
    keywords      = {Data visualization;Semantics;Decision support systems;Visualization;Smart homes;Decision making;Data models;Augmented reality;smart environment;decision support;semantic annotations;ubiquitous computing},
    doi           = {10.1109/ACCESS.2022.3156697},
    issn          = {2169-3536},
    month         = {}
}
@inproceedings{10972969,
    author        = {Zhao, Di Bill and Stuerzlinger, Wolfgang},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {A Novel Bare-Handed Manipulation Technique for Distant Objects in Virtual Reality},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {353--360},
    abstract      = {Manipulating distant 3D objects in virtual reality (VR) with bare hands remains a challenge despite advancements in hand-tracking technology. We introduce the Two-Hand Fingertip-Palm (THFP) technique, which extends the interactive zone to the entire non-dominant hand to manipulate distant objects precisely. A user study comparing THFP to a bare-hand variant of HOMER (BHOMER) revealed that THFP achieves 75\% greater accuracy, particularly in complex tasks like hanging a painting on a slanted wall, though it is 47\% slower. THFP also received higher usability ratings (SUS) and reduced cognitive and physical demands (NASA-TLX), highlighting its user-centric design. These findings demonstrate THFP's potential for improving distant object manipulation in VR.},
    keywords      = {Hands;Three-dimensional displays;Accuracy;Conferences;Virtual reality;User interfaces;User experience;Usability;Painting;Hand tracking;Virtual reality;Distant object manipulation},
    doi           = {10.1109/VRW66409.2025.00083},
    issn          = {},
    month         = {March}
}
@inproceedings{11132042,
    author        = {Vlahovi\'{c}, S. and Moslavac, M. and Mi\v{s}ura, K. and Boban, L. and Jovi\'{c}, A. and Su\v{z}njevi\'{c}, M.},
    booktitle     = {2025 MIPRO 48th ICT and Electronics Convention},
    title         = {Usability and User Experience Evaluation of a Multiplatform House Design Pipeline: Navigating Web, VR, and Mobile AR Workflows},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {1546--1551},
    abstract      = {For decades, Computer-Aided Design (CAD) software has been central to planning and modeling in Architecture, Engineering, and Construction (AEC). More recently, the emergence of Augmented Reality (AR) and Virtual Reality (VR) technologies has transformed how users interact with 3D home designs, enabling innovative ways to create, visualize, and refine living spaces. Combining the usability of desktop applications with the immersive capabilities of AR and VR creates a streamlined multiplatform pipeline, though it also introduces challenges in evaluating usability and User Experience (UX) due to the diverse devices, interaction paradigms, and varying levels of user technological proficiency. This paper examines a multiplatform system that includes a web application for house design, a mobile AR application for on-site exterior visualization, as well as a VR application to explore and adjust life-size interiors. We discuss our process of iterative usability testing and collecting meaningful UX feedback in this context. Furthermore, we provide a high-level summary of the results from two user studies, highlighting participants' impression of the system and its components, as well as insights from the perspective of study administrators.},
    keywords      = {Solid modeling;Design automation;Computational modeling;Pipelines;Data visualization;User experience;Iterative methods;Usability;Augmented reality;Testing;Computer-aided design;building information modeling;augmented reality;virtual reality;extended reality;usability;user experience;quality of experience},
    doi           = {10.1109/MIPRO65660.2025.11132042},
    issn          = {1847-3938},
    month         = {June}
}
@inproceedings{10765108,
    author        = {Zhang, Xiaolu and Rafi, Tahmid and Guan, Yuejun and Li, Shuqing and Lyu, Michael R.},
    booktitle     = {2024 39th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)},
    title         = {Demystifying the Privacy-Realism Dilemma in the Metaverse},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {245--250},
    abstract      = {Metaverse is a form of next-generation human-computer interaction, integrating Virtual and Augmented Reality to create immersive social experiences. However, the inherent expansion of human-computer interfaces in the Metaverse inevitably expands the interface of potential privacy leaks. There exists a dilemma between providing a realistic user experience and mitigating the elevated privacy risks that accompany it. Such dilemma remains underexplored by both industry and academia, despite their significant investments in developing applications and enhancing user experiences. In this study, we systematically examine this dilemma across different Metaverse usage scenarios and perform a study involving 177 users to understand the factors that may affect users' decision making. Our findings reveal that user preferences regarding realism and privacy protection vary significantly depending on the context of usage scenarios. We expect our study results can provide some insights and guidance for the design of privacy protection mechanisms in Metaverse platforms and applications.},
    keywords      = {Human computer interaction;Industries;Privacy;Metaverse;Decision making;User experience;Protection;Next generation networking;Software engineering;Investment;metaverse;privacy;user study},
    doi           = {},
    issn          = {2151-0849},
    month         = {Oct}
}
@inproceedings{10220810,
    author        = {Upadhyay, Kosha},
    booktitle     = {2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)},
    title         = {MemSpark: An Artificially Intelligent Virtual Reality System for Non-Intrusive Cognition Therapy and Evaluation of Dementia},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {114--121},
    abstract      = {Dementia will become an epidemic with cases projected to grow from 55 million to 153 million by 2050. Despite such severity, mainstream therapeutic options fail to affect progression as most are symptomatic, invasive, or ineffective. This research explored a novel virtual reality based therapy that can exercise all cognitive functions to slow dementia progression. Improvements in cognition were measured using three aggregate behavioral biomarkers: recall, reasoning, and executive function. An artificial neural network was developed to compute dementia profiles aligned to the ADAS-Cog test. Trials conducted across 14 people with dementia (PwD) over six months indicated 60\% slower rate of deterioration among the experimental group. The Prolonged Life Expectancy metric analysis suggested that this therapy could double the time PwDs have before reaching significant cognitive impairment. This cognition therapy has the potential to replace mainstream therapies such as tDCS and CCT and eliminate dependency on dementia experts to enable in-home care.},
    keywords      = {Neuroplasticity;Measurement;Costs;Sociology;Medical treatment;Virtual reality;Cognition;Dementia;Profiling;Virtual Reality;Cognition Therapy;Artificial Intelligence;Transfer Learning},
    doi           = {10.1109/ICIRCA57980.2023.10220810},
    issn          = {},
    month         = {Aug}
}
@article{9714054,
    author        = {Kelly, Jonathan W. and Hoover, Melynda and Doty, Taylor A. and Renner, Alex and Zimmerman, Moriah and Knuth, Kimberly and Cherep, Lucia A. and Gilbert, Stephen B.},
    journal       = {IEEE Transactions on Visualization and Computer Graphics},
    title         = {Remote research on locomotion interfaces for virtual reality: Replication of a lab-based study on teleporting interfaces},
    year          = {2022},
    volume        = {28},
    number        = {5},
    pages         = {2037--2046},
    abstract      = {The wide availability of consumer-oriented virtual reality (VR) equipment has enabled researchers to recruit existing VR owners to participate remotely using their own equipment. Yet, there are many differences between lab environments and home environments, as well as differences between participant samples recruited for lab studies and remote studies. This paper replicates a lab-based experiment on VR locomotion interfaces using a remote sample. Participants completed a triangle-completion task (travel two path legs, then point to the path origin) using their own VR equipment in a remote, unsupervised setting. Locomotion was accomplished using two versions of the teleporting interface varying in availability of rotational self-motion cues. The size of the traveled path and the size of the surrounding virtual environment were also manipulated. Results from remote participants largely mirrored lab results, with overall better performance when rotational self-motion cues were available. Some differences also occurred, including a tendency for remote participants to rely less on nearby landmarks, perhaps due to increased competence with using the teleporting interface to update self-location. This replication study provides insight for VR researchers on aspects of lab studies that may or may not replicate remotely.},
    keywords      = {Task analysis;Navigation;Games;Virtual environments;Legged locomotion;Headphones;Green products;Navigation;Spatial cognition;Virtual reality;Teleporting;Online data collection},
    doi           = {10.1109/TVCG.2022.3150475},
    issn          = {1941-0506},
    month         = {May}
}
@inproceedings{10112008,
    author        = {Khandelwal, Utkal and Sharma, Avnish and Panicker, Aneesya},
    booktitle     = {2023 6th International Conference on Information Systems and Computer Networks (ISCON)},
    title         = {Impact of Telepresence of Hotel Websites on Behavioral Intention of Indian consumers: A Select Study},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {With the advancement in technology and increasing innovation, the organizational ways of responding to customers' needs, promoting and advertising the product and service brands has completely transformed. The different market changes and trends broadly impacted the marketing communication process of the organizations. In the world of competitions and technological growth the hotel industry also changed its way of approaching and targeting customers to build strong market presence. The development of virtual world in form of hotel websites and its associated customer experiences have strongly influenced the buying behavior and decision making process. This study talks about the different variables including sensory, cognitive and emotional attributes and their role in influencing customer buying intentions. The present study identifies the antecedents of telepresence by investigating variables including sensory, emotional and cognitive attributes and examines the impact of telepresence on behavioral intentions of customers towards hotel websites. An online self-administered survey was conducted to collect data. This study helps to determine the conceptual framework model fitness through confirmatory factor analysis. The findings of this study state the significance of telepresence theory by exploring various antecedents and outcomes of the customers' telepresence in a hotel's website context. It has concluded that higher telepresence leads to positive behavioral intention among customers.},
    keywords      = {Industries;Technological innovation;Analytical models;Telepresence;Decision making;Organizations;Market research;Telepresence;Hotel Websites;Behavioral Intentions;Indian consumers},
    doi           = {10.1109/ISCON57294.2023.10112008},
    issn          = {2832-143X},
    month         = {March}
}
@inproceedings{9796920,
    author        = {Liu, Jianwei and He, Yinghui and Xiao, Chaowei and Han, Jinsong and Cheng, Le and Ren, Kui},
    booktitle     = {IEEE INFOCOM 2022 - IEEE Conference on Computer Communications},
    title         = {Physical-World Attack towards WiFi-based Behavior Recognition},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {400--409},
    abstract      = {Behavior recognition plays an essential role in numerous behavior-driven applications (e.g., virtual reality and smart home) and even in the security-critical applications (e.g., security surveillance and elder healthcare). Recently, WiFi-based behavior recognition (WBR) technique stands out among many behavior recognition techniques due to its advantages of being non-intrusive, device-free, and ubiquitous. However, existing WBR research mainly focuses on improving the recognition precision, while neglecting the security aspects. In this paper, we reveal that WBR systems are vulnerable to manipulating physical signals. For instance, our observation shows that WiFi signals can be changed by jamming signals. By exploiting the vulnerability, we propose two approaches to generate physically online adversarial samples to perform untargeted attack and targeted attack, respectively. The effectiveness of these attacks are extensively evaluated over four real-world WBR systems. The experiment results show that our attack approaches can achieve 80\% and 60\% success rates for untargeted attack and targeted attack in physical world, respectively. We also propose three methods to mitigate the hazard of such attacks.},
    keywords      = {Target recognition;Surveillance;Virtual reality;Smart homes;Medical services;Behavioral sciences;Sensors;Behavior recognition;WiFi;Genetic algorithm;Adversarial sample},
    doi           = {10.1109/INFOCOM48880.2022.9796920},
    issn          = {2641-9874},
    month         = {May}
}
@article{9597560,
    author        = {Picano, Benedetta},
    journal       = {IEEE Access},
    title         = {Multi-Sensorial Human Perceptual Experience Model Identifier for Haptics Virtual Reality Services in Tactful Networking},
    year          = {2021},
    volume        = {9},
    number        = {},
    pages         = {147549--147558},
    abstract      = {The tactful networking paradigm is expected to play a crucial role in the next generation networks. Accordingly, adaptive human-aware environments, sensitive to the daily human behavior and individual traits have to be provided, in order to offer a fully immersive and customized experience to users. On the basis of data collected by actual cognitive experiments, this paper proposes a learning framework to discover the multi-sensory human perceptual experience. The paper applies the mixture density network to identify the perception model considering different senses, and then the multi-sensory integration is performed, accordingly to the actual neuro-cognitive model. Furthermore, a supervised learning module has been used to cluster the users on the basis of the human perception identification strategy previously designed, assuming a multimodal structure for the cognitive brain activity. Finally, a practical contextualization is presented, in relation to the haptics virtual reality services. What emerges from the results is the effectiveness of the tactful approach, i.e., brain-aware, involving the proposed framework, which is validated in comparison to the more conventional brain-agnostic scheme. In fact, the system performance, expressed in terms of reliability in guaranteeing the service exploitation before a target deadline based on the integrated perception, reaches remarkable improvements applying the brain-aware strategy, which exploits the human perception knowledge.},
    keywords      = {Visualization;Brain modeling;Solid modeling;Supervised learning;Quality of service;Haptic interfaces;Unsupervised learning;Human-in-the-loop;quality-of-experience;tactful networking;supervised learning},
    doi           = {10.1109/ACCESS.2021.3124607},
    issn          = {2169-3536},
    month         = {}
}
@inproceedings{9459396,
    author        = {Liu, Bing and Zhan, Zhicheng},
    booktitle     = {2021 7th International Conference of the Immersive Learning Research Network (iLRN)},
    title         = {Work-in-Progress–--Improve Spatial Learning by Chunking Navigation Instructions in Mixed Reality},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1--3},
    abstract      = {Although navigation system allows users reach destination easily, spatial learning is always necessary, especially in emergency situations. Intentional spatial learning is effective but always requires more attention. In this work-in-progress, we explore ways to improve incidental spatial learning with mixed reality-based (MR) navigation. We analyze how people structure space from volunteered geographic information (VGI) verbal navigation instructions, chunk the space accordingly and use different visual instructions among chunks in MR user interface. A user study is to be conducted to test if spatial learning is improved such design. The findings contribute to the design principles of MR-based navigation.},
    keywords      = {Visualization;Navigation;Mixed reality;Virtual reality;User interfaces;spatial learning;chunking;volunteered geographic information (VGI);navigation instruction;mixed reality},
    doi           = {10.23919/iLRN52045.2021.9459396},
    issn          = {},
    month         = {May}
}
@inproceedings{9792944,
    author        = {Ding, Xueqin and Shen, Shuanghua and Cui, Guangxi and Wang, Yulan and Tan, Jiajia and Zhong, Qian},
    booktitle     = {2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)},
    title         = {Realization of Virtual Reality Technology in College Students' Social Anxiety Intervention Platform based on SQL Information Sequence Data Mining},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {710--713},
    abstract      = {In this paper, under the framework of SQL information sequence mining, combined with well-known social anxiety scales at home and abroad, a social anxiety question bank and its computerized adaptive test (CAT-SA) are constructed. The IRT analysis includes: unidimensionality test, item model-data fitting test, local independence test, DIF test, and selecting items that meet the IRT requirements to construct a social anxiety question bank and its CAT. According to the two-stage adaptive assessment with similar significance in the evaluation scene design, the ITC\_SoPI scale was used to evaluate the individual's degree of adaptation and subjective feeling to the virtual environment. VR-based social anxiety assessment can provide more detailed and comprehensive assessment information and data, and the assessment results are doser to the self-assessment scale and the individual's daily life and state.},
    keywords      = {Solid modeling;Correlation;Computational modeling;Anxiety disorders;Time series analysis;Fitting;Virtual environments;Virtual Reality;College Students;Social Anxiety Intervention;SQL Infomration Sequence;Data Mining},
    doi           = {10.1109/ICAAIC53929.2022.9792944},
    issn          = {},
    month         = {May}
}
@inproceedings{10193110,
    author        = {Kumari, J Jesy Janet and Singh, Aniket and Naidu, R. Ch. A. and Sathya, M and Ramya Sri, M},
    booktitle     = {2023 4th International Conference on Electronics and Sustainable Communication Systems (ICESC)},
    title         = {An Empirical Study on E-Commerce Site using Unique AI based Features and Data Science Tools},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {1357--1364},
    abstract      = {With the advancement of modern-day techniques in the field of Information Technology, the way of shopping through E-Commerce site is becoming outdated. There are two ways through which an individual can do shopping first is the online method and second is the offline one in today's world online shopping by having more variety of products available on individual platform with easy way of shopping because of this day by day the retailers with offline method are facing challenges to increase their sales and obtaining data of demanding products that are available in the market, now with the growth of artificial intelligence, they can use lot of beneficiary tools to boost their business. If a giant next generation E-Commerce site is made with which we can connect all the wholesalers, retailers and customers with their own point of profits, then it can bring a new revolution in the market where there will be different layers will be available with separate user friendly graphic user interface for all wholesalers, retailers and customers, where they will be allowed to access their own layers accordingly with several unique features and benefits to save time and making shopping more amazing for customers and selling their products and boosting daily sales for the retailers with the influence of top wholesalers available to help them with the unique kind of trading system and daily analytics and progress report using data science.},
    keywords      = {Image recognition;Communication systems;Crops;Data science;Electronic commerce;Artificial intelligence;Information technology;E-commerce;image recognition;machine learning;QR code;Virtual reality},
    doi           = {10.1109/ICESC57686.2023.10193110},
    issn          = {},
    month         = {July}
}
@inproceedings{8798260,
    author        = {Keller, Marilyn and Tchilinguirian, Tristan},
    booktitle     = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
    title         = {Obstacles Awareness Methods from Occupancy Map for Free Walking in VR},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {1012--1013},
    abstract      = {With Head Mounted Displays (HMD) equipped with extended tracking features, users can now walk in a room scale space while being immersed in a virtual world. However, to fully exploit this feature and enable free-walking, these devices still require a large physical space, cleared of obstacles. This is an essential requirement that not any user can meet, especially at home, thus this constraint limits the use of free-walking in Virtual Reality (VR) applications. In this poster, we propose ways of representing the physical obstacles surrounding the user. There are generated from an occupancy map and compared to the representation as a point cloud. We propose three visualisation modes: integrating an occupancy map into the virtual floor, generating lava lakes where obstacles are and building a semi-transparent wall along the obstacles boundaries. We found that although showing the obstacles on the floor only impacts lightly the navigation, the preferred visualization mode remains the point cloud.},
    keywords      = {Three-dimensional displays;Visualization;Legged locomotion;Trajectory;Resists;Navigation;Google;Human-centered computing;Visualization;Visualization techniques;Empirical studies in visualization},
    doi           = {10.1109/VR.2019.8798260},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{10109439,
    author        = {Arago, Nilo M. and Paulino, Beaver and De Luna, Allyze Marie and Manlapaz, Arielle Joy and Palabrica, Reneleo Martin and Abellera, Mar Lemuel and Quijano, Jay Fel C. and Amado, Timothy M. and Amon, Villamor M. and Fernandez, Edmon O. and Baccay, Melito A. and Galido, Edgar A.},
    booktitle     = {2022 IEEE 14th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)},
    title         = {Mystic Tours: Cross-Platform Museum Virtual Tourism Application Using 360-degree Imagery and Virtual Reality Technologies},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {In this paper, the researchers developed a cross-platform virtual tourism application named Mystic Tours that utilizes 360-degree imagery and Virtual Reality (VR) Technologies. Mystic Tours has three (3) main features: navigation, interaction, and perception. For navigation, users can pan, tilt, and zoom the environment to explore the 3D scene, including a map that can easily teleport the user to other parts of the museum. For interaction, users can click on the information icon to open the information canvas consisting of text and images with narration support available in both English and Filipino. For perception, users can view the museum using different perspective modes. For android devices, users can turn on the virtual reality mode and explore the area and interact with objects using the gaze control feature. The proponents of the study implemented data analytics using Unity Analytics to understand the behavioral pattern of the users and make data-driven adjustments and recommendations to museums. For testing, the User Acceptance Test (UAT) was divided into five (5) sections: personal data, web application assessment, android touch assessment, virtual reality mode assessment, and general features assessment. In compliance with ISO 9126, the result showed that the respondents rated the application Excellent Quality (EQ) in terms of functionality, reliability, usability, efficiency, maintainability, and portability. In conclusion, the developed application was highly accepted by the test respondents.},
    keywords      = {Measurement;Headphones;Three-dimensional displays;Navigation;ISO Standards;Virtual reality;Museums;Virtual Reality;Cross-Platform Application Development;Unity 3D;Android;WebGL;Data Analytics},
    doi           = {10.1109/HNICEM57413.2022.10109439},
    issn          = {2770-0682},
    month         = {Dec}
}
@inproceedings{9994946,
    author        = {Giovannelli, Alexander and Lisle, Lee and Bowman, Doug A.},
    booktitle     = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
    title         = {Exploring the Impact of Visual Information on Intermittent Typing in Virtual Reality},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {8--17},
    abstract      = {For touch typists, using a physical keyboard ensures optimal text entry task performance in immersive virtual environments. However, successful typing depends on the user's ability to accurately position their hands on the keyboard after performing other, non-keyboard tasks. Finding the correct hand position depends on sensory feedback, including visual information. We designed and conducted a user study where we investigated the impact of visual representations of the keyboard and users' hands on the time required to place hands on the homing bars of a keyboard after performing other tasks. We found that this keyboard homing time decreased as the fidelity of visual representations of the keyboard and hands increased, with a video pass-through condition providing the best performance. We discuss additional impacts of visual representations of a user's hands and the keyboard on typing performance and user experience in virtual reality.},
    keywords      = {Performance evaluation;Visualization;Keyboards;Virtual environments;User experience;Task analysis;Augmented reality;Human-centered computing;Human computer interaction (HCI);Interaction devices;Keyboards Human-centered computing;Interaction paradigms;Virtual reality},
    doi           = {10.1109/ISMAR55827.2022.00014},
    issn          = {1554-7868},
    month         = {Oct}
}
@inproceedings{10765404,
    author        = {Ferreira, Jo\~{a}o P. and Ferreira-Brito, Filipa and Guerreiro, Jo\~{a}o and Guerreiro, Tiago},
    booktitle     = {2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
    title         = {Crafting Virtual Realities: Designing a VR End-User Authoring Platform for Personalised Exposure Therapy},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {932--940},
    abstract      = {Abstract Exposure therapy (ET) gradually introduces people to the objects, animals, or situations they fear to help them overcome the angst with that source of anxiety. VR(ET) enables exposure to various triggers in the safety of the clinical or home environments. While prior work has explored how specific VR environments support therapy in contexts such as social anxiety or arachnophobia, therapy's individualised nature is often overlooked. We used an iterative participatory design approach to develop an authoring platform for therapists, enabling them to tailor VR environments during exposure by changing and parameterising elements and reapplying past scenes. We used this platform as a design probe in a study with ten therapists to elicit discussions about the design of VRET experiences and therapists' authoring needs. Findings highlight the value of controlling the stimuli presented to patients and deviating from stereotypical scenarios, and the importance of further investigating the therapist's virtual representation.},
    keywords      = {Animals;Anxiety disorders;Medical treatment;Safety;Iterative methods;Probes;Augmented reality;Participatory design;virtual reality;exposure therapy;anxiety disorders;VRET;authoring},
    doi           = {10.1109/ISMAR62088.2024.00109},
    issn          = {2473-0726},
    month         = {Oct}
}
@inproceedings{9771992,
    author        = {Qi, Wanbin and Zhang, Ronghui and Zhou, Quan and Jing, Xiaojun},
    booktitle     = {2022 IEEE Wireless Communications and Networking Conference (WCNC)},
    title         = {Towards Device-Free Cross-Scene Gesture Recognition from Limited Samples in Integrated Sensing and Communication},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {195--198},
    abstract      = {Device-free gesture recognition (DFGR) is a critical technology for human-computer interaction and can be used for applications such as smart homes, and virtual reality in Wi-Fi sensing. Existing deep learning-based DFGR techniques typically require a large amount of labeled sensing data and are sensitive to the scene, which limits the development of ubiquitous sensing. In this study, in order to achieve device-free cross-scene gesture recognition from limited sensing samples, we consider the use of a small amount of Wi-Fi channel status information (CSI) data that are continuously obtained from low-cost commercial Wi-Fi devices. To this end, a few-shot learning-based cross-scene DFGR model is proposed for capturing highly discriminative information from dynamic CSI sequences. This information is then used to distinguish different gestures in the limited samples. Our experimental results using Wi-Fi signal collected at real world show that our model is able to realize 99.52\% accuracy and can work well even with only one-piece data of new scene.},
    keywords      = {Human computer interaction;Solid modeling;Conferences;Gesture recognition;Virtual reality;Smart homes;Data models;Cross-scene;gesture recognition;integrated sensing and communication;limited samples;Wi-Fi sensing},
    doi           = {10.1109/WCNC51071.2022.9771992},
    issn          = {1558-2612},
    month         = {April}
}
@article{9144721,
    author        = {Hayes, James},
    journal       = {Engineering \& Technology},
    title         = {AI-powered therapy sets minds at rest},
    year          = {2019},
    volume        = {14},
    number        = {6},
    pages         = {46--49},
    abstract      = {IT MADE HEADLINE news when the leader of the UK's biggest relationship support charity revealed the organisation was considering the possibility of deploying chatbots using artificial intelligence (AI) for live chat counselling services. The chief executive of Relate, Aidan Jones, told an interviewer that he was looking at the potential of "non-human intervention" in 2019 to assist his 1,500 online counsellors, as they were becoming stretched by demands made on the service.},
    keywords      = {Medical treatment;Companies;Machine learning;Tools;Psychology},
    doi           = {10.1049/et.2019.0609},
    issn          = {1750-9637},
    month         = {July}
}
@inproceedings{9585824,
    author        = {Boffi, Laura and Mincolelli, Giuseppe and Bertucci, Simone and Gammarota, Lorenzo and Pes, Fabio and Garofoli, Marco},
    booktitle     = {2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
    title         = {Co-Drive: the experience of a shared car trip between a driver and a remote passenger},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {497--499},
    abstract      = {Co-Drive is a service concept that allows social virtual travelling by car between a driver of a vehicle and a remote passenger connected via virtual reality from home. The Co-Drive concept enables novel social interactions between a driver and a remote passenger who are unknown to each other and it aims to foster new social encounters, for example intergenerational ones between elderly remote passengers (with reduced mobility and travel possibilities) and younger drivers. At ISMAR 2021, Co-Drive will be demonstrated as a way to foster casual and unfocused encounters between unknown conference attendees.},
    keywords      = {Senior citizens;Automobiles;Augmented reality;Vehicles;Human-centered computing;Empirical studies in interaction design},
    doi           = {10.1109/ISMAR-Adjunct54149.2021.00118},
    issn          = {},
    month         = {Oct}
}
@inproceedings{10332563,
    author        = {Liang, Yo-Wen and Huang, Yu-Hsuan},
    booktitle     = {2023 IEEE 6th International Conference on Knowledge Innovation and Invention (ICKII)},
    title         = {Exploration of User Experience in Mixed Reality for Product Virtual Interaction and Display},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {404--409},
    abstract      = {In the post-pandemic era, the strong impact affected the user experience and interaction of products. Web-based online stores also lack intuitive product designs, leading to frequent cognitive disputes. Therefore, a new user experience and interactive approach are continuously researched and discussed. Virtual Reality (VR) and Augmented Reality (AR) provide a Mixed Reality (MR) user experience, which has been influencing business models in the industry since 2020. Additionally, with the emergence of the metaverse at the end of 2021, MR has been recognized as a crucial technology with enormous potential for future demands. However, while many innovative applications of MR have achieved considerable success, they still only focus on entertainment-related experiences and have yet to fully explore the comprehensive range of applications and innovative directions for MR. In such circumstances, we investigated the requirements for user experiences and spatial displays in integrating MR into product experiences. We proposed a novel model that transitions from physical to virtual realms to effectively address the aforementioned challenges. The initial phase involved analyzing the prevailing issues and challenges encountered by users in the product and spatial experience services offered by physical stores and web-based online platforms. Subsequently, the results revealed specific needs were met with the MR technology and alleviated associated pain points. The outcomes of the proposed model provide a reference for future studies to research immersive service experiences within real-world settings with MR devices, thereby removing limitations in space and time.},
    keywords      = {Solid modeling;Technological innovation;Pain;Metaverse;Layout;Mixed reality;Virtual reality;mixed-reality;virtual reality;user experience;interaction design;product display},
    doi           = {10.1109/ICKII58656.2023.10332563},
    issn          = {2770-4785},
    month         = {Aug}
}
@inproceedings{8122970,
    author        = {Meinel, Christoph and Chujfi, Salim},
    booktitle     = {2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
    title         = {Cognitive adaptability to optimize online behavior personalizing digital workspaces with virtual reality},
    year          = {2017},
    volume        = {},
    number        = {},
    pages         = {2334--2339},
    abstract      = {Digital organizations are now ruled by the flexibility offered by remote working environments. The availability of people to work from different places, with digital tools, empower them very often not only to perform their work better and faster, but also to reach higher levels of satisfaction in balancing work and private life. However, from an organizational perspective, there are concerns regarding the management of knowledge of those remote individuals and how they may impact the further creation of knowledge within the organization. Considering that knowledge is not only information stored on databases or written in documents, the interaction between peers is also an enormous source of knowledge that needs to be canalized. Commonly described as tacit knowledge, face-to-face communication is the main enabler of such knowledge and is one is the missing elements in remote working environments. For a geographically distributed team, a common `virtual space', personalized to the cognitive needs of each individual, would represent an improvement in the digital space and could compensate for the missing face-to-face interaction. This paper proposes integrating cognitive adaptability in virtual working environments to enhance user interaction and knowledge processing, taking into consideration behavioral conditions and individuals' learning diversity. Since interaction in decentralized environments is ruled by online behaviors, the use of virtual reality and the sensorimotor experience it offers is proposed to design individual virtual spaces for interaction, which should be created as closely as possible to their ideal learning dimension. Designing individualized environments focusses on creating optimal surrounding digital spaces that precisely match the cognitive and learning conditions of individuals, so that interaction and knowledge creation are not compromised, but improved.},
    keywords      = {Virtual environments;Organizations;Cognition;Knowledge management;Visualization;collaborative work;cognitive adaptability;cyber cognition;knowledge management;virtual reality},
    doi           = {10.1109/SMC.2017.8122970},
    issn          = {},
    month         = {Oct}
}
@inproceedings{10299762,
    author        = {Gurbilek, Gokhan and Onalan, Aysun Gurur},
    booktitle     = {2023 IEEE International Black Sea Conference on Communications and Networking (BlackSeaCom)},
    title         = {Work-in-Progress: An Empirical Study of the Joint Effects of WiFi Coverage and Channel Congestion on Quality of Experience in 5 GHz Band},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {396--401},
    abstract      = {Ever-increasing multimedia application usage brings stricter network requirements every day for wireless networks. WiFi is the commonly used wireless technology for in-home and public networks. Existing literature focuses mainly on video streaming QoE over WiFi against channel congestion. None of the studies investigates the joint effects of coverage and congestion issues on the QoE of different multimedia applications with different network requirements and adoption rates. In this study, first time in the literature, QoE of video conferencing, YouTube video streaming, cloud gaming, and VR streaming applications are investigated under different congestion and coverage scenarios in the 5 GHz WiFi band, taking into account the different adoption rates of the applications. The results show that high congestion can prevent a single user from streaming a 4K video, even when the user is in a medium coverage region. On the other hand, the QoE of cloud gaming, and especially VR streaming, are more to the congestion and coverage issues. For better user experience in multimedia applications with more demands, e.g., VR streaming, the new 6 GHz WiFi band could be a solution in near future.},
    keywords      = {Performance evaluation;Video on demand;Limiting;Wireless networks;Cloud gaming;User experience;Quality of experience;WiFi;Congestion;Coverage;Quality of Experience;Video Conferencing;YouTube;Cloud Gaming;VR Streaming},
    doi           = {10.1109/BlackSeaCom58138.2023.10299762},
    issn          = {},
    month         = {July}
}
@inbook{10789287,
    author        = {Verma, Yash},
    booktitle     = {Artificial Intelligence for Virtual Reality},
    title         = {2 Video surveillance framework using virtual reality interface},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {15--26},
    abstract      = {Video surveillance plays an important role in the security of any location, whether it is residential areas, industries, public spaces like shopping malls, museums and other monuments, banks, offices, building sites, warehouses, airports, railway stations and so on. Monitoring staff play an important role in the surveillance system. A system was needed to be developed to test the cognitive abilities of the staff monitoring video surveillance under different conditions and determine the factors important for monitoring task to improve the surveillance process. For this purpose, a system has been developed using Unity 3D in which the monitoring staffs have to identify the people exhibiting suspicious behavioral patterns from the queues of people with mixed behavioral patterns. The system has been successfully able to calculate the attributes of the security staff like response time of the staff members in identifying suspicious people. This system can be used in forming different strategies regarding the surveillance process.},
    keywords      = {Security;Accuracy;Visualization;Video surveillance;Cameras;Weapons;YOLO;Video games;Three-dimensional displays;Streaming media},
    doi           = {},
    issn          = {},
    publisher     = {De Gruyter},
    isbn          = {9783110713855},
    url           = {https://ieeexplore.ieee.org/document/10789287}
}
@article{9109687,
    author        = {Belmonte, Lidia M. and Garc\'{\i}a, Arturo S. and Segura, Eva and Novais, Paulo and Morales, Rafael and Fern\'{a}ndez-Caballero, Antonio},
    journal       = {IEEE Transactions on Emerging Topics in Computing},
    title         = {Virtual Reality Simulation of a Quadrotor to Monitor Dependent People at Home},
    year          = {2021},
    volume        = {9},
    number        = {3},
    pages         = {1301--1315},
    abstract      = {Unmanned aerial vehicles (UAVs) represent an assistance solution for home care of dependent persons. These aircraft can cover the home, accompany the person, and position themselves to take photographs that can be analyzed to determine the person's mood and the assistance needed. In this context, this work principally aims to design a tool to aid in the development and validation of the navigation algorithms of an autonomous vision-based UAV for monitoring dependent people. For that, a distributed architecture has been proposed based on the real-time communication of two modules, one of them in charge of the dynamics of the UAV, the trajectory planning and the control algorithms, and the other devoted to visualizing the simulation in an immersive virtual environment. Thus, a system has been developed that allows the evaluation of the behavior of the assistant UAV from a technological point of view, as well as to carry out studies from the assisted person's viewpoint. An initial validation of a quadrotor model monitoring a virtual character demonstrates the advantages of the proposed system, which is an effective, safe and adaptable tool for the development of vision-based UAVs to help dependents at home.},
    keywords      = {Monitoring;Heuristic algorithms;Trajectory;Solid modeling;Virtual reality;Tools;Real-time systems;K.4.2.b assistive technologies for persons with disabilities;L.2.0.k virtual reality;I.2.9.a autonomous vehicles},
    doi           = {10.1109/TETC.2020.3000352},
    issn          = {2168-6750},
    month         = {July}
}
@article{8432120,
    author        = {Meuleman, Ben and Rudrauf, David},
    journal       = {IEEE Transactions on Affective Computing},
    title         = {Induction and Profiling of Strong Multi-Componential Emotions in Virtual Reality},
    year          = {2021},
    volume        = {12},
    number        = {1},
    pages         = {189--202},
    abstract      = {Psychological theories of emotion have often defined an emotion as simultaneous changes in several mental and bodily components. In addition, appraisal theories assume that an appraisal component elicits changes in the other emotion components (e.g., motivational, behavioural, experiential). Neither the componential definition of emotion nor appraisal theory have been systematically translated to paradigms for emotion induction, many of which rely on passive emotion induction without a clear theoretical framework. As a result, the observed emotions are often weak. This study explored the potential of virtual reality (VR) to evoke strong emotions in ecologically valid scenarios that fully engaged the mental and bodily components of the participant. Participants played several VR games and reported on their emotions. Multivariate analyses using hierarchical clustering and multilevel linear modelling showed that participants experienced intense, multi-componential emotions in VR. We identified joy and fear clusters of responses, each involving changes in appraisal, motivation, physiology, feeling, and regulation. Appraisal variables were found to be the most predictive for fear and joy intensities, compared to other emotion components, and were found to explain individual differences in VR scenarios, as predicted by appraisal theory. The results advocate for upgraded methodologies for the induction and analysis of emotion processes.},
    keywords      = {Appraisal;Games;Virtual reality;Biological system modeling;Solid modeling;Physiology;Task analysis;Emotion;emotion elicitation;appraisal;virtual reality},
    doi           = {10.1109/TAFFC.2018.2864730},
    issn          = {1949-3045},
    month         = {Jan}
}
@inproceedings{7442269,
    author        = {Dong, Haiwei and Gao, Yu and Al Osman, Hussein and El Saddik, Abdulmotaleb},
    booktitle     = {2015 IEEE International Symposium on Multimedia (ISM)},
    title         = {Development of a Web-Based Haptic Authoring Tool for Multimedia Applications},
    year          = {2015},
    volume        = {},
    number        = {},
    pages         = {13--20},
    abstract      = {In this paper, we introduce an MPEG-V based haptic authoring tool intended for simplifying the development process of haptics-enabled multimedia applications. The developed tool provides a web-based interface for users to create haptic environments by importing 3D models and adding haptic properties to them. The user can then export the resulting environment to a standard MPEG-V format. The latter can be imported to a haptic player that renders the described haptics-enabled 3D scene. The proposed tool can support many haptic devices, including Geomagic Devices, Force Dimension Devices, Novint Falcon Devices, and Moog FCS HapticMaster Devices. We conduct a proof of concept HTML5 haptic game project and user studies on haptic effects, development process and user interface, which shows our tool's effectiveness in simplifying the development process of haptics-enabled multimedia applications.},
    keywords      = {Haptic interfaces;Three-dimensional displays;Transform coding;Rendering (computer graphics);Solid modeling;Force;Web haptics;HTML5;3D graphics;MPEG-V},
    doi           = {10.1109/ISM.2015.71},
    issn          = {},
    month         = {Dec}
}
@inproceedings{7457137,
    author        = {Burns, Nicholas Brent and Sassaman, Peter and Daniel, Kathryn and Huber, Manfred and Z\'{a}ruba, Gergely},
    booktitle     = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)},
    title         = {PESTO: Data integration for visualization and device control in the SmartCare project},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {The SmartCare project is to design, develop, and evaluate an intelligent sensor-driven living environment for the elderly. The core objectives are to provide emergency detection, improve quality of life, extend independence for the elderly, and detect patterns of behavior that could suggest early signs of a physical or cognitive issue, all in an unobtrusiveness manner. This paper specifically focuses on the development of the infrastructure integration component: PESTO and two of its sub components: a 3D visualization of the resident's smart apartment (VISMA) and a system to provide everyday task assistance through the Z-Wave home automation technology (ZAPS).},
    keywords      = {Data visualization;Three-dimensional displays;Home automation;Software;Monitoring;Wireless communication;Senior citizens;eldercare;home healthcare;pervasive computing;ubiquitous computing;smart technology;sensor networks;z-wave;home automation;virtual environment;3D modeling},
    doi           = {10.1109/PERCOMW.2016.7457137},
    issn          = {},
    month         = {March}
}
@inproceedings{8780383,
    author        = {Singh, Neeraj Kumar and Wang, Hao},
    booktitle     = {2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)},
    title         = {Virtual Environment Model of Glucose Homeostasis for Diabetes Patients},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {417--422},
    abstract      = {A medical device is designed to meet the patient specific requirements. The required biological behaviour of the medical device is driven by mostly the operating environment. Most of the time, a medical device fails due to lack of understanding of the system requirements, including the functional and non-functional requirements. For example, the U.S. Food and Drug Administration (FDA) has reported a large number of serious illnesses and deaths related to IIP. Our approach is to trigger hidden requirements at an early stage of the system development. In order to achieve our goal, this paper proposes an abstract development of virtual environment model of the glucose homeostasis for diabetes patients to analyze the patient specific medical devices, such as an Insulin Infusion Pump (IIP). The main objective of this environment model is to assist in the construction, clarification, and validation of the system requirements by developing and designing the closed-loop model of medical devices.},
    keywords      = {Sugar;Biological system modeling;Mathematical model;Insulin;Medical devices;Diabetes;Virtual environments;Homeostasis;Diabetes;Formal methods;Environment modelling.},
    doi           = {10.1109/ICPHYS.2019.8780383},
    issn          = {},
    month         = {May}
}
@inproceedings{7312621,
    author        = {Haidar, Hassan and Kalakech, Ali and Hamie, Ali and Querrec, Ronan},
    booktitle     = {2015 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP)},
    title         = {A control layer for a Peer-to-Peer middleware using behavior semantics},
    year          = {2015},
    volume        = {},
    number        = {},
    pages         = {155--162},
    abstract      = {The increasing demand on networked virtual reality environments (VRE) is putting pressure to adopt scalable architecture capable to support new participants and deliver new services. Client/Server (C/S) architecture is showing different limitations especially in terms of scalability. Proposed solutions are based on a migration to a decentralized Peer-to-Peer (P2P) architecture that still lacks the control layer previously hosted by the server role. On the other hand, distributed data doesn't share same significance for maintaining synchronization between environments. Thus, controlling what data to distribute and when by defining interest on selected data according to certain criteria help in building generic strategies for the distribution process of VRE. In this paper, we propose a control layer for a P2P architecture based on behavior semantic-knowledge of VRE as a dynamic selection criteria for data of interest. Our proposal is presented using a semantic-rich framework named MASCARET distributed using a pure P2P middleware named Data Distribution Service (DDS).},
    keywords      = {Unified modeling language;Solid modeling;Peer-to-peer computing;Middleware;Filtering;Semantics;Virtual reality;Distributed Virtual Reality Environment;Behavior Semantics;Middleware;Peer-to-Peer;OMG;DDS},
    doi           = {10.1109/ICCP.2015.7312621},
    issn          = {},
    month         = {Sep.}
}
@inproceedings{7377242,
    author        = {Seaborn, Katie and Pennefather, Peter and Fels, Deborah I.},
    booktitle     = {2015 IEEE Games Entertainment Media Conference (GEM)},
    title         = {A cooperative game for older powered chair users and their friends and family},
    year          = {2015},
    volume        = {},
    number        = {},
    pages         = {1--4},
    abstract      = {For older adults, adopting a powered mobility aid signals a life transition that affects several well-being factors: their self-image, motivation, and self-perception of ability, but also how other people -- friends, family, coworkers, strangers -- relate to and perceive these individuals. We present initial findings from a user study in which we (a) recorded a baseline of well-being using established psychological instruments, and (b) evaluated a web-based prototype of a cooperative mixed reality game for improving the well-being of older powered chair users and their friends and family. Our results show that most participants considered themselves to be happy and were driven by hedonic and eudaimonic motives during gameplay, but were mixed with respect to their attitudes towards disability.},
    keywords      = {Games;Virtual reality;Wheelchairs;Instruments;Usability;Atmospheric measurements;Particle measurements;older adults;powered chairs;mobility impairment;game design;well-being;inclusive design},
    doi           = {10.1109/GEM.2015.7377242},
    issn          = {},
    month         = {Oct}
}
@inproceedings{7938242,
    author        = {Elshehaly, Mai and Szeto, Gregory and Pan, Zhigeng and Chen, Jian},
    booktitle     = {2016 International Conference on Virtual Reality and Visualization (ICVRV)},
    title         = {ImmunoExplorer: A Web-Based Multivariate Visualization System for Exploratory Analysis of Immunotherapy},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {480--487},
    abstract      = {We present ImmunoExplorer, a web-based multivariate visualization environment that supports exploratory analysis of experimental datasets typical in immunotherapy research. Research advances in immuno-oncology have opened up new frontiers for experimental and clinical research that aims to understand the complex interactions between cancer and the immune systems. Immunotherapy focuses on the development of novel cancer therapies based on leveraging these interactions. Extensive analysis of experimental datasets is required to rigorously validate preclinical results and clinical outcomes to design new therapies and to identify who will benefit from them. Visualization is a crucial part of this analysis, given the complexity, multidimensionality, and heterogeneity of the data involved and the lack of automatic computational solutions to derive patterns. In this work we first characterize the data types and analysis tasks, and then present two visualization techniques for comparative studies of various therapies. Finally, we demonstrate the usefulness of the design through a case study using a real dataset.},
    keywords      = {Immune system;Tumors;Medical treatment;Data visualization;Visualization;Proteins;Encoding;Data visualization;multivariate analysis;design study;tumor therapy},
    doi           = {10.1109/ICVRV.2016.87},
    issn          = {},
    month         = {Sep.}
}
@inproceedings{9644386,
    author        = {Gramoli, Lysa and Lacoche, J\'{e}r\'{e}my and Foulonneau, Anthony and Gouranton, Val\'{e}rie and Arnaldi, Bruno},
    booktitle     = {2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
    title         = {Needs Model for an Autonomous Agent during Long-term Simulations},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {134--138},
    abstract      = {Simulating human behavior in virtual environments is still a challenge. Yet, this feature is crucial to make them more believable. Therefore, many approaches have been proposed in order to find ways to faithfully simulate human behavior. One of the key features to make a virtual agent more believable is the simulation of needs such as hunger or tiredness. Unfortunately, most of the existing approaches in needs simulation do not really address the issue of long-term simulations where some problems may appear such as time drift. Yet, this kind of simulation is useful in many fields like video games or virtual data generation. This is why, in this paper, we focus on the creation of a needs model designed for long-term simulations. According to this model, needs can evolve over several simulated days without interruption. This model is configured to obtain a proper relation between control and autonomy in order to have a coherent behavior during long periods. This paper deals with the key features to set up this needs model and introduces some preliminary results to check the coherence of the agent behavior.},
    keywords      = {Solid modeling;Conferences;Virtual environments;Games;Coherence;Data models;Autonomous agents;agent behavior;needs model;long-term simulation},
    doi           = {10.1109/AIVR52153.2021.00031},
    issn          = {},
    month         = {Nov}
}
@inproceedings{10536479,
    author        = {Do, Tiffany D. and Protko, Camille Isabella and McMahan, Ryan P.},
    booktitle     = {2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {The Influence of Mixed-Gender Avatar Facial Features on Racial Perception: Insights from the VALID Avatar Library},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {450--453},
    abstract      = {Using the VALID Avatar Library, we created 14 mixed-gender avatars by combining facial features from male and female avatars within seven racial categories. In an online study (n=68), the avatars were perceived as racially ambiguous, despite source avatars sharing the same race. Same-race participant analysis showed nuanced ambiguity reduction, emphasizing categorization refinement. Findings suggest a potential link between gender and race perception, influenced by limited perceptual expertise.},
    keywords      = {Three-dimensional displays;Avatars;Conferences;Virtual environments;User interfaces;Libraries;Space heating;Human-centered computing--User studies;Computing methodologies--Perception},
    doi           = {10.1109/VRW62533.2024.00088},
    issn          = {},
    month         = {March}
}
@inproceedings{10108453,
    author        = {Albrecht, Matthias and Assl\"{a}nder, Lorenz and Reiterer, Harald and Streuber, Stephan},
    booktitle     = {2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)},
    title         = {MoPeDT: A Modular Head-Mounted Display Toolkit to Conduct Peripheral Vision Research},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {691--701},
    abstract      = {Peripheral vision plays a significant role in human perception and orientation. However, its relevance for human-computer interaction, especially head-mounted displays, has not been fully explored yet. In the past, a few specialized appliances were developed to display visual cues in the periphery, each designed for a single specific use case only. A multi-purpose headset to exclusively augment peripheral vision did not exist yet. We introduce MoPeDT: Modular Peripheral Display Toolkit, a freely available, flexible, reconfigurable, and extendable headset to conduct peripheral vision research. MoPeDT can be built with a 3D printer and off-the-shelf components. It features multiple spatially configurable near-eye display modules and full 3D tracking inside and outside the lab. With our system, researchers and designers may easily develop and prototype novel peripheral vision interaction and visualization techniques. We demonstrate the versatility of our headset with several possible applications for spatial awareness, balance, interaction, feedback, and notifications. We conducted a small study to evaluate the usability of the system. We found that participants were largely not irritated by the peripheral cues, but the headset's comfort could be further improved. We also evaluated our system based on established heuristics for human-computer interaction toolkits to show how MoPeDT adapts to changing requirements, lowers the entry barrier for peripheral vision research, and facilitates expressive power in the combination of modular building blocks.},
    keywords      = {Headphones;Visualization;Three-dimensional displays;Head-mounted displays;Prototypes;Virtual reality;Printers;Human-centered computing--Human computer interaction (HCI)--Interaction paradigms--Mixed / augmented reality;Human-centered computing--Human computer interaction (HCI)--Interactive systems and tools--User interface toolkits},
    doi           = {10.1109/VR55154.2023.00084},
    issn          = {2642-5254},
    month         = {March}
}
@inproceedings{8120298,
    author        = {Henshall, Gareth I. and Teahan, William J. and Cenydd, Llyr Ap},
    booktitle     = {2017 International Conference on Cyberworlds (CW)},
    title         = {Crowd-Sourced Procedural Animation Optimisation: Comparing Desktop and VR Behaviour},
    year          = {2017},
    volume        = {},
    number        = {},
    pages         = {48--55},
    abstract      = {Procedural animation systems are capable of synthesising life-like organic motion automatically. However due to extensive parameterisation, tuning these systems can be very difficult. Not only are there potentially hundreds of interlinked parameters, the resultant animation can be very subjective and the process is difficult to automate effectively.In this paper we describe a crowd-sourced approach to procedural animation parameter optimisation using genetic algorithms. We test our approach by asking users to interactively rate a population of virtual dolphins to a prescribed behavioural criteria. Our results show that within a few generations a group of users can successfully tune the system toward a desired behaviour.Our secondary motivation is to investigate if there are differences in animation and behavioural preference between observations made using a standard desktop monitor and those made using Virtual Reality (VR). We describe a study where users tuned two sets of dolphin animation systems in parallel, one using a normal monitor and another using an Oculus Rift. Our results indicate that being immersed in VR leads to some key differences in preferred behaviour.},
    keywords      = {Animation;Dolphins;Optimization;Bones;Neural networks;Mouth;Time-frequency analysis;Virtual Reality;Procedural Animation;Parameter Optimisation;Genetic Algorithm},
    doi           = {10.1109/CW.2017.52},
    issn          = {},
    month         = {Sep.}
}
@inproceedings{9583825,
    author        = {Raeburn, Gideon and Tokarchuk, Laurissa},
    booktitle     = {2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
    title         = {Varying user agency and interaction opportunities in a home mobile augmented virtuality story},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {347--356},
    abstract      = {New opportunities for immersive storytelling experiences have arrived through the technology in mobile phones, including the ability to overlay or register digital content on a user's real world surroundings, to greater immerse the user in the world of the story. This raises questions around the methods and freedom to interact with the digital elements, that will lead to a more immersive and engaging experience. To investigate these areas the Augmented Virtuality (AV) mobile phone application Home Story was developed for iOS devices. It allows a user to move and interact with objects in a virtual environment displayed on their phone, by physically moving in the real world, completing particular actions to progress a story. A mixed methods study with Home Story either guided participants to the next interaction, or offered them increased agency to choose what object to interact with next. Virtual objects could also be interacted with in one of three ways; imagining the interaction, an embodied interaction using the user's free hand, or a virtual interaction performed on the phone's touchscreen. Similar levels of immersion were recorded across both study conditions suggesting both can be effective, though highlighting different issues in each case. The embodied free hand interactions proved particularly memorable, though further work is required to improve their implementation, arising from their novelty and lack of familiarity.},
    keywords      = {Art;Augmented virtuality;Navigation;Design methodology;Virtual environments;Mobile handsets;Registers;Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Applied computing;Arts and humanities;Media arts},
    doi           = {10.1109/ISMAR52148.2021.00051},
    issn          = {1554-7868},
    month         = {Oct}
}
@inproceedings{7863209,
    author        = {Ch'ng, Eugene and Gaffney, Vince and Garwood, Paul and Chapman, Henry and Bates, Richard and Neubauer, Wolfgang},
    booktitle     = {2016 22nd International Conference on Virtual System \& Multimedia (VSMM)},
    title         = {Merging the real with the virtual: Crowd behaviour mining with virtual environments},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {1--9},
    abstract      = {The first recorded crowdsourcing activity was in 1714 [1], with intermittent public event occurrences up until the millennium when such activities become widespread, spanning multiple domains. Crowdsourcing, however, is relatively novel as a methodology within virtual environment studies, in archaeology, and within the heritage domains where this research is focused. The studies that are being conducted are few and far between in comparison to other areas. This paper aims to develop a recent concept in crowdsourcing work termed `crowd behaviour mining' [2] using virtual environments, and to develop a unique concept in crowdsourcing activities that can be applied beyond the case studies presented here and to other domains that involve human behaviour as independent variables. The case studies described here use data from experiments involving separate heritage projects and conducted during two Royal Society Summer Science Exhibitions, in 2012 and 2015 respectively. `Crowd Behaviour Mining' analysis demonstrated a capacity to inform research in respect of potential patterns and trends across space and time as well as preferences between demographic user groups and the influence of experimenters during the experiments.},
    keywords      = {Crowdsourcing;Europe;Virtual environments;Sea measurements;Market research;Google;Context;crowdsourcing;crowd behaviour mining;virtual environments;landscape archaeology;digital heritage},
    doi           = {10.1109/VSMM.2016.7863209},
    issn          = {2474-1485},
    month         = {Oct}
}
@inproceedings{9223331,
    author        = {Bruckschen, Lilli and Bungert, Kira and Wolter, Moritz and Krumpen, Stefan and Weinmann, Michael and Klein, Reinhard and Bennewitz, Maren},
    booktitle     = {2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
    title         = {Where Can I Help? Human-Aware Placement of Service Robots},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {533--538},
    abstract      = {As service robots are entering more and more homes it gets evermore important to find behavior strategies that ensure a harmonic coexistence between those systems and their users. In this paper, we present a novel approach to enable a mobile robot to provide timely assistance to a user moving in its environment, while simultaneously avoiding unnecessary movements as well as interferences with the user. We developed a framework that uses information about the last object interaction to predict possible future movement destinations of the user and infer where they might need assistance based on prior knowledge. Given this prediction, the robot chooses the best position for itself that minimizes the time until assistance can be provided as well as avoids interferences with other activities of the user. We evaluated our approach in comparison to state-of-the-art methods in simulated environments and performed a user study in a virtual reality environment. Our evaluation demonstrates that our approach is able to decrease both the time until assistance is provided and the travel distance of the robot as well as increases the average distance between the user and the robot in comparison to state-of-the-art systems. Additionally, the robot behavior generated by our method is rated as more pleasant by our study participants than comparable literature approaches.},
    keywords      = {Service robots;Navigation;Conferences;Virtual reality;Prediction methods;Harmonic analysis;Mobile robots},
    doi           = {10.1109/RO-MAN47096.2020.9223331},
    issn          = {1944-9437},
    month         = {Aug}
}
@inbook{10790166,
    author        = {Borole, Yogini and Borkar, Pradnya and Raut, Roshani and Balpande, Vijaya Parag and Chatterjee, Prasenjit},
    booktitle     = {Digital Twins: Internet of Things, Machine Learning, and Smart Manufacturing},
    title         = {Chapter 5 Machine Learning, AI, and IoT to Construct Digital Twin},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {49--60},
    abstract      = {This chapter explains how system builders should approach the development of digital twins that use artificial intelligence. What are the biggest hardware challenges when it comes to artificial intelligence/machine learning?},
    keywords      = {Artificial intelligence;Data models;Big Data;Internet of Things;Digital twins;Analytical models;Computational modeling;Solid modeling;Mathematical models;Three-dimensional displays},
    doi           = {},
    issn          = {},
    publisher     = {De Gruyter},
    isbn          = {9783110778960},
    url           = {https://ieeexplore.ieee.org/document/10790166}
}
@inproceedings{10776258,
    author        = {Aldossari, Saud Alhajaj},
    booktitle     = {2024 International Conference on Intelligent Computing, Communication, Networking and Services (ICCNS)},
    title         = {K - Means Artificial Intelligence Clustering Technique for 6G Propagation Channels},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--5},
    abstract      = {The global contemporary revolution is accelerating in our modern environment. Mobile communications have undergone a generational transition at regular periods. While fifth-generation (5G) structures are presently beginning to be financially suitable and with the benefaction of high Mm Wave and terahertz (THz) frequencies, there is a great deal of interest in systems past 5G. It is known as the 6Th generation (6G) remote system. In recent years, the development of Artificial Intelligence (AI) has rapidly grown, leading to its integration into various fields, including wireless communications. This integration of AI in wireless communication technologies can potentially revolutionize the future of 6G technology. The widespread use of new generation Information and Communications Technology (ICT) such as AI, blockchain innovation, virtual reality (VR), augmented reality (AR), etc. With the usage of high Mm Wave, the structure and propagation of the wireless signal is unknown. This paper studies the behavior of Channel State Information (CSI) via unsupervised learning method such as K-Means clustering methods in 145 GHz bands.},
    keywords      = {6G mobile communication;Wireless communication;Technological innovation;5G mobile communication;Turning;Information and communication technology;Artificial intelligence;Unsupervised learning;Channel state information;Terahertz communications;6G;artificial intelligence clustering;K-Means;Mm Wave;CSI},
    doi           = {10.1109/ICCNS62192.2024.10776258},
    issn          = {},
    month         = {Sep.}
}
@inproceedings{10858974,
    author        = {Han, Joon Kuy and Wong, Dennis and Fu, Zhoulai and Kang, Byungkon},
    booktitle     = {2024 IEEE 29th Pacific Rim International Symposium on Dependable Computing (PRDC)},
    title         = {AuthZit: Personalized Visual-Spatial and Loci-Tagging Fallback Authentication},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {120--130},
    abstract      = {Designing a fallback authentication that is both memorable and strong poses a challenging task due to the need for authentication secrets to remain secure and easily recallable without frequent reinforcement. This could be especially prevalent for cloud computing security and resiliency. Inspired by the robust visual-spatial memory and associative memory of individuals, we introduce AuthZit, a novel system. AuthZit encodes authentication secrets as paths implementing a fault-tolerant algorithm through a 3D map of real-life places, navigated in both first person and 2D bird's-eye perspective, coupled with a loci-tag (textual secret) associated with the location. Two experiments were conducted to iteratively design and evaluate AuthZit. First, it was observed that visual-spatial secrets are most memorable when navigated through a combination of 3D first-person and 2D bird's-eye view perspectives. Second, we evaluated AuthZit against security questions and Android's 9-dot pattern lock across three dimensions: memorability, security, and speed. AuthZit's complexity-controlled secrets were significantly more memorable after three months, more resilient to shoulder surfing, and close adversaries.},
    keywords      = {Resistance;Fault tolerance;Three-dimensional displays;Navigation;Cloud computing security;Fault tolerant systems;Authentication;Space exploration;Resilience;Investment},
    doi           = {10.1109/PRDC63035.2024.00025},
    issn          = {2473-3105},
    month         = {Nov}
}
@inproceedings{10874329,
    author        = {Zhang, Yao},
    booktitle     = {2024 4th International Signal Processing, Communications and Engineering Management Conference (ISPCEM)},
    title         = {Application of VR Driving Game in Visual Research of Unmanned Car},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {530--533},
    abstract      = {At present, most of the test of unmanned vehicles at home and abroad uses the construction of actual test sites to test the unmanned vehicles. However, the road conditions required for unmanned vehicle tests are relatively high, requiring a large amount of capital and labor. The material resources are very huge, and there are some natural environmental factors beyond human control. In view of the limitations of the above tests, it is of great significance to construct a safe, effective, economical and stable unmanned vehicle test environment. This article mainly studies the application of VR driving games in the visual research of driverless cars. The test environment of this paper includes virtual reality scene module, micro traffic simulation module, virtual reality interaction module, network communication module, and unmanned vehicle module. The unmanned vehicle on the test bench makes corresponding behavior decisions based on the received virtual scene data, and transmits these behavior decision data to the virtual unmanned vehicle in the virtual scene through network communication. The virtual unmanned vehicle operates in a virtual scene after obtaining data such as vehicle speed, heading angle, and brakes. This operating state is used to express the state of the real unmanned vehicle, thereby verifying the intelligence of the real unmanned vehicle. The experiments in this paper show that the network model has a high average accuracy rate under the same test time, and the detection speed can reach 13 frames per second. It can be seen that the overall performance of YOLOv3 is better. The test results show that YOLOv3 algorithm has better accuracy and real-time performance on seven common traffic sign detections.},
    keywords      = {YOLO;Visualization;Solid modeling;Accuracy;Roads;Virtual reality;Games;Traffic control;Autonomous vehicles;Testing;VR;Unmanned Vehicle Driving;Unmanned Vehicle Vision;3D Modeling},
    doi           = {10.1109/ISPCEM64498.2024.00095},
    issn          = {},
    month         = {Nov}
}
@article{8481548,
    author        = {Huang, Wenjia and Terzopoulos, Demetri},
    journal       = {IEEE Transactions on Visualization and Computer Graphics},
    title         = {Door and Doorway Etiquette for Virtual Humans},
    year          = {2020},
    volume        = {26},
    number        = {3},
    pages         = {1502--1517},
    abstract      = {We introduce a framework for simulating a variety of nontrivial, socially motivated behaviors that underlie the orderly passage of pedestrians through doorways, especially the common courtesy of opening and holding doors open for others, an important etiquette that has been overlooked in the literature on autonomous multi-human animation. Emulating such social activity requires serious attention to the interplay of visual perception, navigation in constrained doorway environments, manipulation of a variety of door types, and high-level decision making based on social considerations. To tackle this complex human simulation problem, we take an artificial life approach to modeling autonomous pedestrians, proposing a layered architecture comprising mental, behavioral, and motor layers. The behavioral layer couples two stages: (1) a decentralized, agent-based strategy for dynamically determining the well-mannered ordering of pedestrians around doorways, and (2) a state-based model that directs and coordinates a pedestrian's interactions with the door. The mental layer is a Bayesian network decision model that dynamically selects appropriate door-holding behaviors by considering both internal and external social factors pertinent to pedestrians interacting with one another in and around doorways. Our framework addresses the various door types in common use and supports a variety of doorway etiquette scenarios with efficient, real-time performance.},
    keywords      = {Task analysis;Animation;Visualization;Context modeling;Planning;Real-time systems;Virtual humans;multi-human simulation;behavioral animation;social animation;door and doorway etiquette},
    doi           = {10.1109/TVCG.2018.2874050},
    issn          = {1941-0506},
    month         = {March}
}
@inproceedings{10229055,
    author        = {Meng, Xuanqi and Zhou, Jiarun and Liu, Xiulong and Tong, Xinyu and Qu, Wenyu and Wang, Jianrong},
    booktitle     = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
    title         = {Secur-Fi: A Secure Wireless Sensing System Based on Commercial Wi-Fi Devices},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {1--10},
    abstract      = {Wi-Fi sensing technology plays an important role in numerous IoT applications such as virtual reality, smart homes and elder healthcare. The basic principle is to extract physical features from the Wi-Fi signals to depict the user's locations or behaviors. However, current research focuses more on improving the sensing accuracy but neglects the security concerns. Specifically, current Wi-Fi router usually transmits a strong signal, so that we can access the Internet even through the wall. Accordingly, the outdoor adversaries are able to eavesdrop on this strong Wi-Fi signal, and infer the behavior of indoor users in a non-intrusive way, while the indoor users are unaware of this eavesdropping. To prevent outside eavesdropping, we propose Secur-Fi, a secure Wi-Fi sensing system. Our system meets the following two requirements: (1) we can generate fraud signals to block outside unauthorized Wi-Fi sensing; (2) we can recover the signal, and enable authorized Wi-Fi sensing. We implement the proposed system on commercial Wi-Fi devices and conduct experiments in three applications including passive tracking, behavior recognition, and breath detection. The experiment results show that our proposed approaches can reduce the accuracy of unauthorized sensing by 130\% (passive tracking), 72\% (behavior recognition), 86\% (breath detection).},
    keywords      = {Wireless communication;Wireless sensor networks;Virtual reality;Smart homes;Feature extraction;Sensors;Behavioral sciences;Wi-Fi;Wireless Sensing;Channel State Information},
    doi           = {10.1109/INFOCOM53939.2023.10229055},
    issn          = {2641-9874},
    month         = {May}
}
@inproceedings{9576372,
    author        = {Yigitbas, Enes and Klauke, Jonas and Gottschalk, Sebastian and Engels, Gregor},
    booktitle     = {2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
    title         = {VREUD - An End-User Development Tool to Simplify the Creation of Interactive VR Scenes},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1--10},
    abstract      = {Recent advances in Virtual Reality (VR) technology and the increased availability of VR-equipped devices enable a wide range of consumer-oriented applications. For novice developers, however, creating interactive scenes for VR applications is a complex and cumbersome task that requires high technical knowledge which is often missing. This hinders the potential of enabling novices to create, modify, and execute their own interactive VR scenes. Although recent authoring tools for interactive VR scenes are promising, most of them focus on expert professionals as the target group and neglect the novices with low programming knowledge. To lower the entry barrier, we provide an open-source web-based End-User Development (EUD) tool, called VREUD, that supports the rapid construction and execution of interactive VR scenes. Concerning construction, VREUD enables the specification of the VR scene including interactions and tasks. Furthermore, VREUD supports the execution and immersive experience of the created interactive VR scenes on VR head-mounted displays. Based on a user study, we have analyzed the effectiveness, efficiency, and user satisfaction of VREUD which shows promising results to empower novices in creating their interactive VR scenes.},
    keywords      = {Visualization;Head-mounted displays;Authoring systems;Immersive experience;Tools;Task analysis;Programming profession;Virtual Reality;End-user Development;Authoring;Interactive Scene;Development Tool},
    doi           = {10.1109/VL/HCC51201.2021.9576372},
    issn          = {1943-6106},
    month         = {Oct}
}
@article{10080971,
    author        = {Liu, Jianwei and He, Yinghui and Xiao, Chaowei and Han, Jinsong and Ren, Kui},
    journal       = {IEEE Transactions on Dependable and Secure Computing},
    title         = {Time to Think the Security of WiFi-Based Behavior Recognition Systems},
    year          = {2024},
    volume        = {21},
    number        = {1},
    pages         = {449--462},
    abstract      = {Behavior recognition plays an essential role in numerous behavior-driven applications (e.g., virtual reality and smart home) and even in the security-critical applications (e.g., security surveillance and elder healthcare). Recently, WiFi-based behavior recognition (WBR) technique stands out among many behavior recognition techniques due to its advantages of being non-intrusive, device-free, and ubiquitous. However, existing WBR research mainly focuses on improving the recognition precision, while rarely studying the security aspects. In this article, we reveal that WBR systems are vulnerable to manipulating physical signals. For instance, our observation shows that WiFi signals can be changed by jamming signals. By exploiting the vulnerability, we propose two approaches to generate physically online adversarial samples to perform untargeted attack and targeted attack, respectively. The effectiveness of these attacks are extensively evaluated over four real-world WBR systems. The experiment results show that our attack approaches can achieve 80\% and 60\% success rates for untargeted attack and targeted attack in physical world, respectively. We also show that our attack approaches can be generalized to other WiFi-based sensing applications, such as user authentication.},
    keywords      = {Behavioral sciences;Jamming;Security;Protocols;Wireless fidelity;Transmitters;Feature extraction;Adversarial sample;behavior recognition;genetic algorithm;WiFi},
    doi           = {10.1109/TDSC.2023.3261328},
    issn          = {1941-0018},
    month         = {Jan}
}
@inproceedings{10750102,
    author        = {Rosa, Nina},
    booktitle     = {2024 IEEE VIS Workshop on Visualization for Climate Action and Sustainability (Viz4Climate + Sustainability)},
    title         = {AwARe: Using handheld augmented reality for researching the potential of food resource information visualization},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {10--16},
    abstract      = {Consumers have the potential to play a large role in mitigating the climate crisis by taking on more pro-environmental behavior, for example by making more sustainable food choices. However, while environmental awareness is common among consumers, it is not always clear what the current impact of one's own food choices are, and consequently it is not always clear how or why their own behavior must change, or how important the change is. Immersive technologies have been shown to aid in these aspects. In this paper, we bring food production into the home by means of handheld augmented reality. Using the current prototype, users can input which ingredients are in their meal on their smartphone, and after making a 3D scan of their kitchen, plants, livestock, feed, and water required for all are visualized in front of them. In this paper, we describe the design of the current prototype and, by analyzing the current state of research on virtual and augmented reality for sustainability research, we describe in which ways the application could be extended in terms of data, models, and interaction, to investigate the most prominent issues within environmental sustainability communications research.},
    keywords      = {Solid modeling;Three-dimensional displays;Source coding;Green products;Prototypes;Data visualization;Data models;Sustainable development;Augmented reality;Meteorology;Handheld augmented reality;visualization;food;sustainability},
    doi           = {10.1109/Viz4Climate-Sustainability64680.2024.00006},
    issn          = {},
    month         = {Oct}
}
@inproceedings{10610259,
    author        = {Riechmann, Malte and Kirsch, Andr\'{e} and Koenig, Matthias and Rexilius, Jan},
    booktitle     = {2024 IEEE International Conference on Robotics and Automation (ICRA)},
    title         = {Virtual Borders in 3D: Defining a Drone's Movement Space Using Augmented Reality},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {15202--15208},
    abstract      = {Robots are increasingly finding their way into home environments, where they can assist with household tasks like vacuuming or surveilling. While the robots can navigate on their own, users might not want them to go everywhere or not in a specific way. For example, users might not want a drone to fly over a table where important letters and the newspaper are stored, even though it is the shortest path to the goal. Therefore, an application is required, that is easy to learn and to apply even for inexperienced users.In this paper, we present a framework that uses a tablet as augmented reality (AR) device to modify a robot's movement space in 3D. A user can define virtual borders in the real world with the tablet and add them to a map, changing the navigational behavior of the robot. The framework is evaluated by a user study with inexperienced participants that verifies our approach. Further analyses show, that even complex scenarios can be covered with our framework.},
    keywords      = {Three-dimensional displays;Navigation;Task analysis;Robots;Augmented reality;Drones},
    doi           = {10.1109/ICRA57147.2024.10610259},
    issn          = {},
    month         = {May}
}
@inproceedings{10515452,
    author        = {Sri, Bande Bhavya and Amulya, Kadamati Dharani Naga Sai and Pallapothu, Beulah and Rao, M.V.L.N. Raja and P, Siva Satya Sreedhar and Abirami, A.},
    booktitle     = {2024 International Conference on Distributed Computing and Optimization Techniques (ICDCOT)},
    title         = {Revolutionizing User Experience for Product Quality Evaluation using AR/VR and NLP},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {The research work proposes an important change technique that could transform User Experience (UX) evaluation by overcoming the limits of existing systems. Existing systems, which depend on traditional testing and surveys, usually fail to provide a complete understanding of user interactions. The proposed system creates immersive interfaces using Augmented Reality (AR), Virtual Reality (VR), and Natural Language Processing (NLP), while also obtaining qualitative feedback from user comments. Algorithmic analytics and machine learning algorithms enable reliable quantification of user activity. Real-time monitoring and iterative improvement cycles allow for dynamic responsiveness. A comparative investigation shows that the suggested system outperforms AR/VR immersion, NLP sentiment analysis, and algorithmic analytics. Efficiency measures such as accuracy (0.90), precision (0.92), recall (0.88), and F1 Score (0.90) demonstrate that it exceeds systems. The study proposes an innovative, user-centric solution set for rethinking UX evaluation, resulting in an in-depth knowledge of product quality in an ever-changing digital environment.},
    keywords      = {Sentiment analysis;Machine learning algorithms;Heuristic algorithms;Transforms;User experience;Product design;Real-time systems;Revolutionizing User Experience;Product Quality Evaluation;Innovative Interfaces;Natural Language Processing;Comparative Analysis;User-centric Design},
    doi           = {10.1109/ICDCOT61034.2024.10515452},
    issn          = {},
    month         = {March}
}
@inproceedings{10006967,
    author        = {Firman, Antares and Muktiyanto, Ali and Inan, Dedi I. and Juita, Ratna and Beydoun, Ghassan and Daryono},
    booktitle     = {2022 Seventh International Conference on Informatics and Computing (ICIC)},
    title         = {UT Metaverse: Beyond Universitas Terbuka Governance Transformation and Open Challenges},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {The Open and Distance Learning (ODL) system as we know is among the field that will be altered by Metaverse technology due to the benefits it offers. Various initiatives for embracing the Metaverse for distance learning are now underway. Universitas Terbuka (UT), the earliest government-mandated university for managing ODL in Indonesia, is also now at the first stage of preparing to harness the benefit of the Metaverse. This initiative is called Universitas Terbuka Metaverse (UT Verse), a Metaverse framework architecture developed by UT encompassing all its business processes. Towards this purpose, UT Verse Audit Centre (UTVAC), an instantiation as a sub-UT Verse, is proposed. This paper presents the complete architecture of the UT Verse as the foundation of the UT governance transformation to be a cyber university and the initiative for the VAC. As both initiatives are still in their infancy, we aim to share our lessons learnt and highlight the challenges to obtain feedback for mitigating their ongoing developments as earlier as possible which might be costly otherwise.},
    keywords      = {Computer aided instruction;Metaverse;Computer architecture;Informatics;Business;Universitas Terbuka;Open University;Metaverse;Virtual Audit Centre;University Governance Transformation},
    doi           = {10.1109/ICIC56845.2022.10006967},
    issn          = {},
    month         = {Dec}
}
@inproceedings{9294359,
    author        = {Epple, N. and Hankofer, T. and Riener, A.},
    booktitle     = {2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
    title         = {Scenario Classes in Naturalistic Driving: Autoencoder-based Spatial and Time-Sequential Clustering of Surrounding Object Trajectories},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {Surrounding vehicles are among the essential features to describe traffic scenarios. Besides maneuver (e.g., turn) and scene (e.g., highway), these features are hard to capture in words or labels. The recognition and evaluation of these scenario features are important for road safety. Consequently, when analyzing naturalistic driving data, the composition of the scenarios is essential in order to be able to evaluate driver behavior, and the effects of the overall system quantitatively. In this work, we propose a method to group surrounding vehicles from the perspective of the ego-vehicle and use it for an improved scenario classification. In a two-step approach, we group each vehicle within a scenario independently. We separate the spatial domain (driving tube) from the time domain (performance style). The spatial domain is clustered using a hierarchical ward algorithm to allow for variation of the cluster depth. With the merged result, we realize an outlier detection and a method to quantify the frequency of trajectories within scenarios. From this, the uniqueness of scenarios, e.g., for resimulation, is quantified. This enables us to identify clusters of similar maneuvers of surrounding vehicles up to, for example, lane change maneuver groups of the same speed and acceleration course.},
    keywords      = {Clustering algorithms;Electron tubes;Classification algorithms;Trajectory;Shape;Convolutional codes;Unsupervised learning},
    doi           = {10.1109/ITSC45102.2020.9294359},
    issn          = {},
    month         = {Sep.}
}
@inproceedings{9089930,
    author        = {Maldonato, Nelson Mauro and Bottone, Mario and Sperandeo, Raffaele and Scandurra, Cristiano and Bochicchio, Vincenzo and Cappuccio, Massimiliano Lorenzo and Esposito, Antonietta M. and Muzii, Benedetta},
    booktitle     = {2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)},
    title         = {The biodynamic stress hypothesis Towards an evolutionary psychology paradigm},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {369--374},
    abstract      = {In recent decades, stress has played a prominent role in terms of how the individual views the world and in the sphere of public health policies. Expressions such as ``being stressed'', ``reducing stress'' and so on abound in individual communication. Recently, the World Health Organization, with the ICD 11, formally recognized stress as a central contributor to the ``burn out syndrome''. Despite these advances, scientific discussion on stress has made little progress due to a significant number of issues related to its definition, the nature of normal or pathological responses and its neurobiological basis, each of which must be kept quite separate from those related to psychiatric and medical disorders related to stress. In this article we shall try to a) define stress in a scientifically adequate and rigorous manner; b) describe stress (and stress response) in its normal individual phenomenology, including behavioral and biological changes during a response to a stressful event; c) formulate some hypotheses on the psychobiological basis of stress in the light of the biodynamic stress hypothesis; d) analyze the consequences of stress at an early age; e) detect implications for the development of new IC technologies.},
    keywords      = {Stress;Diseases;Psychology;Integrated circuits;Genetics;Homeostasis;Neuroscience;diathesis;stress;adaptation;vulnerability;adrenocortical dysregulation},
    doi           = {10.1109/CogInfoCom47531.2019.9089930},
    issn          = {2380-7350},
    month         = {Oct}
}
@article{7254253,
    author        = {Lee, Jae Woong and Cho, Seoungjae and Liu, Sirui and Cho, Kyungeun and Helal, Sumi},
    journal       = {IEEE Transactions on Automation Science and Engineering},
    title         = {Persim 3D: Context-Driven Simulation and Modeling of Human Activities in Smart Spaces},
    year          = {2015},
    volume        = {12},
    number        = {4},
    pages         = {1243--1256},
    abstract      = {Automated understanding and recognition of human activities and behaviors in a smart space (e.g., smart house) is of paramount importance to many critical human-centered applications. Recognized activities are the input to the pervasive computer (the smart space) which intelligently interacts with the users to maintain the application's goal be it assistance, safety, child-development, entertainment or other goals. Research in this area is fascinating but severely lacks adequate validation which often relies on datasets that contain sensory data representing the activities. Availing adequate datasets that can be used in a large variety of spaces, for different user groups, and aiming at different goals is very challenging. This is due to the prohibitive cost and the human capital needed to instrument physical spaces and to recruit human subjects to perform the activities and generate data. Simulation of human activities in smart spaces has therefore emerged as an alternative approach to bridge this deficit. Traditional event-driven approaches have been proposed. However, the complexity of human activity simulation was proved to be challenging to these initial simulation efforts. In this paper, we present Persim 3D-an alternative context-driven approach to simulating human activities capable of supporting complex activity scenarios. We present the context-activity-action nexus and show how our approach combines modeling and visualization of actions with context and activity simulation. We present the Persim 3D architecture and algorithms, and describe a detailed validation study of our approach to verify the accuracy and realism of the simulation output (datasets and visualizations) and the scalability of the human effort in using Persim 3D to simulate complex scenarios. We show positive and promising results that validate our approach.},
    keywords      = {Context-aware services;Digital simulation;Smart homes;Sensor systems;Pervasive computing;Graphical user interfaces;Ubiquitous computing;Context-aware services;digital simulation;graphical user interfaces;pervasive computing;sensor systems;smart homes;ubiquitous computing},
    doi           = {10.1109/TASE.2015.2467353},
    issn          = {1558-3783},
    month         = {Oct}
}
@inproceedings{9757381,
    author        = {Guan, Jie and Irizawa, Jay and Morris, Alexis},
    booktitle     = {2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Extended Reality and Internet of Things for Hyper-Connected Metaverse Environments},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {163--168},
    abstract      = {The Metaverse encompasses technologies related to the internet, virtual and augmented reality, and other domains toward smart interfaces that are hyper-connected, immersive, and engaging. However, Metaverse applications face inherent disconnects between virtual and physical components and interfaces. This work explores how an Extended Metaverse framework can be used to increase the seamless integration of interoperable agents between virtual and physical environments. It contributes an early theory and practice toward the synthesis of virtual and physical smart environments anticipating future designs and their potential for connected experiences.},
    keywords      = {Three-dimensional displays;Extended reality;Conferences;User interfaces;Ambient intelligence;Internet of Things;Faces;Metaverse;mixed reality;internet-of-things;agents;Human-centered computing – Mixed / augmented reality;Human-centered computing – Virtual reality;Human-centered computing – Ambient intelligence},
    doi           = {10.1109/VRW55335.2022.00043},
    issn          = {},
    month         = {March}
}
@inbook{10952673,
    author        = {Rashidi, Sol},
    booktitle     = {Your AI Survival Guide: Scraped Knees, Bruised Elbows, and Lessons Learned from Real-World AI Deployments},
    title         = {What the Future Holds},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {191--199},
    abstract      = {Summary <p>While artificial intelligence's (AI) impact on employment has been a concern, the future may see a shift toward AI creating new job categories. As AI automates routine tasks, the emphasis will shift to roles that require human creativity, empathy, and strategic thinking, reshaping the workforce landscape. In the realm of cybersecurity, AI\&\#x2010;driven security systems will become more sophisticated in detecting and responding to threats and anomalies. These systems will proactively identify vulnerabilities and respond to security incidents in real time, providing a more robust defense against cyber threats. While most of the AI applications are still in research labs, we will see a surge of products hitting the market to help with virtual reality therapy, digital therapists, teletherapy, medication management, and cognitive behavioral therapy. Artificial super intelligence represents an AI system that surpasses artificial general intelligence and doesn't require human intervention for results, answers, or outputs.</p>},
    keywords      = {Artificial intelligence;Business;Ethics;Market research;Machine learning;Home appliances;Computer security;Companies;Surges;Scalability},
    doi           = {},
    issn          = {},
    publisher     = {Wiley},
    isbn          = {9781394272655},
    url           = {https://ieeexplore.ieee.org/document/10952673}
}
@inproceedings{8052644,
    author        = {Heryadi, Yaya and Robbany, Ahmad Zakky and Sudarma, Hantze},
    booktitle     = {2016 1st International Conference on Game, Game Art, and Gamification (ICGGAG)},
    title         = {User experience evaluation of virtual reality-based cultural gamification using GameFlow approach},
    year          = {2016},
    volume        = {},
    number        = {},
    pages         = {1--5},
    abstract      = {This paper presents some empiric results on the effect of some game player profiles to their user experience. The cultural gamification prototype for this study is developed using Virtual Reality technology on Google Cardboard in which some elements of Indonesian culture is used in part of the game story. Dataset for the game evaluation is collected using survey method. Data collection is implemented using self-administered questionnaire which is developed based on GameFlow framework. The respondent population is the college students who like to play games. The survey samples are chosen using purposive sampling technique. The results of this study indicate that there is a strong association of playing frequency and personality traits to game user experiences. Also, there is a weak association between gender and age to game user experiences. These research findings are valuable for game designer to design enjoyable and educational games.},
    keywords      = {Games;Mathematical model;Solid modeling;Cultural differences;Prototypes;Instruments;Cultural Gamification;User Experience Evaluation;GameFlow},
    doi           = {10.1109/ICGGAG.2016.8052644},
    issn          = {},
    month         = {Dec}
}
@article{10132042,
    author        = {Yoshida, Kyle T. and Kiernan, Joel X. and Adenekan, Rachel A. G. and Trinh, Steven H. and Lowber, Alexis J. and Okamura, Allison M. and Nunez, Cara M.},
    journal       = {IEEE Transactions on Haptics},
    title         = {Cognitive and Physical Activities Impair Perception of Smartphone Vibrations},
    year          = {2023},
    volume        = {16},
    number        = {4},
    pages         = {672--679},
    abstract      = {Vibration feedback is common in everyday devices, from virtual reality systems to smartphones. However, cognitive and physical activities may impede our ability to sense vibrations from devices. In this study, we develop and characterize a smartphone platform to investigate how a shape-memory task (cognitive activity) and walking (physical activity) impair human perception of smartphone vibrations. We measured how Apple's Core Haptics Framework parameters can be used for haptics research, namely how hapticIntensity modulates amplitudes of 230 Hz vibrations. A 23-person user study found that physical ($p< 0.001$) and cognitive ($p=0.012$) activity increase vibration perception thresholds. Cognitive activity also increases vibration response time ($p< 0.001$). This work also introduces a smartphone platform that can be used for out-of-lab vibration perception testing. Researchers can use our smartphone platform and results to design better haptic devices for diverse, unique populations.},
    keywords      = {Vibrations;Task analysis;Haptic interfaces;Shape measurement;Fingers;Legged locomotion;Cognitive systems;Smart phones;Vibration;perception;cognitive activity;physical activity;smartphone;mobile},
    doi           = {10.1109/TOH.2023.3279201},
    issn          = {2329-4051},
    month         = {Oct}
}
@article{8794519,
    author        = {Randhavane, Tanmay and Bera, Aniket and Kapsaskis, Kyra and Gray, Kurt and Manocha, Dinesh},
    journal       = {IEEE Transactions on Visualization and Computer Graphics},
    title         = {FVA: Modeling Perceived Friendliness of Virtual Agents Using Movement Characteristics},
    year          = {2019},
    volume        = {25},
    number        = {11},
    pages         = {3135--3145},
    abstract      = {We present a new approach for improving the friendliness and warmth of a virtual agent in an AR environment by generating appropriate movement characteristics. Our algorithm is based on a novel data-driven friendliness model that is computed using a user-study and psychological characteristics. We use our model to control the movements corresponding to the gaits, gestures, and gazing of friendly virtual agents (FVAs) as they interact with the user's avatar and other agents in the environment. We have integrated FVA agents with an AR environment using with a Microsoft HoloLens. Our algorithm can generate plausible movements at interactive rates to increase the social presence. We also investigate the perception of a user in an AR setting and observe that an FVA has a statistically significant improvement in terms of the perceived friendliness and social presence of a user compared to an agent without the friendliness modeling. We observe an increment of 5.71\% in the mean responses to a friendliness measure and an improvement of 4.03\% in the mean responses to a social presence measure.},
    keywords      = {Task analysis;Psychology;Computational modeling;Three-dimensional displays;Skeleton;Computer science;Avatars;Social perception;intelligent virtual agents;friendliness;gaits;gestures;gazing},
    doi           = {10.1109/TVCG.2019.2932235},
    issn          = {1941-0506},
    month         = {Nov}
}
@inproceedings{9926423,
    author        = {Meyer, Joel and Pinosky, Allison and Trzpit, Thomas and Colgate, Ed and Murphey, Todd D.},
    booktitle     = {2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)},
    title         = {A Game Benchmark for Real-Time Human-Swarm Control},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {743--750},
    abstract      = {We present a game benchmark for testing human-swarm control algorithms and interfaces in a real-time, high-cadence scenario. Our benchmark consists of a swarm vs. swarm game in a virtual ROS environment in which the goal of the game is to "capture" all agents from the opposing swarm; the game's high-cadence is a result of the capture rules, which cause agent team sizes to fluctuate rapidly. These rules require players to consider both the number of agents currently at their disposal and the behavior of their opponent's swarm when they plan actions. We demonstrate our game benchmark with a default human-swarm control system that enables a player to interact with their swarm through a high-level touchscreen interface. The touchscreen interface transforms player gestures into swarm control commands via a low-level decentralized ergodic control framework. We compare our default human-swarm control system to a flocking-based control system, and discuss traits that are crucial for swarm control algorithms and interfaces operating in real-time, high-cadence scenarios like our game benchmark. Our game benchmark code is available on Github; more information can be found at https://sites.google.com/view/swarm-game-benchmark},
    keywords      = {Computer aided software engineering;Codes;Games;Transforms;Benchmark testing;Touch sensitive screens;Control systems},
    doi           = {10.1109/CASE49997.2022.9926423},
    issn          = {2161-8089},
    month         = {Aug}
}
@inproceedings{9827886,
    author        = {Rahman, M. Mahbubur and Martelli, Dario and Gurbuz, Sevgi Z.},
    booktitle     = {2022 IEEE 12th Sensor Array and Multichannel Signal Processing Workshop (SAM)},
    title         = {Gait Variability Analysis with Multi-Channel FMCW Radar for Fall Risk Assessment},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {345--349},
    abstract      = {Early detection of fall risk in homes and assisted living facilities is essential in preventing debilitating injuries and improving the quality of life of older adults. Several studies have found increased gait variability among community-living older adults with a history of falls. Quantitative 3D gait analysis in laboratories equipped with motion capture devices can be used to record and extract stride-to-stride gait fluctuations that are indicative of fall risk. Such facilities are very expensive, may not be easily accessible for aging and rural communities. Wearable sensors are a cheaper alternative to observe gait in natural settings; however, it can suffer from drift or other inaccuracies. RF sensors can be a game changer to reduce healthcare costs and disparities, improve quality of care, and facilitate aging-in-place by enabling frequent estimation of gait variability in natural settings. In particular, multi-channel frequency modulated continuous wave (FMCW) radar can be used to characterize gait and detect gait abnormalities. In this paper, multi-channel FMCW radar is used to measure gait dynamics in terms of step-time variability. The accuracy of RF measurements is validated via comparison with gold standards, such as the Vicon motion capture camera system. Step-time variability was compared for both normal walking and walking during visual perturbations generated through the use of a virtual reality headset. The accuracy of RF measurement is evaluated for single and multiple channel processing. Our results demonstrate that multi-channel RF sensors can be an effective tool for gait variability assessment in natural, in-home settings.},
    keywords      = {Radio frequency;Legged locomotion;Radar measurements;Radar;Particle measurements;Motion capture;Risk management;gait variability;RF sensor;Vicon;FMCW Radar},
    doi           = {10.1109/SAM53842.2022.9827886},
    issn          = {2151-870X},
    month         = {June}
}
@inproceedings{7350729,
    author        = {Lu, Ching-Hu},
    booktitle     = {2015 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design},
    title         = {IoT-enhanced and Bidirectionally Interactive Information Visualization for Context-Aware Home Energy Savings},
    year          = {2015},
    volume        = {},
    number        = {},
    pages         = {15--20},
    abstract      = {In recent years, due to deteriorating global warming, there has been increasing attention to home energy savings, which is often a serious and not so interesting task. In this regard, we proposed a playful and bidirectionally interactive eco-feedback with three kinds of information visualization integrated with a 3D pet-raising game, which synchronously visualizes the information of the physical environment with the virtual environment by leveraging IoT (Internet of Things) enabled technologies in hopes of enhancing user experience and prolonging users' engagement in energy savings. In addition to mere mapping from physical to virtual environment for traditional game-based energy savings, this study also makes use of the other direction to form a bidirectional mapping to empower users to allow direct and flexible remote control anywhere and anytime in a more natural and playful way. Furthermore, integrating context-awareness with the bidirectional mapping in an energy-saving system also enhances the immersive experience of the users.},
    keywords      = {Home appliances;Visualization;Positron emission tomography;Avatars;Sensors;Games;Game-based eco-feedback;IoT;Physical-cyber system;Context-awareness;Mixed Reality},
    doi           = {10.1109/ISMAR-MASHD.2015.20},
    issn          = {},
    month         = {Sep.}
}
@article{8768328,
    author        = {Taleb Zadeh Kasgari, Ali and Saad, Walid and Debbah, M\'{e}rouane},
    journal       = {IEEE Transactions on Communications},
    title         = {Human-in-the-Loop Wireless Communications: Machine Learning and Brain-Aware Resource Management},
    year          = {2019},
    volume        = {67},
    number        = {11},
    pages         = {7727--7743},
    abstract      = {Human-centric applications such as virtual reality and immersive gaming are central to future wireless networks. Common features of such services include: 1) their dependence on the human user's behavior and state and 2) their need for more network resources compared to conventional applications. To successfully deploy such applications over wireless networks, the network must be made cognizant of not only the quality-of-service (QoS) needs of the applications, but also of the perceptions of the human users on this QoS. In this paper, by explicitly modeling the limitations of the human brain, a concrete measure for the delay perception of human users is introduced. Then, a learning method, called probability distribution identification, is developed to find a probabilistic model for this delay perception based on the brain features of a human user. Given the learned model for the delay perception of the human brain, a brain-aware resource management algorithm based on Lyapunov optimization is proposed for allocating radio resources to human users while minimizing the transmit power and taking into account the reliability of both machine type devices and human users. Then, a closed-form relationship between the reliability measure and wireless physical layer metrics of the network is derived. Simulation results show that a brain-aware approach can yield savings of up to 78\% in power compared to the system that only considers QoS metrics. The results also show that, compared with QoS-aware, brain-unaware systems, the brain-aware approach can save substantially more power in low-latency systems.},
    keywords      = {Delays;Resource management;Quality of service;Brain modeling;Reliability;Wireless networks;Virtual reality (VR);brain;wireless networks;low latency communications;cellular networks},
    doi           = {10.1109/TCOMM.2019.2930275},
    issn          = {1558-0857},
    month         = {Nov}
}
@inproceedings{10174151,
    author        = {Malik, Sehrish and Naqvi, Moeen Ali and Moonen, Leon},
    booktitle     = {2023 IEEE/ACM 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)},
    title         = {CHESS: A Framework for Evaluation of Self-Adaptive Systems Based on Chaos Engineering},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {195--201},
    abstract      = {There is an increasing need to assess the correct behavior of self-adaptive and self-healing systems due to their adoption in critical and highly dynamic environments. However, there is a lack of systematic evaluation methods for self-adaptive and self-healing systems. We proposed CHESS, a novel approach to address this gap by evaluating self-adaptive and self-healing systems through fault injection based on chaos engineering (CE).The artifact presented in this paper provides an extensive overview of the use of CHESS through two microservice-based case studies: a smart office case study and an existing demo application called Yelb. It comes with a managing system service, a self-monitoring service, as well as five fault injection scenarios covering infrastructure faults and functional faults. Each of these components can be easily extended or replaced to adopt the CHESS approach to a new case study, help explore its promises and limitations, and identify directions for future research.},
    keywords      = {Chaos;Systematics;Adaptive systems;Autonomous systems;Microservice architectures;Behavioral sciences;Software engineering;self-healing;resilience;chaos engineering;evaluation;artifact},
    doi           = {10.1109/SEAMS59076.2023.00033},
    issn          = {2157-2321},
    month         = {May}
}
@article{10214414,
    author        = {Khodabandelou, Ghazaleh and Chibani, Abdelghani and Amirat, Yacine and Tanimoto, Steven},
    journal       = {IEEE Transactions on Automation Science and Engineering},
    title         = {A Recurrent Neural Network Optimization Method for Anticipation of Hierarchical Human Activity},
    year          = {2024},
    volume        = {21},
    number        = {3},
    pages         = {4657--4673},
    abstract      = {Human activity anticipation is a pillar of new interactive multimedia technologies. It enables better human-computer interaction and creative sensory experience in all types of virtual reality-based multimedia applications. Human behaviors are hierarchically constituted in terms of low-level and high-level activities. Fine-grained activities play a substantial role in the early recognition of simple and complex human movements in real-time with low latency, allowing longer predictions in the future. In this paper, a new objective function is proposed to anticipate fine-grained human activities using IMU data, which still suffers from an imbalance problem. Four customized objective surrogate functions are applied in unidirectional and bidirectional recurrent neural networks and compared to efficiently optimize the model considering the loss of individual classes. The experiments on five datasets across proposed loss functions show that the proposed model significantly outperforms the counterpart methods and advances the state-of-the-art. The proposed model shows accuracy scores of up to 98\% and 96\% for high-level and low-level activities, respectively. Note to Practitioners--There are a large number of methods that can be used for the recognition of human activity in assisted living, smart home technologies, and pervasive healthcare applications. However, studies on these methods tend to focus on recognition rather than anticipation of human activity. Furthermore, they use either vision-based or egocentric video data, which can make it challenging to collect and evaluate in virtual reality-based scenarios. To enable more natural interaction with physical and virtual reality environments, virtual reality-based technologies require built-in algorithms capable of consistently identifying complex and varied human movements. Fine-grained activities are paramount in predicting activities at an early stage to adequately characterize human behaviors. In this paper, a study is conducted to anticipate fine-grained human activity based on IMU (Inertial Measurement Unit) data, which are still subject to the negative effects of an imbalanced sample distribution. The proposed model is evaluated on different benchmarks and compared with baseline methods. The results show that the proposed model outperforms all baselines. These results have important implications for human activity prediction problems.},
    keywords      = {Solid modeling;Behavioral sciences;Visualization;Prediction algorithms;Virtual reality;Reliability;Recurrent neural networks;Human activity anticipation;recurrent neural networks;fine-grained activities;imbalanced data;customized objective functions},
    doi           = {10.1109/TASE.2023.3300821},
    issn          = {1558-3783},
    month         = {July}
}
@inproceedings{8717157,
    author        = {Gehrke, Lukas and Guerdan, Luke and Gramann, Klaus},
    booktitle     = {2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)},
    title         = {Extracting Motion-Related Subspaces from EEG in Mobile Brain/Body Imaging Studies using Source Power Comodulation},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {344--347},
    abstract      = {Mobile Brain/Body Imaging (MoBI) is an emerging non-invasive approach to investigate human brain activity and motor behavior associated with cognitive processes in natural conditions. MoBI studies and analyses pipelines combine brain measurements, e.g. Electroencephalography (EEG), with motion data as participants conduct tasks with near-natural behavior. Within the field however, standard source decomposition and reconstruction pipelines largely rely on unsupervised blind source separation (BSS) approaches and do not consider movement information to guide the decomposition of oscillatory brain sources. We propose the use of a supervised spatial filtering method, Source Power Co-modulation (SPoC), for extracting source components that co-modulate with body motion. Further, we introduce a method to validate the quality of oscillatory sources in MoBI studies. We illustrate the approach to investigate the link between hand and head movement kinematics and power dynamics of EEG sources while participants explore an invisible maze in virtual reality. Stable oscillatory source envelopes correlating with hand and head motion were isolated in all subjects, with median \ensuremath{\rho} = .13 for all sources and median \ensuremath{\rho} = .16 for sources passing the selection criteria. The results indicate that it is possible to improve movement related source separation to further guide our understanding of how movement and brain dynamics interact.},
    keywords      = {Electroencephalography;Correlation;Task analysis;Acceleration;Imaging;Brain;Blind source separation},
    doi           = {10.1109/NER.2019.8717157},
    issn          = {1948-3554},
    month         = {March}
}
@article{9081967,
    author        = {Kim, Hyunjin and Hong, Sang and Kim, Jinsul and Ryou, Jaecheol},
    journal       = {IEEE Access},
    title         = {Intelligent Application Protection Mechanism for Transportation in V2C Environment},
    year          = {2020},
    volume        = {8},
    number        = {},
    pages         = {86777--86787},
    abstract      = {The emergence of vehicle-to-cloud (V2C) technology is changing cloud computing and transportation ecosystems. V2C technology enables the development of smart services, such as driving assistance and vehicle maintenance, that transmit information to the driver. Recent studies have primarily focused on services. To date, there has not been sufficient research on security functions to detect abnormal behaviors on virtual application. If an abnormal behavior occurs in the application, the service not only notices the wrong information to driver, but also affects the transportation system around the vehicle. To defend against distributed denial of service (DDoS) attacks, system resources should be monitored constantly. However, continuous monitoring is difficult because V2C services change dynamically according to the service environment. In addition, rule-based or supervised monitoring is impossible for each of the numerous services provided by a cloud computing center. In this paper, we propose an intelligent application protection mechanism for smart vehicle services in a V2C environment that detects abnormal behavior through image-based system resource monitoring using artificial intelligence (ISRM-AI) to improve cloud vehicle service security. The ISRM-AI generates images about system information such as CPU, network, memory on V2C cloud services. Also, the mechanism analyzes the status using a convolutional neural network (CNN) to detect abnormal behavior of the each services. We constructed a service environment to test the performance of the proposed mechanism. In addition, we simulated the proposed mechanism's ability to detect DDoS attacks using real attack data. The proposed mechanism guarantees the reliability of a smart service by enhancing the security of the V2C environment.},
    keywords      = {Cloud computing;Denial-of-service attack;Monitoring;Transportation;Computer crime;Bandwidth;Vehicle to cloud;V2C service;cloud computing;detection mechanism;transportation;artificial intelligence},
    doi           = {10.1109/ACCESS.2020.2991273},
    issn          = {2169-3536},
    month         = {}
}
@inproceedings{9212946,
    author        = {Hu, Tao and Meng, Wenming and Li, Shuai},
    booktitle     = {2019 International Conference on Virtual Reality and Visualization (ICVRV)},
    title         = {Extract Accurate 3D Human Skeleton from Video},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {100--107},
    abstract      = {Extracting 3D skeletons from video faces more problems than extracting 3D skeletons from images. For example, there will be more motion blur and occlusion in the video. But video also has its own unique properties and there is a strong similarity between frames in the video. In this article, we focus on maximizing the utilization of temporal information in the video to extract the accurate 3D human skeleton. Our system is divided into three parts. The first part utilizes unsupervised learning method to split the video into a serious of sub-video according to the content. Human pose has high similarity in this sub-video. The second part is to detect the 2D skeleton in this divided sub-video. In order to establish the connection between the frames and ensure the efficiency, we adopt the convLSTM model [38] in this module. The last part is to map the 2D skeleton sequence detected in the previous step into 3D space, the input is 2D joint point sequence, and the output is the corresponding 3D joint point sequence. In this module, we choose one-dimensional convolution model. This model can build the relationship between frames in the nearby areas of each frame.},
    keywords      = {Three-dimensional displays;Two dimensional displays;Skeleton;Feature extraction;Solid modeling;Pose estimation;Predictive models;3D Human Pose Estimation;Using Temporary Information;Sequential model;Video Key Frame Detect},
    doi           = {10.1109/ICVRV47840.2019.00025},
    issn          = {2375-141X},
    month         = {Nov}
}
@inproceedings{10581264,
    author        = {Kamal, Saleha and Jalal, Ahmad},
    booktitle     = {2024 International Conference on Engineering \& Computing Technologies (ICECT)},
    title         = {Multi-Feature Descriptors for Human Interaction Recognition in Outdoor Environments},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {In recent years, Artificial intelligence has gained significant attention in automatically recognizing human interaction. Thus, leading researchers to develop efficient Human Interaction Recognition (HIR) systems. Efficient feature extraction is the key to developing a system that achieves higher accuracies. Feature extraction emphasizes identifying robust features that can effectively distinguish various human behaviors. This paper introduces a novel approach enabling machines to understand human behaviors in an outdoor environment to recognize human interactions efficiently. This research aims to extract key body points from human silhouettes for robust spatio-temporal features that exhibit unique characteristics for each interaction. Our proposed human interaction recognition (HIR) system recognizes six complex human interactions taken from UT - Interaction dataset i.e. handshake, punch, kick, point, hug, and push. We have designed hybrid feature algorithms and a multiclass support vector machine (SVM) for interaction recognition. To evaluate our system's performance, we have computed Mean recognition accuracy and compared it with other state-of-the-art classifiers. The experimental results showcase the reliability of our proposed approach in handling complex real-world scenarios. Thus, making it applicable to vast domains such as smart homes, violence detection, security systems, and surveillance.},
    keywords      = {Support vector machines;Computers;Solid modeling;Accuracy;Surveillance;System performance;Virtual reality;Spatio-temporal features;key body points;human interaction recognition;support vector machine},
    doi           = {10.1109/ICECT61618.2024.10581264},
    issn          = {},
    month         = {May}
}
@inproceedings{10660991,
    author        = {Winkle, Katie and Mulvihill, Natasha},
    booktitle     = {2024 19th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
    title         = {Anticipating the Use of Robots in Domestic Abuse: A Typology of Robot Facilitated Abuse to Support Risk Assessment and Mitigation in Human-Robot Interaction},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {781--790},
    abstract      = {Domestic abuse research demonstrates that perpetrators are agile in finding new ways to coerce and to consolidate their control. They may leverage loved ones or cherished objects, and are increasingly exploiting and subverting what have become everyday `smart' technologies. Robots sit at the intersection of these categories: they bring together multiple digital and assistive functionalities in a physical body, often explicitly designed to take on a social companionship role. We present a typology of robot facilitated abuse based on these unique affordances, designed to support systematic risk assessment, mitigation and design work. Whilst most obviously relevant to those designing robots for in-home deployment or intrafamilial interactions, the ability to coerce can be wielded by those who have any form of social power, such that our typology and associated design reflections may also be salient for the design of robots to be used in the school or workplace, between carers and the vulnerable, elderly and disabled and/or in institutions which facilitate intimate relations of care.CCS CONCEPTS\textbullet{} Human-centered computing \rightarrow{} Auditory feedback; User studies; \textbullet{} Computer systems organization\rightarrow{}Robotics;\textbullet{} Applied computing\rightarrow{}Sound and music computing.},
    keywords      = {Human computer interaction;Systematics;Prevention and mitigation;Affordances;Employment;Human-robot interaction;Reflection;trustworthy AI;safety;robot abuse;domestic abuse;feminism},
    doi           = {},
    issn          = {2167-2121},
    month         = {March}
}
@inproceedings{10039424,
    author        = {Hafi, Lotfi El and Zheng, Youwei and Shirouzu, Hiroshi and Nakamura, Tomoaki and Taniguchi, Tadahiro},
    booktitle     = {2023 IEEE/SICE International Symposium on System Integration (SII)},
    title         = {Serket-SDE: A Containerized Software Development Environment for the Symbol Emergence in Robotics Toolkit},
    year          = {2023},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {The rapid deployment of intelligent robots to perform service tasks has become an increasingly complex challenge for researchers due to the number of disciplines and skills involved. Therefore, this paper introduces Serket-SDE, a containerized Software Development Environment (SDE) for the Symbol Emergence in Robotics Toolkit (Serket) that relies on open-source technologies to build cognitive robotic systems from multimodal sensor observations. The main contribution of Serket-SDE is an integrated framework that allows users to rapidly compose, scale, and deploy probabilistic generative models with robots. The description of Serket-SDE is accompanied by demonstrations of unsupervised multimodal categorizations using a mobile robot in various simulation environments. Further extensions of the Serket-SDE framework are discussed in conclusion based on the demonstrated results.},
    keywords      = {Multimodal sensors;Symbols;Virtual environments;Documentation;System integration;Robot sensing systems;Software},
    doi           = {10.1109/SII55687.2023.10039424},
    issn          = {2474-2325},
    month         = {Jan}
}
@inproceedings{9982244,
    author        = {Ye, Ruolin and Xu, Wenqiang and Fu, Haoyuan and Jenamani, Rajat Kumar and Nguyen, Vy and Lu, Cewu and Dimitropoulou, Katherine and Bhattacharjee, Tapomayukh},
    booktitle     = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    title         = {RCare World: A Human-centric Simulation World for Caregiving Robots},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {33--40},
    abstract      = {We present RCareWorld, a human-centric simulation world for physical and social robotic caregiving designed with inputs from stakeholders. RCareWorld has realistic human models of care recipients with mobility limitations and caregivers, home environments with multiple levels of accessibility and assistive devices, and robots commonly used for caregiving. It interfaces with various physics engines to model diverse material types necessary for simulating caregiving scenarios, and provides the capability to plan, control, and learn both human and robot control policies by integrating with state-of-the-art external planning and learning libraries, and VR devices. We propose a set of realistic caregiving tasks in RCareWorld as a benchmark for physical robotic caregiving and provide baseline control policies for them. We illustrate the high-fidelity simulation capabilities of RCareWorld by demonstrating the execution of a policy learnt in simulation for one of these tasks on a real-world setup. Additionally, we perform a real-world social robotic caregiving experiment using behaviors modeled in RCareWorld. Robotic caregiving, though potentially impactful towards enhancing the quality of life of care recipients and caregivers, is a field with many barriers to entry due to its interdisciplinary facets. RCareWorld takes the first step towards building a realistic simulation world for robotic caregiving that would enable researchers worldwide to contribute to this impactful field. Demo videos and supplementary materials can be found at: https://emprise.cs.cornell.edu/rcareworld/.},
    keywords      = {Robot control;Libraries;Planning;Stakeholders;Task analysis;Robots;Physics},
    doi           = {10.1109/IROS47612.2022.9982244},
    issn          = {2153-0866},
    month         = {Oct}
}
@inproceedings{7226721,
    author        = {Khoo, Wai L. and Olmschenk, Greg and Zhu, Zhigang and Ro, Tony},
    booktitle     = {2015 IEEE International Conference on Mobile Services},
    title         = {Evaluating Crowd Sourced Navigation for the Visually Impaired in a Virtual Environment},
    year          = {2015},
    volume        = {},
    number        = {},
    pages         = {431--437},
    abstract      = {Crowdsourcing has been shown to be a powerful method for solving a variety of problems. In this paper, we introduce an approach for allowing a crowd to help navigate a visually impaired user to their destination in real-time. Furthermore, we experiment with several approaches in aggregating and feeding back crowd data to determine the optimal method. Our approach streams live video from the visually impaired user's mobile device to a crowd of sighted volunteers. Each crowd member is able to provide their opinion on how the user should proceed and our algorithm aggregates this into a single opinion that is sent as feedback to the user. In this paper, we first present the design and implementation of our crowd sourced navigation system, including webapp design and two aggregation algorithms: averaging and league leader approaches. A virtualized user (avatar) is also developed for more controlled and repeatable testing of aggregation approaches with multiple crowd sourced volunteers. We also tested two navigation modes: a real-user controlled avatar, and a program controlled avatar. Experimental results are provided with the two aggregation methods and the two navigation modes. Our results show that we do not have significant difference between the aggregation methods and the program controlled avatar performed better than a real-user controlled avatar.},
    keywords      = {Navigation;Avatars;Streaming media;Testing;Virtual environments;Real-time systems;Google;crowd sourcing;mobile;visually impaired;virtual environment},
    doi           = {10.1109/MobServ.2015.65},
    issn          = {2329-6453},
    month         = {June}
}
@inproceedings{10716150,
    author        = {Chhabhaiya, Krishna and Patil, Vipul and Mehta, Priyam and Prajapati, Akash and Kaur, Gurleen},
    booktitle     = {2024 Parul International Conference on Engineering and Technology (PICET)},
    title         = {Augmented Reality Try on 3D (ARTON3D)},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {An AR smart mirror integrates traditional mirror functionalities with augmented reality technology, offering users a host of interactive capabilities. By employing sensors and advanced computer vision algorithms, these mirrors can detect users and overlay virtual content onto their reflections. This content may encompass various features like weather updates, news snippets, social media feeds, and tailored product/service recommendations. With an AR smart mirror, individuals can virtually try on clothing, access medical information or reminders, and manage smart home devices without physical interaction. The advent of AR smart mirrors heralds a potential revolution in how we interact with technology and information daily, seamlessly blending the physical and digital realms. These mirrors have versatile applications across diverse settings, from homes and workplaces to retail establishments and public areas, enriching our interactions with surroundings and facilitating informed decision-making. While still in nascent stages of development, AR smart mirrors represent an enticing frontier in the rapidly evolving domain of augmented reality technology.},
    keywords      = {Privacy;Three-dimensional displays;Social networking (online);Smart homes;Rendering (computer graphics);Reflection;Mirrors;Smart devices;Augmented reality;Meteorology;AR smart mirrors;sensors;computer vision;overlay;reflections;tryon;potential revolution;versatile applications;informed decision making;rapidly evolving domain;augmented reality technology},
    doi           = {10.1109/PICET60765.2024.10716150},
    issn          = {},
    month         = {May}
}
@inproceedings{10972696,
    author        = {Lacet, Demetrius and Cassola, Fernando and Valle, Alexandre and Oliveira, Marco and Morgado, Leonel},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Multiplatform Ecosystem for Visualizing Ocean Dynamic Formations with Virtual Choreographies: Oil Spill Case},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {438--446},
    abstract      = {This paper presents a solution for visualizing oil spills at sea by combining satellite data with virtual choreographies. The system enables dynamic, interactive visualization of oil slicks, reflecting their shape, movement, and interaction with environmental factors like currents and wind. High-resolution geospatial data supports a multiplatform experience with aerial and underwater perspectives. This approach promotes independence, interoperability, and multiplatform compatibility in environmental disaster monitoring. The results validate virtual choreographies as effective tools for immersive exploration and analysis, offering structured data narratives beyond passive visualization--especially valuable for mixed reality applications.},
    keywords      = {Three-dimensional displays;Satellites;Oils;Oceans;Disasters;Data visualization;Rendering (computer graphics);Geospatial analysis;Environmental monitoring;Interoperability;oil spill visualization;virtual choreographies;environmental monitoring;3D simulation},
    doi           = {10.1109/VRW66409.2025.00097},
    issn          = {},
    month         = {March}
}
@inproceedings{8690652,
    author        = {Mtawa, Yaser Al and Haque, Anwar and Bitar, Bassel},
    booktitle     = {2018 IEEE 88th Vehicular Technology Conference (VTC-Fall)},
    title         = {Does Internet of Things Disrupt Residential Bandwidth Consumption?},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {1--5},
    abstract      = {The Internet of Things (IoT) aims to connect smart devices communicating and collaborating while providing a wide range of services. Fixed-access Internet traffic grows globally for many reasons such as increasing number of connected devices, and the number of people who utilize the Internet. IoT, video streaming, 4K technology, and virtual and augmented reality (VR/AR) are some applications and services that have the major impact on Internet traffic. Many research and industry communities believe that the Internet of things (IoT) will be the top driver of bandwidth of fixed-access Internet in the future. In this paper, we compare IoT's impact with other bandwidth drivers such as video streaming, 4K technology, and VR/AR, and we investigate whether or not IoT will have a disruptive impact on the residential bandwidth in the near future. We design our model to forecast the residential Internet bandwidth by 2021 and measure the contribution of IoT to this projection. Our model includes all possible types of households and their bandwidth consumption behaviors. Our results show that video entertainment with 4K technology along with VR/AR will be the top drivers of future bandwidth, while IoT will be of least impact among them. Our model shows that 50\% of households will require \leq{} 78 Mbps, and 62\% of households will require <; 100 Mbps, meaning 12\% of households will require between 78 and 100 Mbps. Furthermore, only 10\% of households will demand more than 300 Mbps by 2021, and nearly half of them will use more than 500 Mbps.},
    keywords      = {Bandwidth;Streaming media;Internet of Things;Sensors;Machine-to-machine communications;TV;Internet of Things (IoT);4K Video;Intenret Traffic Forecast;Bandwidth-consuming Applications;VR/AR Technology;Residential Fixed-Access Internet Bandidth},
    doi           = {10.1109/VTCFall.2018.8690652},
    issn          = {2577-2465},
    month         = {Aug}
}
@inbook{10950916,
    author        = {Hackl, Cathy and Lueth, Dirk and Di Bartolo, Tommaso and Siu, Yat},
    booktitle     = {Navigating the Metaverse: A Guide to Limitless Possibilities in a Web 3.0 World},
    title         = {Meet the Metaverse Consumers},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {91--114},
    abstract      = {Summary <p>Because the metaverse is all about engagement and communities of like\&\#x2010;minded people, we can't think of a better place to start a metaverse strategy than by learning more about the consumers populating it. Knowing who they are, what they want, and how they engage in the metaverse should directly influence the digital products and in\&\#x2010;app experiences that businesses design. Traditional video games attract players based on the genre and platforms the games are published on. LinkedIn appeals to the professional crowd, while Tik Tok appeals to younger generations gravitating toward short online videos. It's difficult to provide user data in the metaverse because many dApps protect users' personal information or may not track information due to data privacy laws. The metaverse is new, but marketing and product development has some of the same principles we've seen before. Knowing people's motives helps connect the brand, product, and consumer.</p>},
    keywords      = {Metaverse;Social networking (online);Games;Decentralized applications;Business;Blockchains;Video games;Navigation;Whales;Web sites},
    doi           = {},
    issn          = {},
    publisher     = {Wiley},
    isbn          = {9781119899006},
    url           = {https://ieeexplore.ieee.org/document/10950916}
}
@inproceedings{10724276,
    author        = {Sah, Sumit Prasad and Khadka, Roshan and Nayak, Soumili and Pati, Subhashree and Mishra, Monalisa},
    booktitle     = {2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
    title         = {Advancement in Virtual Fitting Rooms: Integrating AI for Enhanced Online Shopping Experiences},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--5},
    abstract      = {This innovative research reveals a ground-breaking technique for creating an immersive virtual changing room experience using only the user's supplied 2D images--no 3D components are required at all. This project offers a creative way to create a virtual dressing room experience at home using a particular technological stack designed for 2D view processing and the VITON dataset. Using deep learning techniques such as OpenPose, U2Net, and ResNet101, the system analyzes the user's photos, identifying fine body details and carefully extracting them from the surrounding landscape. The user's distinct body form is then rebuilt and the virtual drape of clothing is synchronized using these identified body landmarks as anchor points. The technology, which is controlled by a geometric module, creates a beautiful effect by enveloping clothes around the virtual outline of the user. This ensures that the clothing is accurately represented as it would naturally fit their body. The visual ambience of the virtual world is further enhanced by an inventive alias generator that adds contextual background information. With its innovative method, virtual fashion exploration enters a new era. Users will be able to try on a wide variety of outfits with unmatched accuracy and intuitive ease, all without the hassles and complexity of 3D modeling. The result will be a seamless and incredibly engaging virtual dressing experience. The user only has to take two pictures using a camera or smartphone as part of this easy, quick, and effective procedure.},
    keywords      = {Deep learning;Visualization;Three-dimensional displays;Accuracy;Clothing;Fitting;People with disabilities;Information age;Generators;Synchronization;Virtual fitting room;ResNet101;OpenPose;Geometric Matching Module;U2Net;Alias Generator;Pose estimation;Semantic segmentation},
    doi           = {10.1109/ICCCNT61001.2024.10724276},
    issn          = {2473-7674},
    month         = {June}
}
@inproceedings{9000089,
    author        = {Jiang, Bo and Liu, Ye and Chan, W.K.},
    booktitle     = {2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
    title         = {ContractFuzzer: Fuzzing Smart Contracts for Vulnerability Detection},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {259--269},
    abstract      = {Decentralized cryptocurrencies feature the use of blockchain to transfer values among peers on networks without central agency. Smart contracts are programs running on top of the blockchain consensus protocol to enable people make agreements while minimizing trusts. Millions of smart contracts have been deployed in various decentralized applications. The security vulnerabilities within those smart contracts pose significant threats to their applications. Indeed, many critical security vulnerabilities within smart contracts on Ethereum platform have caused huge financial losses to their users. In this work, we present ContractFuzzer, a novel fuzzer to test Ethereum smart contracts for security vulnerabilities. ContractFuzzer generates fuzzing inputs based on the ABI specifications of smart contracts, defines test oracles to detect security vulnerabilities, instruments the EVM to log smart contracts runtime behaviors, and analyzes these logs to report security vulnerabilities. Our fuzzing of 6991 smart contracts has flagged more than 459 vulnerabilities with high precision. In particular, our fuzzing tool successfully detects the vulnerability of the DAO contract that leads to  million and the freezing of \$150 million worth of Ether.},
    keywords      = {Runtime;Instruments;Smart contracts;Computer bugs;Virtual reality;Fuzzing;Decentralized applications;Blockchains;Security;Testing;Fuzzing;Fuzzer;Smart contract;Vulnerability;Test oracle;Ethereum;Blockchain},
    doi           = {10.1145/3238147.3238177},
    issn          = {2643-1572},
    month         = {Sep.}
}
@inproceedings{8362264,
    author        = {Hu, Brian and Johnson-Bey, Ishmael and Sharma, Mansi and Niebur, Ernst},
    booktitle     = {2018 52nd Annual Conference on Information Sciences and Systems (CISS)},
    title         = {Head movements are correlated with other measures of visual attention at smaller spatial scales},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {Overt visual attention is traditionally studied by recording eye movements under head-fixed viewing conditions. However, during natural visual exploration, both head and eye movements can be used to redirect gaze to new points of interest. In order to better understand the role of head movements in this process, we recorded head movements while subjects explored a set of complex images from five different categories in a virtual reality environment. We found image-category specific differences in head movements, as quantified by the number and duration of head ``fixations'' (periods of maintained head orientation) as well as the amplitude of head movements. We compared head fixations with several other behavioral measures of attentional selection and with a computational model of bottom-up saliency, using the same set of complex scenes in all experiments. Results show significant positive correlation between head fixations and all other measures of attentional deployment, suggesting that head movements are a readily measurable indicator of overt selective attention at a spatial scale exceeding that of eye movements.},
    keywords      = {Head;Magnetic heads;Visualization;Computational modeling;Organisms;Observers;Trajectory},
    doi           = {10.1109/CISS.2018.8362264},
    issn          = {},
    month         = {March}
}
@inbook{9415294,
    author        = {Bobillier Chaumon, Marc-Eric},
    booktitle     = {Digital Transformations in the Challenge of Activity and Work: Understanding and Supporting Technological Changes},
    title         = {Emerging Technologies and Issues for Activity and Occupational Health},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1--19},
    abstract      = {The question of the introduction of emerging technologies and their constant renewal in organizations fundamentally refers to the place and role that these devices play in business, as well as how they can affect activity and health at work. This chapter aims to question the place and impact that the emerging technologies can have in the often paradoxical transformations and development of activity. The first step is to identify and characterize the emerging technologies that are being deployed in companies. Then, the chapter discusses the impact they may have on professionals and their activity. It examines five paradoxes of the diffusion of technologies in/on the activity: sense of loss of control over the activity vs increased control over the activity, invisibility vs visibility of the activity, increase in virtual teams vs isolation of employees, nomadism vs a sedentary lifestyle at work, and detachment from activity vs proximity of work.},
    keywords      = {Artificial intelligence;Digital transformation;Companies;Task analysis;Production facilities;Law;Exoskeletons},
    doi           = {10.1002/9781119808343.ch1},
    issn          = {},
    publisher     = {Wiley},
    isbn          = {9781119808190},
    url           = {https://ieeexplore.ieee.org/document/9415294}
}
@inbook{9310575,
    author        = {},
    booktitle     = {Digital Innovation and the Future of Work},
    title         = {3 Emerging Technologies and Working Life},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {41--62},
    abstract      = {The concept of digitalization captures the widespread adoption of digital technologies in our lives, in the structure and functioning of organizations and in the transformation of our economy and society. Digital technologies for data processing and communication underly high-impact innovations including the Internet of Things, wireless multimedia, artificial intelligence, big data, enterprise platforms, social networks and blockchain. These digital innovations not only bring new opportunities for prosperity and wellbeing but also affect our behaviors, activities, and daily lives. They enable and shape new forms of production and new working practices in sectors such as manufacturing, healthcare, logistics and supply chains, energy, and public and business services. Digital innovations are not purely technological but form part of comprehensive systemic innovations of a sociotechnical and networked nature, requiring the alignment of technology, processes, organizations, and humans. Examples are platform-based work, customer driven value creating networks, and urban public service systems. Building on widespread networking, algorithmic decisions and sharing of personal data, these innovations raise intensive societal and ethical debates regarding key issues such as data sovereignty and privacy intrusion, business models based on data surveillance and negative externalization, quality of work and jobs, and market dominance versus regulation. In this context, this book focuses on the implications of digitalization for the domain of work. The book studies the changing nature of work as well as new forms of digitally enabled organizations, work practices and cooperation. The book sheds light on the technological, economic, and political forces shaping the new world of work and on the prospects for human-centric and responsible innovations. To this end, the book brings together a number of studies in five major topics: 1. The evolution of digital technology impacting ways of working; 2. The role of artificial intelligence in new ways of working; 3. Transformation of work, jobs and employment; 4. Digitalization and need for skills and competencies; and 5. New forms of decentralized working and cooperation.},
    keywords      = {},
    doi           = {},
    issn          = {},
    publisher     = {River Publishers},
    isbn          = {9788770222198},
    url           = {https://ieeexplore.ieee.org/document/9310575}
}
@inproceedings{8571506,
    author        = {Schlund, Jonas and Pflugradt, Noah and Steber, David and Muntwyler, Urs and German, Reinhard},
    booktitle     = {2018 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)},
    title         = {Benefits of Virtual Community Energy Storages Compared to Individual Batteries Based on Behaviour Based Synthetic Load Profiles},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {This paper focuses on a low-voltage grid area consisting of 500 distributed households with both photovoltaics and a battery. If every household focuses only on its self-consumption, the batteries run inefficiently and the grid is stressed unnecessarily. Thus, the batteries within the considered area are connected to form a virtual community energy storage. To simulate such an environment, individual and realistic load profiles for each household are needed. This paper presents a novel, behavior based load profile generator to get such profiles. It is shown that these profiles aggregate to the German standardized load profile H0. An already existing simulation model of decentralized households is adapted in order to include community controllers, which aggregate and distribute the corresponding power flows in order to run the batteries efficiently and avoid unnecessary power flows. The whole low-voltage grid area is simulated for various community sizes within the area. Utilizing community power leads to a better overall efficiency, a decrease in the workload of the grid and a higher self-sufficiency within the considered area. These benefits can already be achieved at small community sizes.},
    keywords      = {Load modeling;Adaptation models;Batteries;Substations;Aggregates;Sociology},
    doi           = {10.1109/ISGTEurope.2018.8571506},
    issn          = {},
    month         = {Oct}
}
@inproceedings{8531456,
    author        = {Shi, Jian},
    booktitle     = {2018 International Conference on Virtual Reality and Intelligent Systems (ICVRIS)},
    title         = {Service Oriented Logistics Supply Chain Management Process Optimization:A Case Study of Agriculture Product Company},
    year          = {2018},
    volume        = {},
    number        = {},
    pages         = {501--504},
    abstract      = {In this article, an agricultural product company X is taken as the research object. Theoretical knowledge of supply chain and the achievements of relevant exploration and practice at home and abroad are adopted to provide optimization of logistics supply chain fox X company, with expected results and safeguards needed to be taken. According to current survey and data collection of the company, we clarify the current situation and existing problems of logistics supply chain, and perform demand analysis of logistics supply chain optimization. Then, based the actual situation of the survey data, the optimized scheme for original logistics process is proposed. ABC classification management is used for inventory optimization and the optimal design of transportation and distribution management is also proposed. Finally the advice and design of major function modules to establish intelligent logistics supply chain information system is put forward to provide theoretical direction for the optimization of X company.},
    keywords      = {Supply chains;Companies;Optimization;Transportation;Supply chain management;logistics supply chain;service demand;management process optimization;ABC},
    doi           = {10.1109/ICVRIS.2018.00129},
    issn          = {},
    month         = {Aug}
}
@inproceedings{10767629,
    author        = {Candia, Alejandro and Cappo, Cristian},
    booktitle     = {2024 43rd International Conference of the Chilean Computer Science Society (SCCC)},
    title         = {TinyICS: An Industrial Control System Simulator Based on NS-3},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {1--8},
    abstract      = {Industrial control systems (ICS) are essential in industrial applications and critical infrastructure. These systems can be composed of various components involving different communication methods. Conducting tests in an ICS can be dangerous and costly. Therefore, having simulation tools is of high value for research and development teams. This work aims to develop an open-source industrial control systems simulator capable of simulating arbitrary process behavior and capturing communication traffic. The NS-3 network simulator was used to simulate communication between the industrial components, and Modbus was developed as the application-level industrial protocol. Abstractions were developed for commonly used industrial devices, as well as the controlled physical process, where end users can define the behavior of these components. Python bindings were developed for the simulator to reduce the learning curve and target system experts. Finally, the proposed simulator is used to model and evaluate an industrial application scenario.},
    keywords      = {Protocols;Scalability;Process control;SCADA systems;Machine learning;Real-time systems;Libraries;Systems simulation;Planning;Research and development;Industrial Control Systems;Simulation;NS-3;Discrete Event System;SCADA},
    doi           = {10.1109/SCCC63879.2024.10767629},
    issn          = {2691-0632},
    month         = {Oct}
}
@inproceedings{8809119,
    author        = {Dafoulas, Georgios and Tsiakara, Ariadni and Samuels-Clarke, Jerome and Maia, Cristiano Cardoso and Neilson, David and Ali, Almaas A.},
    booktitle     = {2019 10th International Conference on Information and Communication Systems (ICICS)},
    title         = {Investigating patterns of emotion and expressions using smart learning spaces},
    year          = {2019},
    volume        = {},
    number        = {},
    pages         = {238--244},
    abstract      = {The Internet of Things (IoT) is based on the use of interconnected device for data transfer. This paper describes findings from current work that uses a range of sensors that are connected together in collecting biometric data from learners. The research is focused on assessing learners' state during different learning activities by using different biometric data. The paper investigates certain patterns of emotion, expressions and Galvanic Skin Response (GSR) (i.e. sweat levels) amongst participants. The findings are discussed under the prism of learner classification against a number of criteria including learning styles, project management preference, team profile and personality type. The paper contributes in understanding how we can monitor individuals' state and behaviour during different learning activities and identify predominant patterns.},
    keywords      = {Monitoring;Augmented reality;Intelligent sensors;STEM;Bioinformatics;Task analysis;Internet of Things;Galvanic Skin Response;Sensors;Biometrics;Smart learning Spaces;emotion recognition},
    doi           = {10.1109/IACS.2019.8809119},
    issn          = {2573-3346},
    month         = {June}
}
@inproceedings{9589319,
    author        = {Chhor, Johnny and Lammersmann, Benedikt},
    booktitle     = {IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society},
    title         = {Predictive Voltage Control for Grid-Forming Power Converters with Virtual Output Impedance},
    year          = {2021},
    volume        = {},
    number        = {},
    pages         = {1--7},
    abstract      = {The ever-increasing expansion of decentralized generation units based on renewable energy sources led to a paradigm shift in the operation of electrical power grids. Grid-forming and voltage-impressing control of grid-tied power converters are anticipated to guarantee stable grid operation. This paper presents a predictive voltage controller with a virtual impedance control loop to operate grid-tied power converters as voltage sources with defined (virtual) output impedance. The prominent finite-control-set model predictive control approach is implemented for the inner voltage control loop to achieve high dynamic and robust behavior. The outer virtual impedance loop is realized with a state feedback approach. To compensate inner voltage drops across the virtual impedance, another voltage reference regulation loop is introduced. The methodology and the respective design and implementation aspects are discussed on the example of a three-level voltage source inverter with LCL filter. To demonstrate the effectiveness of the proposed control scheme particularly during short-circuits, simulations are carried out. Further experiments on a dedicated converter test bench validate its dynamic and steady state control performance.},
    keywords      = {State feedback;Renewable energy sources;Voltage source inverters;Power system dynamics;Regulation;Power grids;Steady-state;finite-control-set model predictive control (FCS-MPC);grid-forming control;neutral-point-clamped (NPC) power converter;decentralized energy resource (DER);microgrid},
    doi           = {10.1109/IECON48115.2021.9589319},
    issn          = {2577-1647},
    month         = {Oct}
}
@inproceedings{10536501,
    author        = {Zhang, Jessy and Morris, Alexis and Martyn, Nikki and Zaccolo, Sandro},
    booktitle     = {2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Designing EEPO: An Emissary Educator Playmate Oracle XR Conversation Agent for Children},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {151--156},
    abstract      = {This paper presents an extended reality (XR) embodied conversational agent, as a social-emotional companion for parents and children within the home context. It has focused on the role of technology including Artificial Intelligence (AI) and XR on holistic child development and well-being, parenting, and the beautiful relational space in between children and parents, here termed Augmented Sociology. Based on the EEPO (Emissary Educator Playmate Oracle) theoretical child technology interaction framework, this work presents an early EEPO prototype, toward an XR social-emotional development companion agent for children and support agent for parents.},
    keywords      = {Three-dimensional displays;Extended reality;Conferences;Sociology;Prototypes;Oral communication;User interfaces;Human-centered computing--Human computer interaction (HCI)--Interaction paradigms--Mixed / augmented reality Human-centered computing--Human computer interaction (HCI)--Interaction paradigms--Natural language interfaces Computing methodologies--Artificial intelligence--Distributed artificial intelligence--Intelligent agents Applied computing-Law, social and behavioral sciences--Sociology},
    doi           = {10.1109/VRW62533.2024.00031},
    issn          = {},
    month         = {March}
}
@inproceedings{10484057,
    author        = {Katageri, Siddharth and De, Arkadipta and Devaguptapu, Chaitanya and Prasad, V S S V and Sharma, Charu and Kaul, Manohar},
    booktitle     = {2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    title         = {Synergizing Contrastive Learning and Optimal Transport for 3D Point Cloud Domain Adaptation},
    year          = {2024},
    volume        = {},
    number        = {},
    pages         = {2930--2939},
    abstract      = {Recently, the fundamental problem of unsupervised domain adaptation (UDA) on 3D point clouds has been motivated by a wide variety of applications in robotics, virtual reality, and scene understanding, to name a few. The point cloud data acquisition procedures manifest themselves as significant domain discrepancies and geometric variations among both similar and dissimilar classes. The standard domain adaptation methods developed for images do not directly translate to point cloud data because of their complex geometric nature. To address this challenge, we leverage the idea of multimodality and alignment between distributions. We propose a new UDA architecture for point cloud classification that benefits from multimodal contrastive learning to get better class separation in both domains individually. Further, the use of optimal transport (OT) aims at learning source and target data distributions jointly to reduce the cross-domain shift and provide a better alignment. We conduct a comprehensive empirical study on PointDA-10 and GraspNetPC-10 and show that our method achieves state-of-the-art performance on GraspNetPC-10 (with \approx{} 4-12\% margin) and best average performance on PointDA-10. Our ablation studies and decision boundary analysis also validate the significance of our contrastive learning module and OT alignment. https://siddharthkatageri.github.io/COT.},
    keywords      = {Point cloud compression;Computer vision;Three-dimensional displays;Data acquisition;Self-supervised learning;Virtual reality;Object detection;Algorithms;3D computer vision;Algorithms;Machine learning architectures;formulations;and algorithms},
    doi           = {10.1109/WACV57701.2024.00292},
    issn          = {2642-9381},
    month         = {Jan}
}
@inproceedings{9875700,
    author        = {Sakly, Houneida and Said, Mourad and Tagina, Moncef},
    booktitle     = {2022 IEEE 9th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)},
    title         = {Left ventricular assist device: CFD Simulation of Flow HeartWare},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--6},
    abstract      = {The development of further treatment techniques in the prognosis of terminal heart failure has recently been influenced by innovative mechanical circulatory systems in the medical profession. The need for cardiac intervention may be determined by the patient's condition. Implantable left ventricular assist devices may be used to replace it in some circumstances left ventricular assist devices. Mechanical assistance of the failing left ventricle enables optimal hemodynamic stability and recovery of secondary organ failure for patients suffering from heart failure. These devices can help the expert until a suitable cardiac allograft becomes available, but they are also used as a last resort for individuals who are not transplant candidates. Furthermore, left ventricular assist devices implantation, requires a second heart procedure, which comes with its own set of dangers and perioperative difficulties during the waiting period. The surgical problem arises when a left ventricular assist devices is already installed after a heart transplant at home. Implementation of the HeartWare System When compared to pulsatile devices, tracking is thought to be more versatile and long-lasting. Our key contribution in this regard is to use of computational fluid dynamics modules to assess the velocity behavior as well as the flow heart rate while taking into account the physical features of blood flow.},
    keywords      = {Heart rate;Road transportation;Solid modeling;Computational fluid dynamics;Surgery;Virtual reality;Stability analysis;HeartWare device;left ventricle;velocity;flow rate;computational fluid dynamics modules},
    doi           = {10.1109/SETIT54465.2022.9875700},
    issn          = {},
    month         = {May}
}
@inproceedings{10002053,
    author        = {Yamamoto, Fuma and Ayedoun, Emmanuel and Tokumaru, Masataka},
    booktitle     = {2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and 23rd International Symposium on Advanced Intelligent Systems (SCIS\&ISIS)},
    title         = {Human-robot interaction environment to enhance the sense of presence in remote sports watching},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--5},
    abstract      = {The recent coronavirus disease 2019 (COVID-19) outbreak has helped increase the popularity of online video communication and meeting platforms as alternatives to face-to-face interactions. Such a trend has also triggered the emergence of remote cheering systems, hinting at the possibility that people could enjoy watching sports games in virtual environments even from their homes in the near future. However, reproducing a sense of presence similar to the atmosphere felt by fans in stadiums or event venues is a major challenge within virtual environments. Thus, our idea is to embed groups of cheerful robots in virtual environments, thereby creating a sense of unity and mimicking emotion spread among fans. In this study, we built a virtual cheering environment and embedded a game-event driven behavior model that enables a group of robots to display various emotions through nonverbal reactions according to the game flow. Then, we conducted a preliminary evaluation of the proposed system, where the participants and a group of robots were placed in a virtual cheering environment to watch a baseball game. The obtained results hinted at the meaningfulness of the proposed approach. Nevertheless, further work is necessary to achieve a sufficient sense of presence and validate the effectiveness of our proposed environment.},
    keywords      = {COVID-19;Fans;Virtual environments;Human-robot interaction;Atmosphere;Games;Robot sensing systems;emotional propagation;presence;sensitivity},
    doi           = {10.1109/SCISISIS55246.2022.10002053},
    issn          = {},
    month         = {Nov}
}
@inproceedings{10973023,
    author        = {St\k{e}pie\'{n}, Joanna and Dudek, Mi\l{}osz and Wodzi\'{n}ski, Marek and Danio\l{}, Mateusz and Igras-Cybulska, Magdalena and W\'{o}jcik-P\k{e}dziwiatr, Magdalena and Hemmerling, Daria},
    booktitle     = {2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
    title         = {Applying Multimodal Mixed Reality System for Classifying Parkinson's Disease: Design and Evaluation of the Voice Module},
    year          = {2025},
    volume        = {},
    number        = {},
    pages         = {953--958},
    abstract      = {Early detection and regular monitoring are crucial for the effective treatment and improvement of the quality of life in patients with Parkinson's disease, a neurodegenerative disorder characterized by bradykinesia, tremors, muscle stiffness, balance issues, and speech impairments. Currently, diagnosis depends on frequent specialist visits, which can be burdensome for elderly patients. This work presents a prototype of a non-invasive tool for accurate Parkinson's disease detection through voice analysis, utilizing a mixed reality head-mounted display. MR goggles (Microsoft HoloLens 2) offer a stress-free, in-home environment, minimizing the need for frequent hospital visits. Patients perform 5 voice-related tasks, and advanced speech recognition models (wav2vec2, wavLM, HuBERT) and text models (BERT) are employed for analysis. Data collection and system evaluation were conducted using the MR system, with 57 participants contributing to the dataset (including 21 patients diagnosed with Parkinson's disease and 36 healthy controls). This technology holds great promise as an advanced diagnostic tool for neurodegenerative diseases, facilitating interactive assessments, reducing the strain on healthcare providers, and enhancing patient comfort by limiting the necessity of regular check-up visits.},
    keywords      = {Solid modeling;Analytical models;Three-dimensional displays;Mixed reality;Prototypes;Speech recognition;User interfaces;Older adults;Diseases;Strain;Augmented Reality;Mixed Reality;Parkinson Disease;Voice Analysis;Interactive medical examinations;Noninvasive diagnostic methods;Digital health technologies},
    doi           = {10.1109/VRW66409.2025.00194},
    issn          = {},
    month         = {March}
}
@inproceedings{9973528,
    author        = {Ahmad, Raza and Manne, Naga Nithin and Malik, Tanu},
    booktitle     = {2022 IEEE 18th International Conference on e-Science (e-Science)},
    title         = {Reproducible Notebook Containers using Application Virtualization},
    year          = {2022},
    volume        = {},
    number        = {},
    pages         = {1--10},
    abstract      = {Notebooks have gained wide popularity in scientific computing. A notebook is both a web-based interactive front-end to program workflows and a lightweight container for sharing code and its output. Reproducing notebooks in different target environments, however, is a challenge. Notebooks do not share the computational environment in which they are executed. Consequently, despite being shareable they are often not reproducible. The application virtualization (AV) method enables shareability and reproducibility of applications in heterogeneous environments. AV-based tools, however, encapsulate non-interactive, batch applications. In this paper, we present FLINC, a user-space method and tool for creating reproducible notebook containers. FLINC virtualizes the notebook process that enables interactive computation and creates notebook containers, which include the environment and all data dependencies accessed by the notebook file. It relies on provenance collected during virtualization to ensure the correct behavior of a notebook when run repeatedly in different environments. We demonstrate how FLINC exports notebook containers seamlessly to non-notebook environments. Our experiments show that FLINC creates lighter weight containers as compared to equivalent non-interactive, batch containers, and preserves the same interactive workflow for the user as in current notebook platforms.},
    keywords      = {Scientific computing;High performance computing;Computational modeling;Containers;Programming;Reproducibility of results;Virtualization;notebook reproducibility;provenance;notebook containers;application virtualization},
    doi           = {10.1109/eScience55777.2022.00015},
    issn          = {},
    month         = {Oct}
}
@article{9690881,
    author        = {Marques, Rafael Salema and Al-Khateeb, Haider and Epiphaniou, Gregory and Maple, Carsten},
    journal       = {IEEE Transactions on Information Forensics and Security},
    title         = {APIVADS: A Novel Privacy-Preserving Pivot Attack Detection Scheme Based on Statistical Pattern Recognition},
    year          = {2022},
    volume        = {17},
    number        = {},
    pages         = {700--715},
    abstract      = {Advanced cyber attackers often ``pivot'' through several devices in such complex infrastructure to obfuscate their footprints and overcome connectivity restrictions. However, prior pivot attack detection strategies present concerning limitations. This paper addresses an improvement of cyber defence with APIVADS, a novel adaptive pivoting detection scheme based on traffic flows to determine cyber adversaries' presence based on their pivoting behaviour in simple and complex interconnected networks. Additionally, APIVADS is agnostic regarding transport and application protocols. The scheme is optimized and tested to cover remotely connected locations beyond a corporate campus's perimeters. The scheme considers a hybrid approach between decentralized host-based detection of pivot attacks and a centralized approach to aggregate the results to achieve scalability. Empirical results from our experiments show the proposed scheme is efficient and feasible. For example, a 98.54\% detection accuracy near real-time is achievable by APIVADS differentiating ongoing pivot attacks from regular enterprise traffic as TLS, HTTPS, DNS and P2P over the internet.},
    keywords      = {Payloads;Inspection;Privacy;Monitoring;Middleboxes;Malware;Knowledge engineering;APT;pivot attack;privacy-preserving;lateral movement;network flow},
    doi           = {10.1109/TIFS.2022.3146076},
    issn          = {1556-6021},
    month         = {}
}
@article{10844277,
    author        = {Nechesov, Andrey and Dorokhov, Ivan and Ruponen, Janne},
    journal       = {IEEE Access},
    title         = {Virtual Cities: From Digital Twins to Autonomous AI Societies},
    year          = {2025},
    volume        = {13},
    number        = {},
    pages         = {13866--13903},
    abstract      = {Virtual Cities (VCs) transcend simple digital replicas of real-world systems, emerging as complex socio-technical ecosystems where autonomous AI entities function as citizens. Agentic AI systems are on track to engage in cultural, economic, and political activities, effectively forming societal structure within VC. This paper proposes an integrated simulation framework that combines physical, structural, behavioral, cognitive, and data fidelity layers, allowing multi-scale simulation from microscopic interactions to macro-urban dynamics. A composite fidelity metric ( $F_{0}$ ) provides systematic approach to evaluate accuracy variations across applications in VCs. We also discuss autonomy of AI entities and classify them according to their capacity to modify goals--ranging from ``tools'' with fixed objectives to ``entities'' capable of redefining their very purpose. We also outline the requirements to define a coefficient to evaluate the degree of autonomy for AI beings. Our results demonstrate that such virtual environments can support the emergence of AI-driven societies, where governance mechanisms like Decentralized Autonomous Organizations (DAOs) and an Artificial Collective Consciousness (ACC) provide ethical and regulatory oversight. By blending horizon scanning with systems engineering method for defining novel AI governance models, this study reveals how VCs can catalyze breakthroughs in urban innovation while driving socially beneficial AI development - consequently opening a new frontier for exploring human-AI coexistence.},
    keywords      = {Artificial intelligence;Virtual environments;Urban areas;Robots;Predictive models;Solid modeling;Real-time systems;Computational modeling;Rendering (computer graphics);Digital twins;Virtual cities;urban metaverse;AI autonomy;virtual twins;digital twins;virtual economies;predictive modeling;AI governance;blockchain;artificial collective consciousness},
    doi           = {10.1109/ACCESS.2025.3531222},
    issn          = {2169-3536},
    month         = {}
}
@inbook{9310634,
    author        = {},
    booktitle     = {Digital Innovation and the Future of Work},
    title         = {11 Competencies in Digital Work},
    year          = {2020},
    volume        = {},
    number        = {},
    pages         = {225--258},
    abstract      = {The concept of digitalization captures the widespread adoption of digital technologies in our lives, in the structure and functioning of organizations and in the transformation of our economy and society. Digital technologies for data processing and communication underly high-impact innovations including the Internet of Things, wireless multimedia, artificial intelligence, big data, enterprise platforms, social networks and blockchain. These digital innovations not only bring new opportunities for prosperity and wellbeing but also affect our behaviors, activities, and daily lives. They enable and shape new forms of production and new working practices in sectors such as manufacturing, healthcare, logistics and supply chains, energy, and public and business services. Digital innovations are not purely technological but form part of comprehensive systemic innovations of a sociotechnical and networked nature, requiring the alignment of technology, processes, organizations, and humans. Examples are platform-based work, customer driven value creating networks, and urban public service systems. Building on widespread networking, algorithmic decisions and sharing of personal data, these innovations raise intensive societal and ethical debates regarding key issues such as data sovereignty and privacy intrusion, business models based on data surveillance and negative externalization, quality of work and jobs, and market dominance versus regulation. In this context, this book focuses on the implications of digitalization for the domain of work. The book studies the changing nature of work as well as new forms of digitally enabled organizations, work practices and cooperation. The book sheds light on the technological, economic, and political forces shaping the new world of work and on the prospects for human-centric and responsible innovations. To this end, the book brings together a number of studies in five major topics: 1. The evolution of digital technology impacting ways of working; 2. The role of artificial intelligence in new ways of working; 3. Transformation of work, jobs and employment; 4. Digitalization and need for skills and competencies; and 5. New forms of decentralized working and cooperation.},
    keywords      = {},
    doi           = {},
    issn          = {},
    publisher     = {River Publishers},
    isbn          = {9788770222198},
    url           = {https://ieeexplore.ieee.org/document/9310634}
}
@inproceedings{10.1145/3617733.3617748,
    author        = {Suprapto, Widjojo and Kempa, Sesilya and Widjaja, Wilson},
    title         = {Virtual Reality Tourism, can it replace the real tourism experience?},
    year          = {2023},
    isbn          = {9798400707735},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3617733.3617748},
    doi           = {10.1145/3617733.3617748},
    abstract      = {The Covid-19 pandemic brought a severe impact on tourism industry, as traveling for leisure was very restricted. Yet, the desire to travel and explore tourist destination created a necessity for various reasons. The aim of this study is to explore virtual reality usage to replace such a travel limitation. Previous studies mention that virtual reality application has been used to enhance tourism promotion. Therefore, this study seeks evidences to go beyond enhancing the experience. The data were collected by questionnaires that were distributed to the Millennials, and the returned questionnaires were from 280 respondents, with 230 valid respondents. The results indicate that presence and authenticity have significant influences on virtual reality usage, however, they have no significant influence on tourism experience. Emotion has no significant influence on virtual reality usage, but it has a significant influence on tourism experience. Virtual reality usage has a significant influence on tourism experience. Virtual reality also acts as a mediator between presence and authenticity on tourism experience. At the moment, virtual reality is affecting the tourism experience, although it is relatively weak.},
    booktitle     = {Proceedings of the 2023 11th International Conference on Computer and Communications Management},
    pages         = {90–94},
    numpages      = {5},
    keywords      = {social medias, the millennials, tourism experience, virtual reality},
    location      = {Nagoya, Japan},
    series        = {ICCCM '23}
}
@inproceedings{10.1145/3586182.3616682,
    author        = {Nargund, Avinash Ajit and Aponte, Alejandro and Caetano, Arthur and Sra, Misha},
    title         = {ModBand: Design of a Modular Headband for Multimodal Data Collection and Inference},
    year          = {2023},
    isbn          = {9798400700965},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3586182.3616682},
    doi           = {10.1145/3586182.3616682},
    abstract      = {Collecting multimodal user data during physical tasks such as cooking, maintenance, or physical rehab is crucial to enable the design of better AI models, interfaces, and applications. However, this is a challenging task with external cameras and sensors due to user movement, self-occlusions and diversity of data streams during task performance. In this work, we present ModBand, a wearable sensor headband with an accompanying software pipeline to collect and visualize data such as facial images, pupillometry, egocentric video, and heart rate during physical task performance. ModBand can be modified, extended, and used both as a standalone device or integrated with existing head-mounted AR devices for AI-based task guidance. Our modular design incorporates cost-effective fabrication methods, such as 3D printing, and enables convenient integration or exclusion of sensors to support custom data collection needs.},
    booktitle     = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
    articleno     = {35},
    numpages      = {3},
    keywords      = {Facial data collection, Mobile, Modular design, Sensor headband, Visual and physiological data, Wearable},
    location      = {San Francisco, CA, USA},
    series        = {UIST '23 Adjunct}
}
@inproceedings{10.1145/3180308.3180351,
    author        = {Senno, Bachar and Barcha, Pedro},
    title         = {Customizing User Experience with Adaptive Virtual Reality},
    year          = {2018},
    isbn          = {9781450355711},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3180308.3180351},
    doi           = {10.1145/3180308.3180351},
    abstract      = {Virtual reality is becoming more prominent than ever. The improved performance of mobile devices, along with the growing interest in more immersive user experiences, have allowed virtual reality to gain solid standing in this regard: nowadays, a smartphone and a pair of VR goggles are all that is needed for a full VR experience. The uses of VR systems extend beyond home entertainment: in particular, we are tackling the possibility that VR can be used by therapists to aid patients suffering from neurodevelopmental disorders (NDD) [1,2]. To that, an adaptive system that can change different aspects of the VR environment, using machine learning techniques, can go a long way in increasing the efficiency of NDD treatments.},
    booktitle     = {Companion Proceedings of the 23rd International Conference on Intelligent User Interfaces},
    articleno     = {42},
    numpages      = {2},
    keywords      = {Adaptive System, Machine Learning, Mobile Virtual Reality},
    location      = {Tokyo, Japan},
    series        = {IUI '18 Companion}
}
@inproceedings{10.1145/3545822.3545825,
    author        = {Li, Boyan and Cao, Yang},
    title         = {Application of Virtual Reality Technology in the Protection of Intangible Cultural Heritage: --Take the ``Lion dance'' in Shehuo as an example},
    year          = {2022},
    isbn          = {9781450396424},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3545822.3545825},
    doi           = {10.1145/3545822.3545825},
    abstract      = {China is an ancient civilization with a long history and culture, and has accumulated many precious cultural heritages over thousands of years. Intangible cultural heritage is a very important part of it. Because the intangible cultural heritage is regional, and the inheritance method is mainly for teachers and apprentices inheritance, many intangible cultural heritages in China are facing the danger of disappearing, and the protection of the intangible cultural heritage is imminent. With the progress of The Times, virtual reality technology has opened up a new way for the protection of intangible cultural heritage.With the support of the brand-new technology, the intangible cultural heritage can be protected through the digital technology. The virtual reality technology has become one of the ways of protecting the intangible cultural heritage. This paper aims to apply the virtual reality technology in the protection of intangible cultural heritage, to make the Chinese intangible cultural heritage ---- "Shehuo" spread and inherit.},
    booktitle     = {Proceedings of the 2022 7th International Conference on Multimedia Systems and Signal Processing},
    pages         = {25–29},
    numpages      = {5},
    keywords      = {3D digital modeling technology, Shehuo, Lion dance, intangible cultural heritage},
    location      = {Shenzhen, China},
    series        = {ICMSSP '22}
}
@inproceedings{10.1145/2890602.2890626,
    author        = {Carter, Lewis and Potter, Leigh Ellen},
    title         = {Designing Games for Presence in Consumer Virtual Reality},
    year          = {2016},
    isbn          = {9781450342032},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/2890602.2890626},
    doi           = {10.1145/2890602.2890626},
    abstract      = {With virtual reality technologies entering the consumer market this year, it is the task of those producing content for the virtual reality platform to ensure that users have an experience that lives up to expectations. Virtual reality comes with its own strengths and weaknesses, and these must be taken into account when designing applications to produce the best possible experience for interaction. This paper employs a qualitative case study to examine participants in sessions with a virtual reality game prototype utilizing the Oculus Rift. The game prototype was designed to investigate problem areas of virtual reality. Data was then analyzed through thematic analysis, and a preliminary set of game design heuristics specific to virtual reality were created. These heuristics are written so that virtual reality game designers can easily apply them.},
    booktitle     = {Proceedings of the 2016 ACM SIGMIS Conference on Computers and People Research},
    pages         = {141–148},
    numpages      = {8},
    keywords      = {Oculus Rift, consumer virtual reality, game design, heuristic evaluation, presence, video game, virtual reality},
    location      = {Alexandria, Virginia, USA},
    series        = {SIGMIS-CPR '16}
}
@inproceedings{10.1145/3123024.3124426,
    author        = {Saha, Deba Pratim and Knapp, R. Benjamin and Martin, Thomas L.},
    title         = {Affective feedback in a virtual reality based intelligent supermarket},
    year          = {2017},
    isbn          = {9781450351904},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3123024.3124426},
    doi           = {10.1145/3123024.3124426},
    abstract      = {The probabilistic nature of the inferences in a context-aware intelligent environment (CAIE) renders them vulnerable to erroneous decisions resulting in wrong services. Learning to recognize a user's negative reactions to such wrong services will enable a CAIE to anticipate a service's appropriateness. We propose a framework for continuous measurement of physiology to infer a user's negative-emotions arising from receiving wrong services, thereby implementing an implicit-feedback loop in the CAIE system. To induce such negative-emotions, in this paper, we present a virtual-reality (VR) based experimental platform while collecting real-time physiological data from ambulatory wearable sensors. Results from the electrodermal activity (EDA) data analysis reveal patterns that correlate with known features of negative-emotions, indicating the possibility to infer service appropriateness from user's reactions to a service, thereby closing an implicit-feedback loop for the CAIE.},
    booktitle     = {Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
    pages         = {646–653},
    numpages      = {8},
    keywords      = {affective feedback, physiological computing},
    location      = {Maui, Hawaii},
    series        = {UbiComp '17}
}
@inproceedings{10.1145/3123024.3123193,
    author        = {Mauriello, Matthew Louis},
    title         = {Scalable methods and tools to support thermographic data collection and analysis for energy audits},
    year          = {2017},
    isbn          = {9781450351904},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3123024.3123193},
    doi           = {10.1145/3123024.3123193},
    abstract      = {Buildings consume 41\% of energy produced in the US and contribute an increasing portion of total carbon dioxide emissions---40\% in 2009 compared to 33\% in 1980 [9]. One factor contributing to these issues is building age. Residential buildings, for example, constitute 95\% of all buildings in the US and are on average over 50 years old [23]; most of these buildings were constructed using energy inefficient designs and their materials have degraded over time. Moreover, the US Department of Energy has set a goal of reducing housing energy use by up to 70\% [18]. To meet this goal, renovations and retrofits of existing building stock has become a pressing need. One effective practice for motivating these improvements is energy auditing, which has seen a resurgence of interest in recent years [20].},
    booktitle     = {Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
    pages         = {360–364},
    numpages      = {5},
    keywords      = {energy efficiency, formative inquiry, mobile devices, sensor kits, support tools, sustainable HCI, thermography},
    location      = {Maui, Hawaii},
    series        = {UbiComp '17}
}
@inproceedings{10.1145/3139131.3139133,
    author        = {Bhandari, Jiwan and Tregillus, Sam and Folmer, Eelke},
    title         = {Legomotion: scalable walking-based virtual locomotion},
    year          = {2017},
    isbn          = {9781450355483},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3139131.3139133},
    doi           = {10.1145/3139131.3139133},
    abstract      = {Using real walking for virtual navigation generally delivers the most natural and immersive virtual reality experience, but its usage is generally bounded by available tracking space. To navigate beyond the confines of available tracking space, users need to switch to an artificial locomotion technique, such as controller input. However, having to switch from leg-based input to hand-based input is considered to break presence. We present a hybrid handsfree locomotion technique called legomotion that lets users seamlessly switch between real walking input and walking-in-place input to enable navigation at scale. A user study with 18 participants compared legomotion to full locomotion using a controller. Legomotion led to higher presence as switching to controller input was found to be more tedious. Because controller input is also faster than walking, we observed most users to abandon positional tracking input altogether and primary use a controller for navigation - which then led to a lower presence. This finding could have major implications for the design of VR locomotion.},
    booktitle     = {Proceedings of the 23rd ACM Symposium on Virtual Reality Software and Technology},
    articleno     = {18},
    numpages      = {8},
    keywords      = {VR sickness, locomotion, presence, virtual reality, walking-in-place},
    location      = {Gothenburg, Sweden},
    series        = {VRST '17}
}
@inproceedings{10.1145/3563357.3567754,
    author        = {Bianchi, Eva and Altaf, Basma and Tavakoli, Arash and Douglas, Isabella P. and Landay, James A. and Billington, Sarah L.},
    title         = {Human wellbeing responses to real and simulated workplaces: A comparison of in-person, online, and virtual environments: poster abstract},
    year          = {2022},
    isbn          = {9781450398909},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3563357.3567754},
    doi           = {10.1145/3563357.3567754},
    abstract      = {Recent studies have emphasized the role of building design on occupant wellbeing. However, studying the impact of built features on wellbeing is time-consuming and expensive. Our work explores the value of different methods to simulate workplace environments and their impact on wellbeing outcomes. Following a laboratory experiment that highlighted the potential of windows and natural materials to reduce stress, we conducted an immersive online replication to assess the continuity of results on a different platform. Online participants reported lower negative affect with natural materials compared to artificial materials, and higher positive affect in the presence of windows vs no window condition, making the stress results similar to those in the lab. Additionally, windows and diverse representations promoted belonging and creativity, respectively. A virtual reality (VR) replication is currently underway with identical variables to investigate the role of VR in facilitating research in this field. Our work contributes to a better understanding of the value of different workplaces (e.g., office, hybrid, or remote) based on their design characteristics.},
    booktitle     = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
    pages         = {299–300},
    numpages      = {2},
    keywords      = {crowdsourcing platforms, human wellbeing, virtual reality, workplace design},
    location      = {Boston, Massachusetts},
    series        = {BuildSys '22}
}
@inproceedings{10.1145/3712678.3721874,
    author        = {Jorgensen, Kyle and Wang, Mea and Krishnamurthy, Diwakar},
    title         = {Enabling Distance-Aware Real-Time Volumetric Video Streaming},
    year          = {2025},
    isbn          = {9798400714696},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3712678.3721874},
    doi           = {10.1145/3712678.3721874},
    abstract      = {Live, real-time volumetric video streaming enables immersive remote communication by transmitting 3D representations of participants, but faces significant bandwidth and computational challenges on consumer hardware. We introduce a distance-aware volumetric video streaming method that prunes point cloud data in real time based on both real-world and virtual viewing distances before any conventional compression or tiling is applied. Our prototype, RealityStream, uses a single Kinect v1 for capture, referencing a precomputed VMAF-driven distance table to guide adaptive downsampling for transmission. This effectively reduces bandwidth demand by up to 65\% while maintaining acceptable visual fidelity. Implemented on a commodity laptop and streamed to a standalone VR headset, RealityStream is shown to be practical, achieving end-to-end latencies of around 75 ms. These findings highlight that taking into account both real and virtual distance is a low-complexity approach for efficient, real-time volumetric video capture and streaming. RealityStream will benefit existing volumetric streaming platforms, making real-time 3D communication more efficient over networks.},
    booktitle     = {Proceedings of the 35th Workshop on Network and Operating System Support for Digital Audio and Video},
    pages         = {1–7},
    numpages      = {7},
    keywords      = {Distance-Aware, Downsampling, Immersive Communication, Mixed Reality, Real-time Streaming, Telepresence, Virtual Reality, Volumetric Video},
    location      = {Stellenbosch, South Africa},
    series        = {NOSSDAV '25}
}
@inproceedings{10.1145/3592834.3592879,
    author        = {Ara\'{u}jo, Gabriel De Castro and Garcia, Henrique Domingues and Farias, Mylene and Prakash, Ravi and Carvalho, Marcelo},
    title         = {360EAVP: A 360-degree Edition-Aware Video Player},
    year          = {2023},
    isbn          = {9798400701894},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3592834.3592879},
    doi           = {10.1145/3592834.3592879},
    abstract      = {In this work, we introduce 360EAVP, an open-source Web browser-based application for streaming and visualization of 360-degree edited videos on head-mounted displays (HMD). The proposed application builds upon the Virtual Reality Tile-Based 360-degree Player (VDTP) by adding new functionalities. Specifically, this paper explains the main features introduced by 360EAVP, which are: 1) operation on HMDs based on real-time user's viewport; 2) dynamic editing via "snap-change" or "fade-rotation" combined with "blinking"; 3) visibility evaluation of user's Field of View with respect to the player's cubic projection (for purposes of tile requests); 4) incorporation of editing timing information into the operation of the ABR algorithm; 5) viewport prediction module based on either linear regression or ridge regression algorithms; and 6) data collection and log module during video playback. The introduced application can be freely used to support research on many topics such as optimization of tile-based 360-degree edited video streaming, psycho-physical experiments, dataset generation, and ABR algorithm development, to name a few.},
    booktitle     = {Proceedings of the 15th International Workshop on Immersive Mixed and Virtual Environment Systems},
    pages         = {18–23},
    numpages      = {6},
    keywords      = {360-degree videos, video processing, streaming, virtual reality},
    location      = {Vancouver, BC, Canada},
    series        = {MMVE '23}
}
@inproceedings{10.1145/3629606.3629608,
    author        = {Wu, Youwen and Huang, Zhang},
    title         = {Research on Human-computer Interaction Design System based on Computer Artificial Intelligence technology},
    year          = {2024},
    isbn          = {9798400716454},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3629606.3629608},
    doi           = {10.1145/3629606.3629608},
    abstract      = {This paper discusses the usability of electric vehicle control interface from the perspective of differentiated human-computer interaction design. Virtual reality technology is used to evaluate the human-computer interaction design scheme of vehicle to improve the iterative efficiency and reduce the investment of capital in the process of interaction design. This paper uses the interactive design scheme of real person and virtual vehicle to interact. At the same time, the test equipment was used to collect video, audio, eye movement track, skin electroencephalography, infrared brain and other data and information, and to conduct data analysis and design evaluation. Experiments show that the software system has good effectiveness and stability.},
    booktitle     = {Proceedings of the Eleventh International Symposium of Chinese CHI},
    pages         = {20–24},
    numpages      = {5},
    location      = {Denpasar, Bali, Indonesia},
    series        = {CHCHI '23}
}
@inproceedings{10.1145/3558482.3581776,
    author        = {Lasierra, Oscar and Garcia-Aviles, Gines and Municio, Esteban and Skarmeta, Antonio and Costa-P\'{e}rez, Xavier},
    title         = {European 5G Security in the Wild: Reality versus Expectations},
    year          = {2023},
    isbn          = {9781450398596},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3558482.3581776},
    doi           = {10.1145/3558482.3581776},
    abstract      = {5G cellular systems are slowly being deployed worldwide delivering the promised unprecedented levels of throughput and latency to hundreds of millions of users. At such scale security is crucial, and consequently, the 5G standard includes a new series of features to improve the security of its predecessors (i.e., 3G and 4G). In this work, we evaluate the actual deployment in practice of the promised 5G security features by analysing current commercial 5G networks from several European operators. By collecting 5G signalling traffic in the wild in several cities in Spain, we i) fact-check which 5G security enhancements are actually implemented in current deployments, ii) provide a rich overview of the implementation status of each 5G security feature in a wide range of 5G commercial networks in Europe and compare it with previous results in China, iii) analyse the implications of optional features not being deployed, and iv) discuss on the still remaining 4G-inherited vulnerabilities. Our results show that in European 5G commercial networks, the deployment of the 5G security features is still on the works. This is well aligned with results previously reported from China [16] and keeps these networks vulnerable to some 4G attacks, during their migration period from 4G to 5G.},
    booktitle     = {Proceedings of the 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
    pages         = {13–18},
    numpages      = {6},
    keywords      = {5g, experimental data collection, security, subscriber anonymity, subscriber privacy},
    location      = {Guildford, United Kingdom},
    series        = {WiSec '23}
}
@inproceedings{10.14236/ewic/BCSHCI2023.6,
    author        = {Khattak, Khalid Ahmad and Woolley, Sandra I.},
    title         = {A Survey of Wearable Tracker Version Updates},
    year          = {2024},
    isbn          = {1234567891011},
    publisher     = {BCS Learning \&amp; Development Ltd},
    address       = {Swindon, GBR},
    url           = {https://doi.org/10.14236/ewic/BCSHCI2023.6},
    doi           = {10.14236/ewic/BCSHCI2023.6},
    abstract      = {As part of a requirements elicitation process for the design of improved interfaces to system-level data, this short paper compares and contrasts wearable tracker 'changelog' documents that communicate software and embedded firmware updates. Seventeen models of five device families of heart rate sensing wearable trackers (from four manufacturers) conformed to specified selection criteria. The changelogs for these devices over a two-year period were analysed for content, style and consistency. Although the emphasis of all changelogs was on reporting improvements and fixes, markedly different styles were observed between manufacturers. The number of update items per version entry for the seventeen tracker changelogs varied from 1 to 6.5 and the number of words per item varied across manufacturer changelogs from 4.6 (Withings) to 18.9 (Fitbit). Changelog entries for Garmin and Withings devices employed a bullet point presentation style whereas Fitbit and Polar changelogs employed a combination of prose and bullet points. In contrast to the concise bullet points of Withings changelogs, Fitbit changelogs had a more conversational style and addressed the user in 2nd person (you/your). Ideally, the presentation, detail and relevance of changelog content would be tailored according to the needs and preferences of stakeholders such as user wearers, researchers or health professionals.},
    booktitle     = {Proceedings of the 36th International BCS Human-Computer Interaction Conference},
    pages         = {49–53},
    numpages      = {5},
    keywords      = {Changelog, Release notes, Health technology, Wearable trackers, Updates},
    location      = {University of York, UK},
    series        = {BCS HCI '23}
}
@inproceedings{10.1145/3631726.3631732,
    author        = {Zhang, Yiqiang and Chen, Xinrong and Wei, Lizheng and Che, Jiaxing and Liu, Peichu and Cui, Jun-Hong},
    title         = {VISS-CF: Visual-Inertial Odometry and Sonar Fused SLAM Framework with Enhanced Corner Feature Matching for Underwater Environment},
    year          = {2024},
    isbn          = {9798400716744},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3631726.3631732},
    doi           = {10.1145/3631726.3631732},
    abstract      = {Underwater simultaneous localization and mapping (SLAM) constitutes a critical foundation for marine vehicle navigation. However, underwater SLAM faces challenges such as high motion distortion and low matching efficiency. In response to this, we introduce a visual-inertial odometry (VIO) and sonar fused SLAM framework with enhanced corner feature matching. Initially, we employ VIO to remove the motion distortion. Additionally, we design a localized corner feature matching mechanism to enhance iterative closest point (ICP) SLAM, aiming to increase both the matching frequency and precision. Experimental results demonstrate that our approach outperforms the compared methods in terms of performance.},
    booktitle     = {Proceedings of the 17th International Conference on Underwater Networks \&amp; Systems},
    articleno     = {5},
    numpages      = {5},
    keywords      = {Underwater SLAM, corner feature matching, iterative closest point., visual-inertial odometry},
    location      = {Shenzhen, China},
    series        = {WUWNet '23}
}
@inproceedings{10.1145/3056540.3056556,
    author        = {Ceccacci, S. and Mengoni, M.},
    title         = {Designing Smart Home Interfaces: Traditional vs Virtual Prototyping},
    year          = {2017},
    isbn          = {9781450352277},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3056540.3056556},
    doi           = {10.1145/3056540.3056556},
    abstract      = {This paper presents a structured User Centered Design (UCD) method to design and develop a highly usable smart home platform to manage the energy consumption of connected appliances. It exploits advanced Tangible Augmented Reality (TAR) technologies to virtually prototype the conceived design solutions and carry out usability testing with sample users. Usability tests are carried out both on traditional high fidelity prototypes and on an innovative Tangible Augmented Reality prototype. Experimental results prove the efficiency of the UCD approach supported by virtual prototypes, instead of traditional ones, the reliability of TAR prototypes to detect usability problems and assess user satisfaction, and its high interaction quality. Advantages obtainable by implementing the proposed structured UCD approach for web interface design, in the context of smart home, are discussed.},
    booktitle     = {Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments},
    pages         = {67–74},
    numpages      = {8},
    keywords      = {Human Centered Computing, Human Computer Interaction, User Centered Design, User Interface Design, Virtual Prototyping, Virtual Reality},
    location      = {Island of Rhodes, Greece},
    series        = {PETRA '17}
}
@inproceedings{10.1145/3625468.3647612,
    author        = {Alhilal, Ahmad and Wu, Ze and Tsui, Yuk Hang and Hui, Pan},
    title         = {FovOptix: Human Vision-Compatible Video Encoding and Adaptive Streaming in VR Cloud Gaming},
    year          = {2024},
    isbn          = {9798400704123},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3625468.3647612},
    doi           = {10.1145/3625468.3647612},
    abstract      = {VR cloud gaming enables users to play high-end VR games on lightweight devices by offloading rendering tasks to cloud servers. Despite video compression, high-definition video streaming requires substantial data transfer rates. Foveated rendering (FR) and video encoding (FVE) leverage the non-uniform perception of the human visual system to reduce computing and bandwidth demand. They enhance visual quality in central gaze regions and reduce it in the periphery. However, bandwidth variation may hinder the provision of smooth VR gaming experiences. We present FovOptix, a system that combines FR with adaptive FVE to deliver video stream at a lower yet adaptive bitrate while not compromising the perceived video quality. FovOptix is based on a game-agnostic open-source to ensure reproducibility and compatibility with various games. We evaluate FovOptix against benchmarks using 5G mobile network traces. FovOptix achieves a latency reduction of 3\% compared to the Google standard and a significant +100\% reduction compared to other solutions. Additionally, it enhances the visual quality within the player's region of interest. Consequently, FovOptix attains the highest playability and gaming scores while minimizing the severity of motion sickness. FovOptix thus offers smooth and accessible VR cloud gaming for a wider range of players.},
    booktitle     = {Proceedings of the 15th ACM Multimedia Systems Conference},
    pages         = {67–77},
    numpages      = {11},
    keywords      = {Adaptive Video Streaming, Foveated Video Encoding, Human Vision System, VR Cloud Gaming},
    location      = {Bari, Italy},
    series        = {MMSys '24}
}
@inproceedings{10.1145/3649902.3653350,
    author        = {Wang, Yao and Dai, Qi and B\^{a}ce, Mihai and Klein, Karsten and Bulling, Andreas},
    title         = {Saliency3D: A 3D Saliency Dataset Collected on Screen},
    year          = {2024},
    isbn          = {9798400706073},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3649902.3653350},
    doi           = {10.1145/3649902.3653350},
    abstract      = {While visual saliency has recently been studied in 3D, the experimental setup for collecting 3D saliency data can be expensive and cumbersome. To address this challenge, we propose a novel experimental design that utilises an eye tracker on a screen to collect 3D saliency data, which could reduce the cost and complexity of data collection. We first collected gaze data on a computer screen and then mapped the 2D points to 3D saliency data through perspective transformation. Using this method, we propose Saliency3D, a 3D saliency dataset (49,276 fixations) comprising 10 participants looking at sixteen objects. We examined the viewing preferences for objects and our results indicate potential preferred viewing directions and a correlation between salient features and the variation in viewing directions.},
    booktitle     = {Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
    articleno     = {19},
    numpages      = {6},
    keywords      = {3D saliency, eye-tracking study, gaze behavior},
    location      = {Glasgow, United Kingdom},
    series        = {ETRA '24}
}
@inproceedings{10.1145/3027063.3027133,
    author        = {Carrasco, Romina},
    title         = {Designing Virtual Avatars to Empower Social Participation among Older Adults},
    year          = {2017},
    isbn          = {9781450346566},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3027063.3027133},
    doi           = {10.1145/3027063.3027133},
    abstract      = {Social participation among older adults improves quality of life, reducing negative emotions that may lead to depression or premature death. The use of virtual avatars (self representations of the user) in online environments can support social participation by providing opportunities for enjoyment. These new online self-representations can affect the behavior of users in both the digital and the physical world. However, further study is needed to identify how to promote social participation for older adults through appropriate design of avatars.},
    booktitle     = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
    pages         = {259–262},
    numpages      = {4},
    keywords      = {older adults, online games, social participation, virtual avatars, virtual reality},
    location      = {Denver, Colorado, USA},
    series        = {CHI EA '17}
}
@inproceedings{10.1109/ISMAR.2007.4538859,
    author        = {Jeon, Seokhee and Kim, Gerard J.},
    title         = {Mosaicing a Wide Geometric Field of View for Effective Interaction in Augmented Reality},
    year          = {2007},
    isbn          = {9781424417490},
    publisher     = {IEEE Computer Society},
    address       = {USA},
    url           = {https://doi.org/10.1109/ISMAR.2007.4538859},
    doi           = {10.1109/ISMAR.2007.4538859},
    booktitle     = {Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality},
    pages         = {1–2},
    numpages      = {2},
    series        = {ISMAR '07}
}
@inproceedings{10.1145/3424616.3424713,
    author        = {Whang, Jooyoung and Polys, Nicholas F.},
    title         = {DeepCinema: Adding Depth with X3D Image-Based Rendering},
    year          = {2020},
    isbn          = {9781450381697},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3424616.3424713},
    doi           = {10.1145/3424616.3424713},
    abstract      = {In scientific research, data visualization is crucial for human understanding and insight. Modern experiments and simulations are increasingly growing in scale and complexity; as we approach the Exascale of big data, current methods of interactive 3D scientific visualization become untenable. Cinema has proposed as an Image-Based solution to this problem, where instead of explicit 3D geometry, the model is represented by an image database, through which users navigate among pre-rendered (in situ) screenshots. However, flat images alone cannot fully express the 3D characteristics of a data. Thus, we propose the DeepCinema technique to improve the depth portrayal of Image-Based Rendering using Displacement Maps and shading. We examine the perceptual efficacy of our technique with a 2-Alternative, Forced Choice user study of 60 participants. The within-subjects multi-factorial design compared user depth judgements over: Displacement Map, shading, and the interval of angular perspective for each image. Results show that this method would be useful for the interactive 3D visualization of Big Scientific Data using Web3D Standards.},
    booktitle     = {Proceedings of the 25th International Conference on 3D Web Technology},
    articleno     = {19},
    numpages      = {10},
    keywords      = {Big Data, Image-Based Rendering, Scientific Visualization, Web3D},
    location      = {Virtual Event, Republic of Korea},
    series        = {Web3D '20}
}
@inproceedings{10.1145/1450579.1450606,
    author        = {Steed, Anthony},
    title         = {A simple method for estimating the latency of interactive, real-time graphics simulations},
    year          = {2008},
    isbn          = {9781595939517},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/1450579.1450606},
    doi           = {10.1145/1450579.1450606},
    abstract      = {One of the critical determinants of the effectiveness and usability of interactive graphics simulations is the latency with which visual updates can be made based on input from interaction devices. High latency can diminish performance and can lead to simulator sickness. We demonstrate a new method for measuring latency using a standard video camera. The method is simple to configure, sensitive and rapid to use. This is in contrast to previous methods which required specialized equipment, were laborious or could only determine gross changes in latency. We attach a tracker to a pendulum and move a simulated image on the screen using the tracker positions. We video both the pendulum and simulated image together, and fit two sine curves, one to centre of motion of pendulum and one to the centre of motion of the simulated image. From the phase difference between these two sine curves we can determine latency changes significantly less than the frame rate of the camera. We demonstrate the method by comparing the latency of a two different systems for a CAVE\texttrademark{}-like display.},
    booktitle     = {Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology},
    pages         = {123–129},
    numpages      = {7},
    keywords      = {interactive systems, latency, performance, real-time graphics, system design},
    location      = {Bordeaux, France},
    series        = {VRST '08}
}
@inproceedings{10.1145/3083187.3084012,
    author        = {Shea, Ryan and Sun, Andy and Fu, Silvery and Liu, Jiangchuan},
    title         = {Towards Fully Offloaded Cloud-based AR: Design, Implementation and Experience},
    year          = {2017},
    isbn          = {9781450350020},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3083187.3084012},
    doi           = {10.1145/3083187.3084012},
    abstract      = {Combining advanced sensors and powerful processing capabilities smart-phone based augmented reality (AR) is becoming increasingly prolific. The increase in prominence of these resource hungry AR applications poses significant challenges to energy constrained environments such as mobile-phones.; AB\@To that end we present a platform for offloading AR applications to powerful cloud servers. We implement this system using a thin-client design and explore its performance using the real world application Pokemon Go as a case study. We show that with careful design a thin client is capable of offloading much of the AR processing to a cloud server, with the results being streamed back. Our initial experiments show substantial energy savings, low latency and excellent image quality even at relatively low bit-rates.},
    booktitle     = {Proceedings of the 8th ACM on Multimedia Systems Conference},
    pages         = {321–330},
    numpages      = {10},
    keywords      = {Augmented Reality, Cloud Offloading, Mobile Gaming},
    location      = {Taipei, Taiwan},
    series        = {MMSys'17}
}
@inproceedings{10.1145/1806565.1806570,
    author        = {Varvello, Matteo and Voelker, Geoffrey M.},
    title         = {Second life: a social network of humans and bots},
    year          = {2010},
    isbn          = {9781450300438},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/1806565.1806570},
    doi           = {10.1145/1806565.1806570},
    abstract      = {Second Life (SL) is a virtual world where people interact and socialize through virtual avatars. Avatars behave similarly to their human counterparts in real life and naturally define a social network. However, not only human-controlled avatars participate in the social network. Automated avatars called bots are common, difficult to identify and, when malicious, can severely detract from the user experience of SL. In this paper we study the SL social network and the role of bots within it. Using traces of avatars in a popular SL region, we analyze the social graph formed by avatar interactions. We find that it resembles natural networks more than other online social networks, and that bots have a fundamental impact on the SL social network. Finally, we propose a bot detection strategy based on the importance of the social connections of avatars in the social graph.},
    booktitle     = {Proceedings of the 20th International Workshop on Network and Operating Systems Support for Digital Audio and Video},
    pages         = {9–14},
    numpages      = {6},
    keywords      = {bot detection, second life, social networking},
    location      = {Amsterdam, The Netherlands},
    series        = {NOSSDAV '10}
}
@inproceedings{10.1145/1836049.1836073,
    author        = {Eno, Joshua and Gauch, Susan and Thompson, Craig W.},
    title         = {Linking behavior in a virtual world environment},
    year          = {2010},
    isbn          = {9781450302098},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/1836049.1836073},
    doi           = {10.1145/1836049.1836073},
    abstract      = {Linking between separate virtual world environments differs significantly from flat web linking, both in terms of technical challenges and user experience. Considering these differences, and the need for individual users to actually create links between locations, it is not clear to what extent the technical linking capability will lead to a truly interconnected world wide web of 3D environments. In order to study linking behavior in a current 3D environment, we examined explicit landmark links as well as implicit avatar pick links in Second Life to determine if linking patterns in a large virtual world corresponded to linking behavior in the flat web. To collect landmark and favorites data, we designed a multi-agent virtual world crawler system to collect publicly available landmarks and avatar picks. To compare the link graph structure of the virtual world link graph to the flat web link graph, we replicate the analysis performed on several flat web link graphs and compare the results. We also explore the correlation between location ranking based on link-based algorithms to internally tracked traffic rankings, which has only recently been done with flat web data sets. We find that although the virtual world link graph is more sparse than the flat web, the underlying structure is quite similar. That users have generated this link graph despite the relative difficulty of creating and following links in the Second Life environment indicates that linking is valued by users, and making linking easier would likely result in a richer user experience.},
    booktitle     = {Proceedings of the 15th International Conference on Web 3D Technology},
    pages         = {157–164},
    numpages      = {8},
    keywords      = {3D web, hyperlink network analysis, virtual worlds},
    location      = {Los Angeles, California},
    series        = {Web3D '10}
}
@inproceedings{10.1109/ISMAR.2008.4637322,
    author        = {Veas, Eduardo and Kruijff, Ernst},
    title         = {Vesp'R: design and evaluation of a handheld AR device},
    year          = {2008},
    isbn          = {9781424428403},
    publisher     = {IEEE Computer Society},
    address       = {USA},
    url           = {https://doi.org/10.1109/ISMAR.2008.4637322},
    doi           = {10.1109/ISMAR.2008.4637322},
    abstract      = {This paper focuses on the design of devices for handheld spatial interaction. In particular, it addresses the requirements and construction of a new platform for interactive AR, described from an ergonomics stance, prioritizing human factors of spatial interaction. The result is a multi-configurable platform for spatial interaction, evaluated in two AR application scenarios. The user tests validate the design with regards to grip, weight balance and control allocation, and provide new insights on the human factors involved in handheld spatial interaction.},
    booktitle     = {Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
    pages         = {43–52},
    numpages      = {10},
    series        = {ISMAR '08}
}
@inproceedings{10.1145/1026633.1026638,
    author        = {Appan, Preetha and Sundaram, Hari and Birchfield, David},
    title         = {Communicating everyday experiences},
    year          = {2004},
    isbn          = {1581139314},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/1026633.1026638},
    doi           = {10.1145/1026633.1026638},
    abstract      = {In this paper, we present our approach to the problem of communicating everyday experiences. This is a challenging problem, since media from everyday events are unstructured, and often poorly annotated. We first attempt to communicate everyday experiences using a dramatic framework, by categorizing media and by introducing causal relations. Based on our experience of the dramatic framework for the everyday media, we introduce an event based framework as well as a viewpoint centric visualization that allows the viewer to have agency, in a highly interactive, non-linear manner. Our approach focuses on structured interaction for consumption of everyday experiences, in contrast to non-interactive consumption of structured communication. Our results indicate that dramatic structures do not work well with everyday media, and novel interactions / visualizations are needed. Experimental results indicate that the viewpoint centric visualization works well. We are in the process of creating a large event database of everyday events, and we are creating the necessary recording and annotation tools.},
    booktitle     = {Proceedings of the 1st ACM Workshop on Story Representation, Mechanism and Context},
    pages         = {17–24},
    numpages      = {8},
    keywords      = {browser, events, networked media, storytelling},
    location      = {New York, NY, USA},
    series        = {SRMC '04}
}
@article{10.1145/3532854,
    author        = {Ngo, Duyen Thi and Ta, Cuong Viet and Ma, Chau Thi and Nguyen, Hoa Minh and Nguyen, Hung Xuan and Le, Ha Thanh},
    title         = {Quality Assessment Criteria and Methods for 3D Digital Replica of Historical Printing Woodblocks},
    year          = {2023},
    issue_date    = {September 2023},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    volume        = {16},
    number        = {3},
    issn          = {1556-4673},
    url           = {https://doi.org/10.1145/3532854},
    doi           = {10.1145/3532854},
    abstract      = {With the available 3D scanning technologies and the special historical characteristics of printing woodblocks, it is necessary to have concrete methods to assess the visual quality of 3D digital replica for preservation and promotion purposes. In this paper, we present our study for assessing the visual quality of 3D digital replica of historical printing woodblocks. In our study, first, assessment criteria are formed to meet the preservation requirements by consulting with printing woodblock conservationists and assessment methods are developed to assess the quality of 3D digital woodblock replica regarding those criteria. Then, a suitable 3D scanning method is applied to a typical set of printing woodblocks to obtain their 3D digital replicas which are used to evaluate the proposed assessment methods. The experimental results reveal that our proposed assessment criteria and methods can be used to evaluate visual quality of 3D digital woodblock replicas regarding the requirements of preservation and promotion of woodblocks.},
    journal       = {J. Comput. Cult. Herit.},
    month         = aug,
    articleno     = {43},
    numpages      = {16},
    keywords      = {3D replica quality assessment, printing woodblocks, 3D reconstruction, printing woodblock digitization}
}
@inproceedings{10.1145/3700906.3700927,
    author        = {Wang, Jiangtao and Li, Huan and Yin, Jinghui and Gao, Suyuan and Yan, Pengkun},
    title         = {Research on Key Technologies for Realistic 3D Modeling of Ancient Buildings},
    year          = {2024},
    isbn          = {9798400707032},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3700906.3700927},
    doi           = {10.1145/3700906.3700927},
    abstract      = {This article takes ancient architecture in Shaanxi Province as the research object. Based on laser 3D scanning technology, the seamless integration of point cloud data and GIS data of individual buildings is completed through unmanned aerial vehicles and RTK, forming a process of spatial data acquisition based on ancient architecture. The key technologies include oblique photography mesh model acquisition, laser point cloud model acquisition, and parameterized 3D model generation. By using dynamic uniform light and color processing to tilt aerial photography images, the color effect of the images is improved, and a high-precision Mesh model is generated using the ContextCapture system. At the same time, scientific and reasonable denoising methods are adopted to process laser point cloud data, ensuring the quality of the point cloud. In model generation, texture compression algorithm is applied to optimize OBJ data, improve texture mapping utilization and model loading efficiency. In the end, the fusion of multi-source data successfully produced real-life 3D models of five ancient buildings, including the Big Wild Goose Pagoda and Bell Tower, providing technical support for the digital protection and dissemination of cultural heritage.},
    booktitle     = {Proceedings of the International Conference on Image Processing, Machine Learning and Pattern Recognition},
    pages         = {128–134},
    numpages      = {7},
    keywords      = {Ancient architecture, Data fusion, Dealistic 3D technology},
    location      = {},
    series        = {IPMLP '24}
}
@inproceedings{10.1145/3409251.3411725,
    author        = {Kim, Young Woo and Han, Jae Hyun and Ji, Yong Gu and Lee, Seul Chan},
    title         = {Exploring the Effectiveness of External Human-Machine Interfaces on Pedestrians and Drivers},
    year          = {2020},
    isbn          = {9781450380669},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3409251.3411725},
    doi           = {10.1145/3409251.3411725},
    abstract      = {Previous literature provided the results that eHMIs can be an effective method in interacting with pedestrians. However, there remains a question whether eHMIs are also effective for other road users or not. Therefore, the present study aimed to explore subjective evaluations on eHMIs with two different perspectives, pedestrians and drivers around AVs. Subjective preferences to different types of eHMIs were investigated through an online survey. Nine types of eHMIs were designed based on the combinations of display location and sign format. The results showed that people have different attitudes towards eHMIs depending on their perspectives. The participants as driver evaluated the bottom condition negatively compared to the pedestrian, and the participants as pedestrians felt that icons are not a good option compared to the drivers. The findings of the present study contribute to design of eHMI considering various road users.},
    booktitle     = {12th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
    pages         = {65–68},
    numpages      = {4},
    keywords      = {External Human-Machine Interfaces, Display Location, Sign Format, Road User},
    location      = {Virtual Event, DC, USA},
    series        = {AutomotiveUI '20}
}
@inproceedings{10.1145/3424616.3424726,
    author        = {Almansoury, Farag and Kpodjedo, S\`{e}gla and Boussaidi, Ghizlane El},
    title         = {Investigating Web3D topics on StackOverflow: a preliminary study of WebGL and Three.js},
    year          = {2020},
    isbn          = {9781450381697},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3424616.3424726},
    doi           = {10.1145/3424616.3424726},
    abstract      = {Web3D developers often have to decide on which technologies are best for their projects. We explore that question through the perspective of community attention and support on Stack Overflow (SO). We focused on i) WebGL, a key low-level JavaScript (JS) API used to render 3D graphics in browsers without plugins, and ii) Three.js, a higher level JS library that reuses WebGL and is reputed easier and more intuitive. We considered questions from SO tagged with WebGL or Three.js and extracted all tags used on these questions. Using these, we were able to compare the relative attention (considering the number of questions and views) and support (considering satisfactory answers and how long they take) received by concerns and technologies associated to WebGL and Three.js. Our results suggest that Three.js gets significantly more community attention but less community support than WebGL on SO.},
    booktitle     = {Proceedings of the 25th International Conference on 3D Web Technology},
    articleno     = {32},
    numpages      = {2},
    keywords      = {StackOverflow, Three.js, Web3D, WebGL, empirical study},
    location      = {Virtual Event, Republic of Korea},
    series        = {Web3D '20}
}
@article{10.1145/267135.267137,
    author        = {Watson, Benjamin and Walker, Neff and Hodges, Larry F. and Worden, Aileen},
    title         = {Managing level of detail through peripheral degradation: effects on search performance with a head-mounted display},
    year          = {1997},
    issue_date    = {Dec. 1997},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    volume        = {4},
    number        = {4},
    issn          = {1073-0516},
    url           = {https://doi.org/10.1145/267135.267137},
    doi           = {10.1145/267135.267137},
    abstract      = {Two user studies were performed to evaluate the effect of level-of-detail (LOD) degradation in the periphery of head-mounted displays on visual search performance. In the first study, spatial detail was degraded by reducing resolution. In the second study, detail was degraded in the color domain by using grayscale in the periphery. In each study, 10 subjects were given a complex search task that required users to indicate whether or not a target object was present among distracters. Subjects used several different displays varying in the amount of detail presented. Frame rate, object location, subject input method, and order of display use were all controlled. The primary dependent measures were search time on correctly performed trials and the percentage of all trials correctly   performed. Results indicated that peripheral LOD degradation can be used to reduce color or spatial visual complexity by almost half in some search tasks with out significantly reducing performance.},
    journal       = {ACM Trans. Comput.-Hum. Interact.},
    month         = dec,
    pages         = {323–346},
    numpages      = {24},
    keywords      = {detail management, high-detail inset, level of detail, object simplification, peripheral degradation, visual search}
}
@inproceedings{10.1145/3630138.3630497,
    author        = {Xie, Chaochen and Song, Jianqiang and Guo, Rujing},
    title         = {Research of mobile edge computing optimization technology based on cell-optimized coverage},
    year          = {2024},
    isbn          = {9781450399951},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3630138.3630497},
    doi           = {10.1145/3630138.3630497},
    abstract      = {In The Internet of Things (IoT), fast response and low energy consumption have been the focus of the technology processing. To effectively reduce the energy consumption and arduous data processing tasks of mobile terminals, transferring data to edge servers for processing is the main current processing method, but this undoubtedly increases the time cost again. In this paper, we densely deploy edge computing servers so that they can be as close as possible to the mobile terminals, while using an optimal coverage combined with a greedy algorithm optimization approach. Simulation results show that this strategy is significant in terms of data transfer time cost and reduced energy consumption. Meanwhile, the impact of data transfer transmission probability on time cost and energy consumption in mobile edge computing is also analyzed in this paper.CCS KEYWORDS \textbullet{} Modeling and Simulation evaluation\textbullet{} Mathematical analysis and Calculus\textbullet{} Planning and scheduling},
    booktitle     = {Proceedings of the 2023 International Conference on Power, Communication, Computing and Networking Technologies},
    articleno     = {74},
    numpages      = {7},
    keywords      = {Edge Computing, Greedy Algorithm, Internet of Things, Optimal Coverage, transfer Probability},
    location      = {Wuhan, China},
    series        = {PCCNT '23}
}
@inproceedings{10.1145/2910674.2935853,
    author        = {Amores, Judith and Maes, Pattie},
    title         = {Influencing Human Behavior by Means of Subliminal Stimuli using Scent, Light and Brain Computer Interfaces},
    year          = {2016},
    isbn          = {9781450343374},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/2910674.2935853},
    doi           = {10.1145/2910674.2935853},
    abstract      = {We present a proof-of-concept system that integrates ambient lights with a custom made olfactory display that releases subtle burst of scent triggered by brain signals and micro face-gestures such as blinks or jaw clenches. We non-invasively monitor real-time brain activity data using EEG and reflect this information using scent and subtle changes in the ambient light of the environment. This paper discusses different applications for this type of system as well as the implementation of the olfactory display and the supporting software that connects the ambient lights and the EEG sensor. We also discuss the use of subliminal cues like tuning the lighting setup and varying the scent for different kind of behavior changes.},
    booktitle     = {Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
    articleno     = {62},
    numpages      = {4},
    keywords      = {BCI, HCI, IoT, affective computing, home automation, olfactory interfaces, pervasive, scent, smart environments, subliminal, unconscious, wearable},
    location      = {Corfu, Island, Greece},
    series        = {PETRA '16}
}
@inproceedings{10.1145/3556089.3556143,
    author        = {Dai, Jianping and Zhou, Pengyun},
    title         = {The Influence of Platforms and Anchors on Consumers' Continuous Participation in The Context of E-commerce Live Broadcast: Empirical Evidence of Textile and Garment Products},
    year          = {2022},
    isbn          = {9781450396394},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3556089.3556143},
    doi           = {10.1145/3556089.3556143},
    abstract      = {The shopping experience of garment consumers in the live broadcast situation belongs to the subjective feeling of psychological level, which will dominate consumers' purchase behavior to a certain extent. The purpose of this paper is to clarify the impact and degree of platform and anchor on consumers' psychological experience and continuous participation in the live broadcast of garment. Based on the perspective of consumer psychological experience and using S-O-R model, this paper constructs the structural equation model of platform, anchor, consumer psychological experience and continuous participation. The Amos tool and 216 questionnaires were used for empirical test, the empirical results show that the anchor's interactive behavior in textile and garment live broadcast will enhance consumers' psychological experience and make them feel happy and immersed. The user interface design and platform interaction will have a positive impact on consumers' psychological experience. The anchor and platform indirectly affect consumers' continuous participation through consumers' psychological experience, in which consumers' psychological experience plays an intermediary role.},
    booktitle     = {Proceedings of the 2022 13th International Conference on E-Business, Management and Economics},
    pages         = {37–44},
    numpages      = {8},
    location      = {Beijing, China},
    series        = {ICEME '22}
}
@inproceedings{10.1145/3397056.3397076,
    author        = {Zhang, Xunhu and Wei, Xiaojuan},
    title         = {The Exploration and Practice of 3D Laser Scanning in the Safety Detection of Beijing Bell and Drum Towers},
    year          = {2020},
    isbn          = {9781450377416},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3397056.3397076},
    doi           = {10.1145/3397056.3397076},
    abstract      = {In order to make Beijing Bell and Drum Towers' Safety detection and structural stability evaluation, we carried out a three-dimensional laser surveying and mapping of Beijing Bell and Drum Towers. And based on three-dimensional laser point cloud data, carried out flat, vertical, cross-sectional construction mapping of the main architecture, texture mapping, city platform tower wall inclined, tilted of the floor, wall roughness and surface flatness measuring of City platform, deformation detection of large timber structure, skew measurement of stone railing and other comprehensive detection work. It provides a detailed basis for the stability evaluation of the main architecture structure. In practice, explore the ancient architecture integrated application safety Inspection items use three-dimensional laser scanning technology, to carry out deformation measurement, disease testing and Safety detection of technical methods and procedures. At the same time, it also provides a comprehensive and detailed data for the follow-up repair engineering design and current data retention.},
    booktitle     = {Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis},
    pages         = {127–131},
    numpages      = {5},
    keywords      = {3D Laser Scanning, Safety Detection, Stability Evaluation, Three-dimensional Point Cloud},
    location      = {Marseille, France},
    series        = {ICGDA '20}
}
@inproceedings{10.1145/3321454.3321463,
    author        = {Kim, Jung-Sook and Jeong, Junho and Chung, Tae-Sub},
    title         = {Development of the IoT- Based Remote Monitoring System of Sleeping Hours},
    year          = {2019},
    isbn          = {9781450366335},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3321454.3321463},
    doi           = {10.1145/3321454.3321463},
    abstract      = {In today's aging society, the need for effective health care for the elderly living alone is increasing enormously. Therefore, it is required to establish a system to cope with daily health check and emergency situation. And, we introduce you to IoT services in the manufacturing industry, in which IoT is expected to have the greatest impact. Of various requirements, sleep is the most important part of health since we spend 1/4 of a day's time for sleep. Accordingly, healthy sleep management and periodic confirmation of sleep are the most important. In this paper, we propose an IoT-based Smart Mat with multiple sensors connected for remote monitoring of the elderly living alone or healthcare users and a system model that can collect data on bedtime, wakeup time, and sleep quality, and develop the recorded contents through it and send them to the smartphone application of the guardians in real time for remote monitoring.},
    booktitle     = {Proceedings of the 2019 4th International Conference on Intelligent Information Technology},
    pages         = {42–45},
    numpages      = {4},
    keywords      = {Healthcare, IoT, Mobile Application, Remote monitoring, Sleeping Hours, Smart Mat System},
    location      = {Da, Nang, Viet Nam},
    series        = {ICIIT '19}
}
@inproceedings{10.1145/3465481.3470060,
    author        = {Sitterer, Alex and Dubois, Nicholas and Baggili, Ibrahim},
    title         = {Forensicast: A Non-intrusive Approach \&amp; Tool For Logical Forensic Acquisition \&amp; Analysis of The Google Chromecast TV},
    year          = {2021},
    isbn          = {9781450390514},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/3465481.3470060},
    doi           = {10.1145/3465481.3470060},
    abstract      = {The era of traditional cable Television (TV) is swiftly coming to an end. People today subscribe to a multitude of streaming services. Smart TVs have enabled a new generation of entertainment, not only limited to constant on-demand streaming as they now offer other features such as web browsing, communication, gaming etc. These functions have recently been embedded into a small IoT device that can connect to any TV with High Definition Multimedia Interface (HDMI) input known as Google Chromecast TV. Its wide adoption makes it a treasure trove for potential digital evidence. Our work is the primary source on forensically interrogating Chromecast TV devices. We found that the device is always unlocked, allowing extraction of application data through the backup feature of Android Debug Bridge (ADB) without device root access. We take advantage of this minimal access and demonstrate how a series of artifacts can stitch together a detailed timeline, and we automate the process by constructing Forensicast – a Chromecast TV forensic acquisition and timelining tool. Our work targeted (n=112) of the most popular Android TV applications including 69\% (77/112) third party applications and 31\% (35/112) system applications. 65\% (50/77) third party applications allowed backup, and of those 90\% (45/50) contained time-based identifiers, 40\% (20/50) invoked some form of logs/activity monitoring, 50\% (25/50) yielded some sort of token/cookie, 8\% (4/50) resulted in a device ID, 26\% (13/50) produced a user ID, and 24\% (12/50) created other information. 26\% (9/35) system applications provided meaningful artifacts, 78\% (7/9) provided time based identifiers, 22\% (2/9) involved some form of logs/activity monitoring, 22\% (2/9) yielded some form of token/cookie data, 22\% (2/9) resulted in a device ID, 44\% (4/9) provided a user ID, and 33\% (3/9) created other information. Our findings also illustrated common artifacts found in applications that are related to developer and advertising utilities, mainly WebView, Firebase, and Facebook Analytics. Future work and open research problems are shared.},
    booktitle     = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
    articleno     = {50},
    numpages      = {12},
    keywords      = {ADB, Android TV, Artifacts, Digital Forensics, Google TV},
    location      = {Vienna, Austria},
    series        = {ARES '21}
}
@article{10.1145/3463521,
    author        = {Liu, Jialin and Li, Dong and Wang, Lei and Xiong, Jie},
    title         = {BlinkListener: "Listen" to Your Eye Blink Using Your Smartphone},
    year          = {2021},
    issue_date    = {June 2021},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    volume        = {5},
    number        = {2},
    url           = {https://doi.org/10.1145/3463521},
    doi           = {10.1145/3463521},
    abstract      = {Eye blink detection plays a key role in many real-life applications such as Human-Computer Interaction (HCI), drowsy driving prevention and eye disease detection. Although traditional camera-based techniques are promising, multiple issues hinder their wide adoption including the privacy concern, strict lighting condition and line-of-sight (LoS) requirements. On the other hand, wireless sensing without a need for dedicated sensors gains a tremendous amount of attention in recent years. Among the wireless signals utilized for sensing, acoustic signals show a unique potential for fine-grained sensing owing to their low propagation speed in the air. Another trend favoring acoustic sensing is the wide availability of speakers and microphones in commodity devices. Promising progress has been achieved in fine-grained human motion sensing such as breathing using acoustic signals. However, it is still very challenging to employ acoustic signals for eye blink detection due to the unique characteristics of eye blink (i.e., subtle, sparse and aperiodic) and severe interference (i.e., from the human target himself and surrounding objects). We find that even the very subtle involuntary head movement induced by breathing can severely interfere with eye blink detection. In this work, for the first time, we propose a system called BlinkListener to sense the subtle eye blink motion using acoustic signals in a contact-free manner. We first quantitatively model the relationship between signal variation and the subtle movements caused by eye blink and interference. Then, we propose a novel method that exploits the "harmful" interference to maximize the subtle signal variation induced by eye blinks. We implement BlinkListener on both a research-purpose platform (Bela) and a commodity smartphone (iPhone 5c). Experiment results show that BlinkListener can achieve robust performance with a median detection accuracy of 95\%. Our system can achieve high accuracies when the smartphone is held in hand, the target wears glasses/sunglasses and in the presence of strong interference with people moving around.},
    journal       = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
    month         = jun,
    articleno     = {73},
    numpages      = {27},
    keywords      = {HCI, acoustic signals, contact-free sensing, eye blink detection}
}
@inproceedings{10.1145/2212776.2223749,
    author        = {Taele, Paul and Hammond, Tracy},
    title         = {Initial approaches for extending sketch recognition to beyond-surface environments},
    year          = {2012},
    isbn          = {9781450310161},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/2212776.2223749},
    doi           = {10.1145/2212776.2223749},
    abstract      = {Sketch recognition researchers have long concentrated their energies on investigating issues related to computer systems' difficulties in recognizing hand-drawn diagrams, but the focus has largely been on recognizing sketches on physical surfaces. While beyond-surface sketching actively takes place in diverse forms and in various activities, directly applying existing on-surface sketch recognition techniques beyond physical surfaces is far from trivial. In this paper, we investigate initial approaches for locating corners and extracting primitive geometric shapes in beyond-surface sketches, which are important ingredients of subsequent higher-level interpretations for building richer sketching interfaces. Moreover, we investigate preliminary challenges of sketch recognition in beyond-surface environments and discuss possible solutions for achieving successful next-step extensions of this work.},
    booktitle     = {CHI '12 Extended Abstracts on Human Factors in Computing Systems},
    pages         = {2039–2044},
    numpages      = {6},
    keywords      = {beyond-surface interactions, low-level processing, sketch recognition},
    location      = {Austin, Texas, USA},
    series        = {CHI EA '12}
}
@inproceedings{10.1145/2614348.2614380,
    author        = {Kotziampasis, Ioannis and Chalmers, Alan},
    title         = {Seamless interconnection of distributed virtual worlds},
    year          = {2007},
    isbn          = {9781605589565},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/2614348.2614380},
    doi           = {10.1145/2614348.2614380},
    abstract      = {Multi-user virtual environments implemented across the web allow many users to interact with the virtual world and each other in. The current standard for embedding virtual worlds in the Internet, VRML 2.0, provides links between these worlds, but it does not allow the user to see across these links before physically entering them. This paper describes the use of portals to connect the distributed virtual environments in a way that the interconnected virtual environment will be visible from different machines. A psychophysical study is presented which investigates user navigation in consistent and inconsistent virtual environments using portals compared to traditional VRML Anchor based hyperlinks.},
    booktitle     = {Proceedings of the 23rd Spring Conference on Computer Graphics},
    pages         = {225–231},
    numpages      = {7},
    keywords      = {VE, VRML, navigation in VEs, web 3d},
    location      = {Budmerice, Slovakia},
    series        = {SCCG '07}
}
@article{10.1145/1265957.1265960,
    author        = {Sprague, Nathan and Ballard, Dana and Robinson, Al},
    title         = {Modeling embodied visual behaviors},
    year          = {2007},
    issue_date    = {July 2007},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    volume        = {4},
    number        = {2},
    issn          = {1544-3558},
    url           = {https://doi.org/10.1145/1265957.1265960},
    doi           = {10.1145/1265957.1265960},
    abstract      = {To make progess in understanding human visuomotor behavior, we will need to understand its basic components at an abstract level. One way to achieve such an understanding would be to create a model of a human that has a sufficient amount of complexity so as to be capable of generating such behaviors. Recent technological advances have been made that allow progress to be made in this direction. Graphics models that simulate extensive human capabilities can be used as platforms from which to develop synthetic models of visuomotor behavior. Currently, such models can capture only a small portion of a full behavioral repertoire, but for the behaviors that they do model, they can describe complete visuomotor subsystems at a useful level of detail. The value in doing so is that the body's elaborate visuomotor structures greatly simplify the specification of the abstract behaviors that guide them. The net result is that, essentially, one is faced with proposing an embodied ``operating system'' model for picking the right set of abstract behaviors at each instant. This paper outlines one such model. A centerpiece of the model uses vision to aid the behavior that has the most to gain from taking environmental measurements. Preliminary tests of the model against human performance in realistic VR environments show that main features of the model show up in human behavior.},
    journal       = {ACM Trans. Appl. Percept.},
    month         = jul,
    pages         = {11–es},
    numpages      = {23},
    keywords      = {Visual routines, reinforcement learning, visual attention}
}
@inproceedings{10.1145/275519.275524,
    author        = {McCulley, Matthew B.},
    title         = {Effective virtual design of multi-dimensional data models and interfaces},
    year          = {1997},
    isbn          = {1581130511},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    url           = {https://doi.org/10.1145/275519.275524},
    doi           = {10.1145/275519.275524},
    booktitle     = {Proceedings of the 1997 Workshop on New Paradigms in Information Visualization and Manipulation},
    pages         = {19–23},
    numpages      = {5},
    location      = {Las Vegas, Nevada, USA},
    series        = {NPIV '97}
}
@article{10.1145/1371216.1371225,
    author        = {Tychsen, Anders and Hitchens, Michael and Brolund, Thea},
    title         = {Character play: the use of game characters in multi-player role-playing games across platforms},
    year          = {2008},
    issue_date    = {April/June 2008},
    publisher     = {Association for Computing Machinery},
    address       = {New York, NY, USA},
    volume        = {6},
    number        = {2},
    url           = {https://doi.org/10.1145/1371216.1371225},
    doi           = {10.1145/1371216.1371225},
    abstract      = {Avatars are a commonly used mechanism for representing the player within the world of a game. The avatar forms the main point of interaction between the player and the game, and thus the avatar is an important game design feature. Character-based games combine the concept of an avatar with that of a character, enhancing the avatar with specific features that commonly are changeable, and which can be defined within or outside the framework of the game rules. Within digital games, the rules-based features have received comparatively more attention than, for example, the personalities and background histories of game characters. This article presents results from a comprehensive empirical study of the way complex game characters are utilized by players in multiplayer role-playing games across two different media platforms. The results indicate that adult players are capable of comprehending and utilizing game characters with well-defined personalities and backgrounds, as well as rules-based components. Furthermore, that the game format plays a significant role in the pattern of usage of the character elements. This pattern appears directly linked with variations in the way that the different game formats handle player characters and activate or promote the activation of, different forms of character elements. The degree to which different character elements are activated also has implications for the degree of player engagement in the character.},
    journal       = {Comput. Entertain.},
    month         = jul,
    articleno     = {22},
    numpages      = {24},
    keywords      = {characters, interaction, online communication, personality, role-playing games}
}
